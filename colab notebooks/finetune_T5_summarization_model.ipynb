{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfqfJGP17HWntyjplod4vX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f93463597aa94a538af95d2e555e3acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18cf1627a5f34b03885331931db6e4eb",
              "IPY_MODEL_de4744fbccf44a5991034579a16183a8",
              "IPY_MODEL_3ee2f30367d44b8588236a61f1526688",
              "IPY_MODEL_565d92ba18484d96835f8bf5561e2739",
              "IPY_MODEL_ab32643a5ccb47a3b1c3cffffd7751a6"
            ],
            "layout": "IPY_MODEL_03d93e887b154876803f75bf4b205199"
          }
        },
        "18cf1627a5f34b03885331931db6e4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b1063a3ff0b4fbd90895d869e5603ff",
            "placeholder": "​",
            "style": "IPY_MODEL_116d0184524040468c3b8e11b9e137ff",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "de4744fbccf44a5991034579a16183a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_cc527dfe387b429f9274b020e30cf6a5",
            "placeholder": "​",
            "style": "IPY_MODEL_93e8a9e997fd4526b2de9c45869d64e0",
            "value": ""
          }
        },
        "3ee2f30367d44b8588236a61f1526688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e283e349964644098bba88e4889905b2",
            "style": "IPY_MODEL_90cef04c62cc46b18a205822a1fa2fe9",
            "value": true
          }
        },
        "565d92ba18484d96835f8bf5561e2739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_86c38eea1c9349a8a84acd39f5b6a2da",
            "style": "IPY_MODEL_bb23b953c4024be78090f99ec59820c2",
            "tooltip": ""
          }
        },
        "ab32643a5ccb47a3b1c3cffffd7751a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70f86b9ea0244c184414b9965c46828",
            "placeholder": "​",
            "style": "IPY_MODEL_e85e8db9710f462d8ec03a67b5b98b81",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "03d93e887b154876803f75bf4b205199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "4b1063a3ff0b4fbd90895d869e5603ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "116d0184524040468c3b8e11b9e137ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc527dfe387b429f9274b020e30cf6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e8a9e997fd4526b2de9c45869d64e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e283e349964644098bba88e4889905b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90cef04c62cc46b18a205822a1fa2fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c38eea1c9349a8a84acd39f5b6a2da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb23b953c4024be78090f99ec59820c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b70f86b9ea0244c184414b9965c46828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e85e8db9710f462d8ec03a67b5b98b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fffdd81795d4187b015e35d2956b2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a72dd933d41b42e183d9651d61387705",
              "IPY_MODEL_4a1c045babd64104818e3702e7c01da3",
              "IPY_MODEL_240bda4720c5406cb54411c60e96b014"
            ],
            "layout": "IPY_MODEL_d5c1872c1495420ba8e70f680540d7d8"
          }
        },
        "a72dd933d41b42e183d9651d61387705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddcbbbd1be10457b85aa4f00ce0d3ab1",
            "placeholder": "​",
            "style": "IPY_MODEL_f775bb5f8b104187b0834f713fb0af98",
            "value": "100%"
          }
        },
        "4a1c045babd64104818e3702e7c01da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3680f06a874f88be6a101b3fac417a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b844851802274bf1bd46085d9d367d0a",
            "value": 3
          }
        },
        "240bda4720c5406cb54411c60e96b014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c10ed7de11f4c05a88132b4709b67d4",
            "placeholder": "​",
            "style": "IPY_MODEL_6385f7248d814895a49f830d33455c44",
            "value": " 3/3 [00:00&lt;00:00, 93.90it/s]"
          }
        },
        "d5c1872c1495420ba8e70f680540d7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddcbbbd1be10457b85aa4f00ce0d3ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f775bb5f8b104187b0834f713fb0af98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd3680f06a874f88be6a101b3fac417a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b844851802274bf1bd46085d9d367d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c10ed7de11f4c05a88132b4709b67d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6385f7248d814895a49f830d33455c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d019ce89270457bb035feda753aca8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90d80fdb88ad45439d281265e41e4c22",
              "IPY_MODEL_f39107850860492f8c6e630870ba364f",
              "IPY_MODEL_232a2ad8d00c4b369d179570fd3217d5"
            ],
            "layout": "IPY_MODEL_4c9a8765eb1941a69964dbcf4afbc33f"
          }
        },
        "90d80fdb88ad45439d281265e41e4c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19233830cb4b46b2906d5431809e407d",
            "placeholder": "​",
            "style": "IPY_MODEL_bec213d0754a46c294852bbe3291df8e",
            "value": "100%"
          }
        },
        "f39107850860492f8c6e630870ba364f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adb26f9fde28415299e710c1623cd37b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c0650618e754bfeb127450f5b947834",
            "value": 3
          }
        },
        "232a2ad8d00c4b369d179570fd3217d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3a83d0dce24c0193531ef2eb0ea9d8",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff93f3bb8ac4b50bec3c74eb0833add",
            "value": " 3/3 [00:00&lt;00:00, 56.04it/s]"
          }
        },
        "4c9a8765eb1941a69964dbcf4afbc33f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19233830cb4b46b2906d5431809e407d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec213d0754a46c294852bbe3291df8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adb26f9fde28415299e710c1623cd37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c0650618e754bfeb127450f5b947834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a3a83d0dce24c0193531ef2eb0ea9d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff93f3bb8ac4b50bec3c74eb0833add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b60606d0115488fa831bb1be6b6c409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30db1fc45c7c458faf3bcf46e8569c65",
              "IPY_MODEL_dccb2f0f5dcc45ed8ad889fb314b73b8",
              "IPY_MODEL_97300fb8c1ab4529ac5684697bc8a1a9"
            ],
            "layout": "IPY_MODEL_45ec2282c4264137bd38d8c7773b3be3"
          }
        },
        "30db1fc45c7c458faf3bcf46e8569c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd5938f021884371b631c710922892f0",
            "placeholder": "​",
            "style": "IPY_MODEL_4b25038873ea4a44b3cbc947a838b1cf",
            "value": "100%"
          }
        },
        "dccb2f0f5dcc45ed8ad889fb314b73b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f082bff2d34d7da4202c22566f8590",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22fcb9351f614c03b5d450696fc0c51e",
            "value": 3
          }
        },
        "97300fb8c1ab4529ac5684697bc8a1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff4eceb367542c69ba91743cf590f87",
            "placeholder": "​",
            "style": "IPY_MODEL_24ac5191c8d24f518392bf6abe69a6a8",
            "value": " 3/3 [00:00&lt;00:00, 49.95it/s]"
          }
        },
        "45ec2282c4264137bd38d8c7773b3be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd5938f021884371b631c710922892f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b25038873ea4a44b3cbc947a838b1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32f082bff2d34d7da4202c22566f8590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fcb9351f614c03b5d450696fc0c51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ff4eceb367542c69ba91743cf590f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ac5191c8d24f518392bf6abe69a6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9074dd716b3c432c8afd8d890a381ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_704bf7bbb5984bb3b1eb1de055340a4c",
              "IPY_MODEL_80312d561f5740469d2deabb6e5d5e33",
              "IPY_MODEL_68b131a852d04db5a859c04f4078fb2e"
            ],
            "layout": "IPY_MODEL_783a42e844a1459dafc13233e7db80c9"
          }
        },
        "704bf7bbb5984bb3b1eb1de055340a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d44a660cf4384145aac5bc3d7ca19806",
            "placeholder": "​",
            "style": "IPY_MODEL_e37eb4168a6744d5843232844dab1249",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "80312d561f5740469d2deabb6e5d5e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e49509f5f0ee4051a14ecebbffed7df5",
            "max": 891691430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a1119bbe3c043dcb2c83904b6c719d9",
            "value": 891691430
          }
        },
        "68b131a852d04db5a859c04f4078fb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1afb85aadc54c29a1b3e2dca7ead31f",
            "placeholder": "​",
            "style": "IPY_MODEL_cc0789f42419496b955bd8da46b72f2e",
            "value": " 892M/892M [00:06&lt;00:00, 133MB/s]"
          }
        },
        "783a42e844a1459dafc13233e7db80c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44a660cf4384145aac5bc3d7ca19806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37eb4168a6744d5843232844dab1249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e49509f5f0ee4051a14ecebbffed7df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1119bbe3c043dcb2c83904b6c719d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1afb85aadc54c29a1b3e2dca7ead31f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc0789f42419496b955bd8da46b72f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f68110c48ae4de5acf627a2d228e017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_072fec27eaa04729961e8bb567f7c7e3",
              "IPY_MODEL_64e65c5eafc242099b07f9600b5d5d35",
              "IPY_MODEL_896b58c315ff40b888b2aab52da8531a"
            ],
            "layout": "IPY_MODEL_1e55104db86b49a1bc94a46eef5e1c2b"
          }
        },
        "072fec27eaa04729961e8bb567f7c7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ebff149d3774e39b7f31626fe3b5682",
            "placeholder": "​",
            "style": "IPY_MODEL_bd63274982754ba4941488d3c996eec5",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "64e65c5eafc242099b07f9600b5d5d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0cf752859f84419be7e2f857507604f",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_663fa01102b7434f8f74858243ccef26",
            "value": 147
          }
        },
        "896b58c315ff40b888b2aab52da8531a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25217f2815fa4910b8cffef620debca3",
            "placeholder": "​",
            "style": "IPY_MODEL_98ea5412c09745159009473fc445fa03",
            "value": " 147/147 [00:00&lt;00:00, 4.05kB/s]"
          }
        },
        "1e55104db86b49a1bc94a46eef5e1c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ebff149d3774e39b7f31626fe3b5682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd63274982754ba4941488d3c996eec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0cf752859f84419be7e2f857507604f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663fa01102b7434f8f74858243ccef26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25217f2815fa4910b8cffef620debca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98ea5412c09745159009473fc445fa03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goPnwTNxEoQj",
        "outputId": "8fe8f81d-f908-44cb-ddb4-8427abdc2948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.98)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.9/dist-packages (0.1.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.9/dist-packages (0.20.5)\n",
            "Requirement already satisfied: inflate64>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from py7zr) (0.3.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from py7zr) (5.9.5)\n",
            "Requirement already satisfied: pycryptodomex>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from py7zr) (3.17)\n",
            "Requirement already satisfied: pybcj>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from py7zr) (1.0.1)\n",
            "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from py7zr) (1.0.0)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.9/dist-packages (from py7zr) (0.2.3)\n",
            "Requirement already satisfied: pyzstd>=0.14.4 in /usr/local/lib/python3.9/dist-packages (from py7zr) (0.15.7)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.9/dist-packages (from py7zr) (1.6.7)\n",
            "Requirement already satisfied: brotli>=1.0.9 in /usr/local/lib/python3.9/dist-packages (from py7zr) (1.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -q\n",
        "!pip install wandb -q\n",
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install sentencepiece\n",
        "! pip install rouge_score\n",
        "! pip install py7zr\n",
        "# Code for TPU packages install\n",
        "# !curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "metadata": {
        "id": "uPfjTYEEE5BD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking out the GPU we have access to. This is output is from the google colab version. \n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjwm-QzRE6O6",
        "outputId": "e6d9282f-8ecd-4c37-fc9f-233bb5d44f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 21 14:16:26 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# Preparing for TPU usage\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()"
      ],
      "metadata": {
        "id": "P3W3g6iFE7PQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdrOyipXE8kG",
        "outputId": "04b76ef8-5a03-4949-ca8f-f754f53ff5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjainr3\u001b[0m (\u001b[33mrahul96jain\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "f93463597aa94a538af95d2e555e3acd",
            "18cf1627a5f34b03885331931db6e4eb",
            "de4744fbccf44a5991034579a16183a8",
            "3ee2f30367d44b8588236a61f1526688",
            "565d92ba18484d96835f8bf5561e2739",
            "ab32643a5ccb47a3b1c3cffffd7751a6",
            "03d93e887b154876803f75bf4b205199",
            "4b1063a3ff0b4fbd90895d869e5603ff",
            "116d0184524040468c3b8e11b9e137ff",
            "cc527dfe387b429f9274b020e30cf6a5",
            "93e8a9e997fd4526b2de9c45869d64e0",
            "e283e349964644098bba88e4889905b2",
            "90cef04c62cc46b18a205822a1fa2fe9",
            "86c38eea1c9349a8a84acd39f5b6a2da",
            "bb23b953c4024be78090f99ec59820c2",
            "b70f86b9ea0244c184414b9965c46828",
            "e85e8db9710f462d8ec03a67b5b98b81"
          ]
        },
        "id": "oS-cX6uwGBUp",
        "outputId": "e3408dd1-2fd6-493c-d657-794d2aca2172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.text = self.data.text\n",
        "        self.ctext = self.data.ctext\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ctext = str(self.ctext[index])\n",
        "        ctext = ' '.join(ctext.split())\n",
        "\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "rUcZdJT5E-fD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # xm.optimizer_step(optimizer)\n",
        "        # xm.mark_step()"
      ],
      "metadata": {
        "id": "SDo391nNFE6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "metadata": {
        "id": "uJ3cKMR0FJEa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Initialize a new run\n",
        "wandb.init(project=\"T5_finetune_dialogue\")\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "# Defining some key variables that will be used later on in the training  \n",
        "config = wandb.config          # Initialize config\n",
        "config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n",
        "config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n",
        "config.TRAIN_EPOCHS = 2        # number of epochs to train (default: 10)\n",
        "config.VAL_EPOCHS = 1 \n",
        "config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "config.SEED = 42               # random seed (default: 42)\n",
        "config.MAX_LEN = 512\n",
        "config.SUMMARY_LEN = 150 \n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "torch.manual_seed(config.SEED) # pytorch random seed\n",
        "np.random.seed(config.SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# tokenzier for encoding the text\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "-ZnNPigMImvJ",
        "outputId": "87f31fb6-1276-466e-fd02-02610d3e287e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230421_230030-31lwn4ke</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rahul96jain/T5_finetune_dialogue/runs/31lwn4ke' target=\"_blank\">hardy-snowflake-5</a></strong> to <a href='https://wandb.ai/rahul96jain/T5_finetune_dialogue' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rahul96jain/T5_finetune_dialogue' target=\"_blank\">https://wandb.ai/rahul96jain/T5_finetune_dialogue</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rahul96jain/T5_finetune_dialogue/runs/31lwn4ke' target=\"_blank\">https://wandb.ai/rahul96jain/T5_finetune_dialogue/runs/31lwn4ke</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing and Pre-Processing the domain data\n",
        "# Selecting the needed columns only. \n",
        "# Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
        "#df = pd.read_csv('./data/news_summary.csv',encoding='latin-1')\n",
        "#df = df[['text','ctext']]\n",
        "#df.ctext = 'summarize: ' + df.ctext\n",
        "#print(df.head())\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "def merge_splits(data):\n",
        "  data = datasets.concatenate_datasets([data[\"train\"], data[\"validation\"], data[\"test\"]])\n",
        "  return data\n",
        "\n",
        "data_AMI = merge_splits(load_dataset(\"knkarthick/AMI\"))\n",
        "data_samsum = merge_splits(load_dataset(\"samsum\"))\n",
        "data_dialogsum = merge_splits(load_dataset(\"knkarthick/dialogsum\"))\n",
        "\n",
        "def flatten(example):\n",
        "    return {\n",
        "        \"ctext\": \"summarize: \" + example[\"dialogue\"],\n",
        "        \"text\": example[\"summary\"],\n",
        "    }\n",
        "\n",
        "\n",
        "data_AMI = data_AMI.map(flatten, remove_columns=[\"id\"])\n",
        "data_samsum = data_samsum.map(flatten, remove_columns=[\"id\"])\n",
        "data_dialogsum = data_dialogsum.map(flatten, remove_columns=[\"id\", \"topic\"])\n",
        "\n",
        "dataset = datasets.concatenate_datasets([data_AMI, data_samsum, data_dialogsum])\n",
        "dataset = dataset.remove_columns([\"dialogue\", \"summary\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "0fffdd81795d4187b015e35d2956b2b5",
            "a72dd933d41b42e183d9651d61387705",
            "4a1c045babd64104818e3702e7c01da3",
            "240bda4720c5406cb54411c60e96b014",
            "d5c1872c1495420ba8e70f680540d7d8",
            "ddcbbbd1be10457b85aa4f00ce0d3ab1",
            "f775bb5f8b104187b0834f713fb0af98",
            "fd3680f06a874f88be6a101b3fac417a",
            "b844851802274bf1bd46085d9d367d0a",
            "7c10ed7de11f4c05a88132b4709b67d4",
            "6385f7248d814895a49f830d33455c44",
            "4d019ce89270457bb035feda753aca8b",
            "90d80fdb88ad45439d281265e41e4c22",
            "f39107850860492f8c6e630870ba364f",
            "232a2ad8d00c4b369d179570fd3217d5",
            "4c9a8765eb1941a69964dbcf4afbc33f",
            "19233830cb4b46b2906d5431809e407d",
            "bec213d0754a46c294852bbe3291df8e",
            "adb26f9fde28415299e710c1623cd37b",
            "3c0650618e754bfeb127450f5b947834",
            "3a3a83d0dce24c0193531ef2eb0ea9d8",
            "9ff93f3bb8ac4b50bec3c74eb0833add",
            "5b60606d0115488fa831bb1be6b6c409",
            "30db1fc45c7c458faf3bcf46e8569c65",
            "dccb2f0f5dcc45ed8ad889fb314b73b8",
            "97300fb8c1ab4529ac5684697bc8a1a9",
            "45ec2282c4264137bd38d8c7773b3be3",
            "fd5938f021884371b631c710922892f0",
            "4b25038873ea4a44b3cbc947a838b1cf",
            "32f082bff2d34d7da4202c22566f8590",
            "22fcb9351f614c03b5d450696fc0c51e",
            "4ff4eceb367542c69ba91743cf590f87",
            "24ac5191c8d24f518392bf6abe69a6a8"
          ]
        },
        "id": "r389xHobIvad",
        "outputId": "3213b3b2-f5bf-4f36-8e52-8eadb03bd61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--AMI-e0c25640a9a75f54/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fffdd81795d4187b015e35d2956b2b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset samsum (/root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d019ce89270457bb035feda753aca8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b60606d0115488fa831bb1be6b6c409"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--AMI-e0c25640a9a75f54/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-526a8a2cb7ebc061.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e/cache-3e0808eff45feb96.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-7accaf022775480d.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR5L1vAbLPKr",
        "outputId": "0f5e2533-7bf2-430d-c416-9df2372486b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['ctext', 'text'],\n",
              "    num_rows: 31108\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of Dataset and Dataloader\n",
        "# Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "#train_size = 0.8\n",
        "#train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
        "#val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "#train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "train_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.2).values()\n",
        "train_dataset = pd.DataFrame(train_data_txt)\n",
        "val_dataset = pd.DataFrame(validation_data_txt)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(dataset.num_rows))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "# Creating the Training and Validation dataset for further creation of Dataloader\n",
        "training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "# Defining the parameters for creation of dataloaders\n",
        "train_params = {\n",
        "    'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "val_params = {\n",
        "    'batch_size': config.VALID_BATCH_SIZE,\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-NWyFW4I0_a",
        "outputId": "76a2c723-3751-465e-e001-987bc5e2903c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: 31108\n",
            "TRAIN Dataset: (24886, 2)\n",
            "TEST Dataset: (6222, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "9074dd716b3c432c8afd8d890a381ffe",
            "704bf7bbb5984bb3b1eb1de055340a4c",
            "80312d561f5740469d2deabb6e5d5e33",
            "68b131a852d04db5a859c04f4078fb2e",
            "783a42e844a1459dafc13233e7db80c9",
            "d44a660cf4384145aac5bc3d7ca19806",
            "e37eb4168a6744d5843232844dab1249",
            "e49509f5f0ee4051a14ecebbffed7df5",
            "9a1119bbe3c043dcb2c83904b6c719d9",
            "a1afb85aadc54c29a1b3e2dca7ead31f",
            "cc0789f42419496b955bd8da46b72f2e",
            "7f68110c48ae4de5acf627a2d228e017",
            "072fec27eaa04729961e8bb567f7c7e3",
            "64e65c5eafc242099b07f9600b5d5d35",
            "896b58c315ff40b888b2aab52da8531a",
            "1e55104db86b49a1bc94a46eef5e1c2b",
            "8ebff149d3774e39b7f31626fe3b5682",
            "bd63274982754ba4941488d3c996eec5",
            "c0cf752859f84419be7e2f857507604f",
            "663fa01102b7434f8f74858243ccef26",
            "25217f2815fa4910b8cffef620debca3",
            "98ea5412c09745159009473fc445fa03"
          ]
        },
        "id": "_yzFClcuI6CU",
        "outputId": "56f344b9-0249-4583-9fb2-0cf957e670ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9074dd716b3c432c8afd8d890a381ffe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f68110c48ae4de5acf627a2d228e017"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log metrics with wandb\n",
        "wandb.watch(model, log=\"all\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8nYMbWmI772",
        "outputId": "e25a98d1-ce32-49c5-a316-ea7da43c0764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "for epoch in range(config.TRAIN_EPOCHS):\n",
        "    train(epoch, tokenizer, model, device, training_loader, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "P26-rYcTI-gw",
        "outputId": "fd7f2a43-a2b6-4873-afad-072027072bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  5.03864049911499\n",
            "Epoch: 0, Loss:  1.80507493019104\n",
            "Epoch: 0, Loss:  1.3921685218811035\n",
            "Epoch: 0, Loss:  2.235650062561035\n",
            "Epoch: 0, Loss:  0.9490264654159546\n",
            "Epoch: 0, Loss:  1.4951149225234985\n",
            "Epoch: 0, Loss:  1.9502311944961548\n",
            "Epoch: 0, Loss:  1.819398283958435\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d6a3e2bb71c2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-7b1779cfacca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, tokenizer, model, device, loader, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3J18peZNQDl",
        "outputId": "a25aa12b-144a-4abf-9e76-7c992092af2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ChM3aUUHYBwm",
        "outputId": "acd52609-17ba-4dd1-8256-481dddaba0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               ctext  \\\n",
              "0  Ashley: Hey who down for Yoga? \\r\\nLaurie: Is ...   \n",
              "\n",
              "                                                text  \n",
              "0  Laurie, Ashley, Matt and Jesse are going for s...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1d23e22-602c-48c8-9591-2b16fc7fc098\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ctext</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ashley: Hey who down for Yoga? \\r\\nLaurie: Is ...</td>\n",
              "      <td>Laurie, Ashley, Matt and Jesse are going for s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1d23e22-602c-48c8-9591-2b16fc7fc098')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1d23e22-602c-48c8-9591-2b16fc7fc098 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1d23e22-602c-48c8-9591-2b16fc7fc098');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "partial_val_set = CustomDataset(val_dataset[:50], tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "partial_val_loader = DataLoader(partial_val_set, **val_params)"
      ],
      "metadata": {
        "id": "12aZFf_9TDJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "# Saving the dataframe as predictions.csv\n",
        "print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "for epoch in range(config.VAL_EPOCHS):\n",
        "    #predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, partial_val_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv('/content/drive/MyDrive/predictions.csv')\n",
        "    print('Output Files generated for review')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GrJ_jCMJRCo",
        "outputId": "1896e56c-b143-4fc8-e1dd-dc5b5e44fbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 0\n",
            "Output Files generated for review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/t5-model-v1.pth\")"
      ],
      "metadata": {
        "id": "Vs5JW5GBNRHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving to huggingface\n",
        "# https://huggingface.co/transformers/v4.0.1/model_sharing.html#:~:text=In%20order%20to%20upload%20a,huggingface.co%2Fnew%3E%20.\n",
        "!transformers-cli login\n",
        "!transformers-cli repo create t5-finetuned-meetings\n",
        "!git clone https://huggingface.co/jainr3/t5-finetuned-meetings\n",
        "!git lfs install"
      ],
      "metadata": {
        "id": "vAb265pLNw8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"https://huggingface.co/jainr3/t5-finetuned-meetings\")\n",
        "tokenizer.save_pretrained(\"https://huggingface.co/jainr3/t5-finetuned-meetings\")"
      ],
      "metadata": {
        "id": "JpXpLRrwOtfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add --all\n",
        "!git status"
      ],
      "metadata": {
        "id": "K34T3uPiO2SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"First version of the t5 finetuned meetings model and tokenizer.\""
      ],
      "metadata": {
        "id": "SpuYmfKIO6Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push"
      ],
      "metadata": {
        "id": "ZnbyCjlfO_BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running inference on my dialogue"
      ],
      "metadata": {
        "id": "WvWNIz2LUtdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RkFfap5HUxSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dcef96d-7f37-442b-85ae-bd2531a8acc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/t5-model.pth\"))\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
      ],
      "metadata": {
        "id": "HNnhfaJiVBlj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_input_text = \" Hi, this is Eric Johnson. It's February 18, 2021, and this is the engineering key review at GitLab. So I've got number four in the agenda, which is a proposal to break up this meeting into four department key reviews. So currently this is engineering. Development quality, security, and UX infrastructure and support to their own key reviews already. I have the reasons why increased visibility able to go deeper. Increased the objectivity with which my reports can manage their groups, allow me more time to focus on new markets and allow me to shift into more of a question asker mode, then generating content and answering questions in these meetings. And to avoid adding three net new meetings to stakeholders counters, I propose we do a sort of two month rotation. So month one development quality go month two security and UX would go. How do people feel about that proposal? I think in the group conversations it's working really well. So I'm supportive and this is the smallest thing. Maybe we need four meetings a month, like it's the biggest department, it's super central. But you proposed this. I don't. I could see either way. So let's stick with the proposal. Go, we'll try it and we'll we can be flexible. I mean, development is larger. Maybe they go more frequently or something. I'll see how it goes. All right. And then I've got number five, which is we've got R&D overall MR rate. And we also have R&D wider MR rate, both as top level KPIs for engineering. So the difference between them in the simplest sense is that R&D wider MR rate includes both community contributions and community MRs. The problems I see with this are that one, the wider MR rate, the one that includes internally and external MRs, it duplicates the overall MR rate, which is. The wider MR rate should just be external, right? And then overall should be narrow plus wider. Oh, yeah. Like we say the wider community. Right, right, right. Okay. So there's. I have to check the taxonomy. Well, like, can you can you confirm? That's that's that's, that's, that's reasoning is my understanding as well. Yeah, I believe water MR rate just captures community contributions. Only and no internal. Yeah, and the reason we measure data is that like one of the most likely failure modes is that we lose the community. Yeah. So we're get, or we're gets goofy is the. When you look at a specific team within the company, there could be contributions outside of that that aren't community contributions. They would be viewed community contributions by that group, but effectively they're not from outside the company. So that's why we use wider to kind of reflect that. And narrow is very specific to the team. But are you saying that if someone in plan contributes to verify its viewed as wider? Not quite that plan plan and verify are just fine. It's when you look at like the development versus infrastructure infrastructure will oftentimes contribute to developments work, but it won't be counted as MRs. Yeah, that's a, that's a potential bit of funkiness that we should talk about separately. I didn't have that in my sort of critique of this, but that that doesn't necessarily make intuitive sense to me. So, so then I think part of my critique of this can be thrown out because it's not as duplicative as I thought, but I still think there's a problem with R&D wider MR rate, which is this thing doesn't really move. In part because it's a rate, so it feels like the way to drive this up is to specifically drive community authors to contribute more than one MR per month. That's how this moves up because it's a productivity rate like we use internally. And that doesn't necessarily feel like the right thing because there's scenarios in which this goes up. We've actually got less contributions overall and less contributors overall. Wait, wait, wait a second. So you're saying that R&D wider MR rate is number MRs per external contributor. Oh my goodness, that should not be the thing. It should be contributions for GitLab team member. So to contribute those, the thing above the division is the external ones. The thing below is the number of team members at GitLab. Is that the case, Lily? I'm checking right now. I think so in our MRs per team member. So unless we start calling people outside the company team member, then it shouldn't be that. Yeah, just clarifying here. So our numerator is community contributions and then our denominator is GitLab team members. So it's not per external member. So we've got what we're doing there, Eric, is we're not trying to say how many MRs does someone send if they send something? How many MRs from external do we get for the size of our organization? Sorry, I have a childhood emergency outside the door. So maybe explain the context behind this. The context is as we grow as a company, we should make sure we keep the community up. Like the logical thing is for the community to flatline and the size of the org to go and before you know, you've kind of outgrown the wider community. Yeah, what I'm seeing is we created this pre-sophisticated taxonomy with prefixes and postfixes to talk about these things. But in reality, we've only got two of them. And it's we keep forgetting, we have a hard time discussing this thing. So I'd rather just name them simply two names for what they are rather than using the taxonomy. But also like in F, I have this proposal of like, what if we just track as a KPI of the percentage of total MRs that come from the community over time? And we would see that drop. I love that. Let's do that instead. But the thing, the thing why we have this complex thing is because you can game that you want to game that you just produce fewer MRs with the engineers that get one. So if you drive that really hard and say this is your number one goal, it's very easy to achieve is just tell all your engineers to produce half. Yeah, so we have we have different metrics to prevent that from happening the same way that like support SLAs and asset kind of buttress one another. I think we're we're robust to that. But simplifying this would make these conversations. If you as our CTO don't even understand them, we went overboard. So I'm supportive. And I forgot and I was agreeing this stuff this morning and like, there's a problem with this and then you just remind me of the context. So yeah, I can't really have my head. A percentage that come from the community. I love that. It's what all our investors ask about. Let's do that. Okay. Cool. So, um, Lily, if you can work with Max to make that transition of the great. And I'll hold the one that we're talking about. That's from the mulberry. Thanks. I'm on the call. Sorry, it was a bit late. Timeline. We do have PIs on the raw number of community MRs and we can make the shift. And why they're confirming from the definition, I think why they only counts for community. And that's that's what the definition is. Cool. All right. So number six, then Christopher. Sorry, I was looking up to see if I had the percentage graph because I think we played around with this at one point and had a draft of that. Probably about five months back, if I can remember, Lily. Just in FYI month of February, if you were looking at any particular metrics, particularly in development at MR rate. We haven't had updates in four days. There's apparently a lag issue that's been problematic for the data team to basically get updated metrics and they're working on that. Okay. I'm sorry, Max. You get the next one. So yeah, there's some some color there on the on the medication, the lag later on. On to on to seven. We continue. I said FYI in addition to the TBI status. I'm sorry. I wanted to just touch on the postgres replication issue there real quick. I've been trying to get my arms wrapped around it. Um, do we have the right attention to this? This is kind of Eric. I don't know if you were commenting on. Hitting towards this in the last meeting around some of the infrastructure improvements on the product side. I'm just not quite sure whose responsibility is to focus on getting a handle on some of the constraints we have on replication. So what I was mentioning in the in the product queue review about an hour ago is I think is sort of like unrelated. And so I think the DRI needs to be your kind of data engineering team. But of course there's a dependency on infrastructure because that's where the data is being piqued from. They they do on that data source. So let's say for the replication lag on that slave host where I'm sorry not the on the the secondary host where the data is being pulled from like infrastructure would be the DRI for that. And so any escalations but well all those. And I know we have an action plan for that as far as creating another dedicated host just for the data team to pull from. I did ask I saw that issue and I did talk to Craig gums a little bit as well on the database side just to see if there's some database improvements and I'm still trying to figure out, you know, if it's truly just dedicated computation old sort of resource a server. Or if there's actually some some database tuning that needs to occur, do you have a sense of that. There's so I'd say it's it's three different things. It's having a dedicated host that doesn't have conflicting query traffic coming from other other workloads. There are some tuning performance or tuning improvements to be made. And then there's also improvements in and this is where it does maybe relate a little bit to what the topic was in the last review basically the overall demand on the database layer from from dot com activities and like improving those. It's definitely not just one of those things that one of the most specific actions we're going to take though is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there. And not having conflicting query. And conflicting queries affect the ability to update the replication. Steve, I definitely want to partner with you on this one because I think the the demand on those databases is only going to increase. It's not going down. And I think we need to get. I'm still unclear on where to focus and to get the biggest bang for the buck. I think of the computational resource dedication that's going to be a good thing, but I'll probably going to squeeze the balloon. Next area will will honor itself. Okay, I'll put into the infricky review for next week. Okay, on this issue. Thank you, Steve. So then back to mecon 7 or. Yes. Thank you. And Rob was in these assassins that this morning as well. We have the attention there. Number seven, just provide provide update on previous conversations. We continue to improve defect tracking and against SLOs. There is a first iteration P.I that we are experimenting to show percentage of defects meeting. And we are going to be able to see the SLOs key findings as ones are hovering at 80% as to at 60. We've been focused mostly on S1 as to this point as hence why S3 and S4s are a lower. And this will likely be the case. We are also in point B are working on the measurement for average open box age. This would give us a whole picture of what's what's left. So the age goes up and down. We are cleaning the backlog. The average age should go down as well. There's no P.I yet, but I just want to update and show up beyond this. It's not a off track. Number C Craig on S2. Yeah, just looking through the charts. And I noted that there's a spike in meantime to close. Yeah, and just want to see if you had any insight into that for us. This is the S2. Yeah, this is where the point B on age and supplemental charts in the back end helps. So I haven't seen a dip in age nor the count overall. I think it's the latter. We need to dig in a bit deeper in that. And also the data lag. I would like to re-evaluate when we have a whole picture of when everything is synced in as well. Christie, you have some insights. Yeah, I'm just wondering if part of this could be the fact that we changed the severity across the board for MRs to S2. And so we may have some older bugs in there that hadn't been addressed because they were at a lower severity. Now we've moved them to S2 and maybe that caused a little spike. That could be the case that we did in a limited fashion. It won't be a huge volume. We also iterated after that to pin on priority since product owns prioritization. So I wouldn't account it entirely to that. I mean, this isn't the infertile key review, but. I know that they've gotten backed up on those issues. So if some some good portion of those are infertile created or related, then that may be lifting it as well. I can take the deeper dig in and then provide an update next time. I think we need extra debug slicing of the data here. So you would like to go to point eight. Yeah, we are now measuring S1 as to SLO achievement with closed bugs. But if you then look at the number of bugs, it's exponential growth. And then it will be trivial to us to achieve 100% SLO achievement. If you just look at close bugs, even though there would be a major problem in the company, 99% of all bugs are overdue. As long as I only close ones that are still within the SLO, I'll have great achievement. So I think we shouldn't be looking at the closed bugs. I think we should be looking at open bugs. The entire population or percentage of those is within the SLO time. I think we're doing it the wrong way. Thanks for the thanks for the feedbacks that. Hence why we wanted to have the average age to measure what's outside in the open. And then make this iteration to measure also measure focus on the age of all opened, including open bugs. This is also something we have discussed with Christopher in the next iteration as well. And we happy when happy to adjust. So the key. Yes, go ahead. So average age would get closer to it. It's not what I'm proposing. What I'm proposing is off the open bugs are percentages outside of SLO. So display it as a percentage. You do now just do it about the open bugs month or close. Got it. Okay. The exceeding SLO for open bugs. Yeah, or open bugs that are within SLO. So you have a chart that should go up and to the right like everything else. Sounds great. We can take it to the next data metrics work stream to deliver this. Cool. Thanks. Is it pretty good? Yeah, I like it. You make you have to figure out how to. Because we like to be able to have charts that we can historically reconstruct if we need to. So in tickets close out, you need to go through their history to figure out at this time when it was open. Did it breach the SLO or not? That's a good point. This might be much harder computationally. And so I totally respect if we can do it for that reason. Yeah, I think that's a good point. Yeah, I think that's a good point. Cool. Nine. Yeah, I just wanted to ask the team like I went through all the key meeting metrics. Everything looked in line with prior periods and look good. Is there anything the team wants to call out? It's mostly that we should be watching. Yeah, I'll call out. So the good news is in Q4. We had our smallest decline over several quarters. So we only went down by a tenth of a point. The quarter previous was point six or six tenths of a point and the quarter before that was a full point. So. We see this as an improvement, even though it was still a decline, but it's still a decline. Obviously, we want this actually tracking in an upward direction. We also don't have enough data to know whether or not this is an actual real trend up. So I'm optimistic. I think this is a good thing. We have had a much keener focus on us over the past several quarters. And that's why I think, okay, the work that we've done. I think actually is catching up and getting noticed in sus, but we got to keep an eye on it. We can't. We cannot assume that that's the case. Yeah, and the bug discussion above just kind of points out that like we have an underlying problem right now in our metrics measurement. So if we change the measurements to reflect that, then hopefully we're in good shape. If we don't and we flat line and address it so that we flat line open S1s and S2s, you will see a temporary jump in and above SLOs. As we clear out that back, I'll go over that period of time. So we have a point C, which is similar to infrastructure. We need to get more security work prioritized or hearing that from the team, but neither that problem or that activity is sort of currently reflected in our security metrics. So we have some work to do long term to make sure the we see things like that in the metrics and the measurements that we're making. So back to you said 10. So now that Nero MR rate seems significantly below target. And maybe I helped that it would bounce back from December. I think it bounced back, but not back on target. Any any context there? What's going on? Yeah, so with family and friends days, we actually had some heavier of vacation days. And we historically have one thing to know is that we are actually at a higher MR rate. If you look, if you go back the last 18 months, we're actually at a higher Nero MR rate than we were back in each month this year. So if you compare October to October, November to November and January, I'm sorry, October, November, December and January, comparatively to last year, which will find is we're between a half point and a 1.5. MR rate above where we were in the month of previous year. That's great contact. Thank you, Chris, for good work. Yeah, so the expectation is is that February is a short month. We were at I think 16 work days with friends and family day and other things. Obviously seven carriages in Texas doesn't help things either for the folks who are working in Texas. But hopefully the rest of the team is being effective. I was hoping to see a better result right now, but with four or five days, particularly around release week. That's usually when we see do do see a little bit higher activity. So that's not accounted for yet. But you know, Marches, Marches when I'm expecting kind of see a real rebound much like we did last year. Awesome. Thanks. The other context I'll give is we now do time series targets. So when we change the target, you'll see they're reflected in the line. So if we were to look back historically here, the goal here was actually lower and Christopher was ambitious. So we kept raising it. We kept meeting that. So it should stare step here and we could go back and reconstruct that if we really wanted to. And then ignoring the sort of the seasonal dip here, we raised it to I think 11. And then we realize we're kind of hitting that point of doing and raising returns and the right thing to do business wise. And this is in our FY 22 direction is hold the line at productivity. Let's start to raise other things related to quality security, availability and what not. So that's kind of what you are, you're seeing this bump is we raised it and we realized, okay, that's not the we shouldn't raise it anymore. And we brought it back down to 10. So 10 will be the dark going forward. I'm going to try to get better a lot of other things while preventing this from dipping. And just want to call out that it's not necessary. Like, and higher MR rates should also help to address security and quality and other things because you're more productive. So you can fix more things so it's not necessarily opposite. But I agree with that. Let's hold the line 10 is then is a great number and and focus on other indicators to improve that makes it on a sense. Cool. Well said. All right, that's the agenda. Anyone want to vocalize anything else? Great. Well, thanks everybody. And I'm going to go check on my four year old and see if she got what whatever she needed. So cheers and toxic.\""
      ],
      "metadata": {
        "id": "nJLkAe4cV-gl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_params = {\n",
        "    'batch_size': config.VALID_BATCH_SIZE,\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }"
      ],
      "metadata": {
        "id": "gX321K9bDQh-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = pd.DataFrame(columns=['ctext', 'text'])\n",
        "\n",
        "def get_input_sentences(start_idx):\n",
        "  # Get whole sentences up to X number of characters; don't break sentences up\n",
        "  end_idx = start_idx + 1024\n",
        "  text = my_input_text[start_idx:end_idx]\n",
        "  end_sentence_chars = [\".\", \"?\", \"!\"]\n",
        "  next_start_idx = end_idx\n",
        "  while text[-1] not in end_sentence_chars and end_idx < len(my_input_text):\n",
        "      text = text[:-1]\n",
        "      next_start_idx -= 1\n",
        "  #print(len(tokenizer.tokenize(text)))\n",
        "  return text, next_start_idx\n",
        "\n",
        "start = 0\n",
        "input_text = []\n",
        "summarized_text = []\n",
        "while start < len(my_input_text):\n",
        "  input, start = get_input_sentences(start)\n",
        "  input_text.append(input)\n",
        "  print(\"input text \\n\" + input)\n",
        "\n",
        "for i, input in enumerate(input_text):\n",
        "  my_data.loc[i] = [\"summarize: \" + input, input]\n",
        "\n",
        "#my_data.loc[0] = [\"summarize: \" + my_input_text, \"\"]\n",
        "\n",
        "my_data = CustomDataset(my_data, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "my_data_loader = DataLoader(my_data, **val_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJdT6OJ9X_dN",
        "outputId": "8e31d5eb-296c-4c89-af69-f7000b1f6fb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input text \n",
            " Hi, this is Eric Johnson. It's February 18, 2021, and this is the engineering key review at GitLab. So I've got number four in the agenda, which is a proposal to break up this meeting into four department key reviews. So currently this is engineering. Development quality, security, and UX infrastructure and support to their own key reviews already. I have the reasons why increased visibility able to go deeper. Increased the objectivity with which my reports can manage their groups, allow me more time to focus on new markets and allow me to shift into more of a question asker mode, then generating content and answering questions in these meetings. And to avoid adding three net new meetings to stakeholders counters, I propose we do a sort of two month rotation. So month one development quality go month two security and UX would go. How do people feel about that proposal? I think in the group conversations it's working really well. So I'm supportive and this is the smallest thing.\n",
            "input text \n",
            " Maybe we need four meetings a month, like it's the biggest department, it's super central. But you proposed this. I don't. I could see either way. So let's stick with the proposal. Go, we'll try it and we'll we can be flexible. I mean, development is larger. Maybe they go more frequently or something. I'll see how it goes. All right. And then I've got number five, which is we've got R&D overall MR rate. And we also have R&D wider MR rate, both as top level KPIs for engineering. So the difference between them in the simplest sense is that R&D wider MR rate includes both community contributions and community MRs. The problems I see with this are that one, the wider MR rate, the one that includes internally and external MRs, it duplicates the overall MR rate, which is. The wider MR rate should just be external, right? And then overall should be narrow plus wider. Oh, yeah. Like we say the wider community. Right, right, right. Okay. So there's. I have to check the taxonomy. Well, like, can you can you confirm?\n",
            "input text \n",
            " That's that's that's, that's, that's reasoning is my understanding as well. Yeah, I believe water MR rate just captures community contributions. Only and no internal. Yeah, and the reason we measure data is that like one of the most likely failure modes is that we lose the community. Yeah. So we're get, or we're gets goofy is the. When you look at a specific team within the company, there could be contributions outside of that that aren't community contributions. They would be viewed community contributions by that group, but effectively they're not from outside the company. So that's why we use wider to kind of reflect that. And narrow is very specific to the team. But are you saying that if someone in plan contributes to verify its viewed as wider? Not quite that plan plan and verify are just fine. It's when you look at like the development versus infrastructure infrastructure will oftentimes contribute to developments work, but it won't be counted as MRs.\n",
            "input text \n",
            " Yeah, that's a, that's a potential bit of funkiness that we should talk about separately. I didn't have that in my sort of critique of this, but that that doesn't necessarily make intuitive sense to me. So, so then I think part of my critique of this can be thrown out because it's not as duplicative as I thought, but I still think there's a problem with R&D wider MR rate, which is this thing doesn't really move. In part because it's a rate, so it feels like the way to drive this up is to specifically drive community authors to contribute more than one MR per month. That's how this moves up because it's a productivity rate like we use internally. And that doesn't necessarily feel like the right thing because there's scenarios in which this goes up. We've actually got less contributions overall and less contributors overall. Wait, wait, wait a second. So you're saying that R&D wider MR rate is number MRs per external contributor. Oh my goodness, that should not be the thing.\n",
            "input text \n",
            " It should be contributions for GitLab team member. So to contribute those, the thing above the division is the external ones. The thing below is the number of team members at GitLab. Is that the case, Lily? I'm checking right now. I think so in our MRs per team member. So unless we start calling people outside the company team member, then it shouldn't be that. Yeah, just clarifying here. So our numerator is community contributions and then our denominator is GitLab team members. So it's not per external member. So we've got what we're doing there, Eric, is we're not trying to say how many MRs does someone send if they send something? How many MRs from external do we get for the size of our organization? Sorry, I have a childhood emergency outside the door. So maybe explain the context behind this. The context is as we grow as a company, we should make sure we keep the community up.\n",
            "input text \n",
            " Like the logical thing is for the community to flatline and the size of the org to go and before you know, you've kind of outgrown the wider community. Yeah, what I'm seeing is we created this pre-sophisticated taxonomy with prefixes and postfixes to talk about these things. But in reality, we've only got two of them. And it's we keep forgetting, we have a hard time discussing this thing. So I'd rather just name them simply two names for what they are rather than using the taxonomy. But also like in F, I have this proposal of like, what if we just track as a KPI of the percentage of total MRs that come from the community over time? And we would see that drop. I love that. Let's do that instead. But the thing, the thing why we have this complex thing is because you can game that you want to game that you just produce fewer MRs with the engineers that get one. So if you drive that really hard and say this is your number one goal, it's very easy to achieve is just tell all your engineers to produce half.\n",
            "input text \n",
            " Yeah, so we have we have different metrics to prevent that from happening the same way that like support SLAs and asset kind of buttress one another. I think we're we're robust to that. But simplifying this would make these conversations. If you as our CTO don't even understand them, we went overboard. So I'm supportive. And I forgot and I was agreeing this stuff this morning and like, there's a problem with this and then you just remind me of the context. So yeah, I can't really have my head. A percentage that come from the community. I love that. It's what all our investors ask about. Let's do that. Okay. Cool. So, um, Lily, if you can work with Max to make that transition of the great. And I'll hold the one that we're talking about. That's from the mulberry. Thanks. I'm on the call. Sorry, it was a bit late. Timeline. We do have PIs on the raw number of community MRs and we can make the shift. And why they're confirming from the definition, I think why they only counts for community.\n",
            "input text \n",
            " And that's that's what the definition is. Cool. All right. So number six, then Christopher. Sorry, I was looking up to see if I had the percentage graph because I think we played around with this at one point and had a draft of that. Probably about five months back, if I can remember, Lily. Just in FYI month of February, if you were looking at any particular metrics, particularly in development at MR rate. We haven't had updates in four days. There's apparently a lag issue that's been problematic for the data team to basically get updated metrics and they're working on that. Okay. I'm sorry, Max. You get the next one. So yeah, there's some some color there on the on the medication, the lag later on. On to on to seven. We continue. I said FYI in addition to the TBI status. I'm sorry. I wanted to just touch on the postgres replication issue there real quick. I've been trying to get my arms wrapped around it. Um, do we have the right attention to this? This is kind of Eric.\n",
            "input text \n",
            " I don't know if you were commenting on. Hitting towards this in the last meeting around some of the infrastructure improvements on the product side. I'm just not quite sure whose responsibility is to focus on getting a handle on some of the constraints we have on replication. So what I was mentioning in the in the product queue review about an hour ago is I think is sort of like unrelated. And so I think the DRI needs to be your kind of data engineering team. But of course there's a dependency on infrastructure because that's where the data is being piqued from. They they do on that data source. So let's say for the replication lag on that slave host where I'm sorry not the on the the secondary host where the data is being pulled from like infrastructure would be the DRI for that. And so any escalations but well all those. And I know we have an action plan for that as far as creating another dedicated host just for the data team to pull from.\n",
            "input text \n",
            " I did ask I saw that issue and I did talk to Craig gums a little bit as well on the database side just to see if there's some database improvements and I'm still trying to figure out, you know, if it's truly just dedicated computation old sort of resource a server. Or if there's actually some some database tuning that needs to occur, do you have a sense of that. There's so I'd say it's it's three different things. It's having a dedicated host that doesn't have conflicting query traffic coming from other other workloads. There are some tuning performance or tuning improvements to be made. And then there's also improvements in and this is where it does maybe relate a little bit to what the topic was in the last review basically the overall demand on the database layer from from dot com activities and like improving those.\n",
            "input text \n",
            " It's definitely not just one of those things that one of the most specific actions we're going to take though is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there. And not having conflicting query. And conflicting queries affect the ability to update the replication. Steve, I definitely want to partner with you on this one because I think the the demand on those databases is only going to increase. It's not going down. And I think we need to get. I'm still unclear on where to focus and to get the biggest bang for the buck. I think of the computational resource dedication that's going to be a good thing, but I'll probably going to squeeze the balloon. Next area will will honor itself. Okay, I'll put into the infricky review for next week. Okay, on this issue. Thank you, Steve. So then back to mecon 7 or. Yes. Thank you. And Rob was in these assassins that this morning as well. We have the attention there.\n",
            "input text \n",
            " Number seven, just provide provide update on previous conversations. We continue to improve defect tracking and against SLOs. There is a first iteration P.I that we are experimenting to show percentage of defects meeting. And we are going to be able to see the SLOs key findings as ones are hovering at 80% as to at 60. We've been focused mostly on S1 as to this point as hence why S3 and S4s are a lower. And this will likely be the case. We are also in point B are working on the measurement for average open box age. This would give us a whole picture of what's what's left. So the age goes up and down. We are cleaning the backlog. The average age should go down as well. There's no P.I yet, but I just want to update and show up beyond this. It's not a off track. Number C Craig on S2. Yeah, just looking through the charts. And I noted that there's a spike in meantime to close. Yeah, and just want to see if you had any insight into that for us. This is the S2.\n",
            "input text \n",
            " Yeah, this is where the point B on age and supplemental charts in the back end helps. So I haven't seen a dip in age nor the count overall. I think it's the latter. We need to dig in a bit deeper in that. And also the data lag. I would like to re-evaluate when we have a whole picture of when everything is synced in as well. Christie, you have some insights. Yeah, I'm just wondering if part of this could be the fact that we changed the severity across the board for MRs to S2. And so we may have some older bugs in there that hadn't been addressed because they were at a lower severity. Now we've moved them to S2 and maybe that caused a little spike. That could be the case that we did in a limited fashion. It won't be a huge volume. We also iterated after that to pin on priority since product owns prioritization. So I wouldn't account it entirely to that. I mean, this isn't the infertile key review, but. I know that they've gotten backed up on those issues.\n",
            "input text \n",
            " So if some some good portion of those are infertile created or related, then that may be lifting it as well. I can take the deeper dig in and then provide an update next time. I think we need extra debug slicing of the data here. So you would like to go to point eight. Yeah, we are now measuring S1 as to SLO achievement with closed bugs. But if you then look at the number of bugs, it's exponential growth. And then it will be trivial to us to achieve 100% SLO achievement. If you just look at close bugs, even though there would be a major problem in the company, 99% of all bugs are overdue. As long as I only close ones that are still within the SLO, I'll have great achievement. So I think we shouldn't be looking at the closed bugs. I think we should be looking at open bugs. The entire population or percentage of those is within the SLO time. I think we're doing it the wrong way. Thanks for the thanks for the feedbacks that. Hence why we wanted to have the average age to measure what's outside in the open.\n",
            "input text \n",
            " And then make this iteration to measure also measure focus on the age of all opened, including open bugs. This is also something we have discussed with Christopher in the next iteration as well. And we happy when happy to adjust. So the key. Yes, go ahead. So average age would get closer to it. It's not what I'm proposing. What I'm proposing is off the open bugs are percentages outside of SLO. So display it as a percentage. You do now just do it about the open bugs month or close. Got it. Okay. The exceeding SLO for open bugs. Yeah, or open bugs that are within SLO. So you have a chart that should go up and to the right like everything else. Sounds great. We can take it to the next data metrics work stream to deliver this. Cool. Thanks. Is it pretty good? Yeah, I like it. You make you have to figure out how to. Because we like to be able to have charts that we can historically reconstruct if we need to. So in tickets close out, you need to go through their history to figure out at this time when it was open.\n",
            "input text \n",
            " Did it breach the SLO or not? That's a good point. This might be much harder computationally. And so I totally respect if we can do it for that reason. Yeah, I think that's a good point. Yeah, I think that's a good point. Cool. Nine. Yeah, I just wanted to ask the team like I went through all the key meeting metrics. Everything looked in line with prior periods and look good. Is there anything the team wants to call out? It's mostly that we should be watching. Yeah, I'll call out. So the good news is in Q4. We had our smallest decline over several quarters. So we only went down by a tenth of a point. The quarter previous was point six or six tenths of a point and the quarter before that was a full point. So. We see this as an improvement, even though it was still a decline, but it's still a decline. Obviously, we want this actually tracking in an upward direction. We also don't have enough data to know whether or not this is an actual real trend up. So I'm optimistic. I think this is a good thing.\n",
            "input text \n",
            " We have had a much keener focus on us over the past several quarters. And that's why I think, okay, the work that we've done. I think actually is catching up and getting noticed in sus, but we got to keep an eye on it. We can't. We cannot assume that that's the case. Yeah, and the bug discussion above just kind of points out that like we have an underlying problem right now in our metrics measurement. So if we change the measurements to reflect that, then hopefully we're in good shape. If we don't and we flat line and address it so that we flat line open S1s and S2s, you will see a temporary jump in and above SLOs. As we clear out that back, I'll go over that period of time. So we have a point C, which is similar to infrastructure. We need to get more security work prioritized or hearing that from the team, but neither that problem or that activity is sort of currently reflected in our security metrics.\n",
            "input text \n",
            " So we have some work to do long term to make sure the we see things like that in the metrics and the measurements that we're making. So back to you said 10. So now that Nero MR rate seems significantly below target. And maybe I helped that it would bounce back from December. I think it bounced back, but not back on target. Any any context there? What's going on? Yeah, so with family and friends days, we actually had some heavier of vacation days. And we historically have one thing to know is that we are actually at a higher MR rate. If you look, if you go back the last 18 months, we're actually at a higher Nero MR rate than we were back in each month this year. So if you compare October to October, November to November and January, I'm sorry, October, November, December and January, comparatively to last year, which will find is we're between a half point and a 1.5. MR rate above where we were in the month of previous year. That's great contact. Thank you, Chris, for good work.\n",
            "input text \n",
            " Yeah, so the expectation is is that February is a short month. We were at I think 16 work days with friends and family day and other things. Obviously seven carriages in Texas doesn't help things either for the folks who are working in Texas. But hopefully the rest of the team is being effective. I was hoping to see a better result right now, but with four or five days, particularly around release week. That's usually when we see do do see a little bit higher activity. So that's not accounted for yet. But you know, Marches, Marches when I'm expecting kind of see a real rebound much like we did last year. Awesome. Thanks. The other context I'll give is we now do time series targets. So when we change the target, you'll see they're reflected in the line. So if we were to look back historically here, the goal here was actually lower and Christopher was ambitious. So we kept raising it. We kept meeting that. So it should stare step here and we could go back and reconstruct that if we really wanted to.\n",
            "input text \n",
            " And then ignoring the sort of the seasonal dip here, we raised it to I think 11. And then we realize we're kind of hitting that point of doing and raising returns and the right thing to do business wise. And this is in our FY 22 direction is hold the line at productivity. Let's start to raise other things related to quality security, availability and what not. So that's kind of what you are, you're seeing this bump is we raised it and we realized, okay, that's not the we shouldn't raise it anymore. And we brought it back down to 10. So 10 will be the dark going forward. I'm going to try to get better a lot of other things while preventing this from dipping. And just want to call out that it's not necessary. Like, and higher MR rates should also help to address security and quality and other things because you're more productive. So you can fix more things so it's not necessarily opposite. But I agree with that.\n",
            "input text \n",
            " Let's hold the line 10 is then is a great number and and focus on other indicators to improve that makes it on a sense. Cool. Well said. All right, that's the agenda. Anyone want to vocalize anything else? Great. Well, thanks everybody. And I'm going to go check on my four year old and see if she got what whatever she needed. So cheers and toxic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Now generating summaries on our fine tuned model for my dataset and saving it in a dataframe')\n",
        "for epoch in range(config.VAL_EPOCHS):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, my_data_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv('/content/drive/MyDrive/my_predictions.csv')\n",
        "    print('Output Files generated for review')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-_Fd04WYkRv",
        "outputId": "bbe6f8d7-fbc0-4d65-85c2-241d63c50c6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now generating summaries on our fine tuned model for my dataset and saving it in a dataframe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Files generated for review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1385
        },
        "id": "2IGraKLMZoKj",
        "outputId": "496d02a8-b027-43fe-9ec7-f75c19bd98a4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       Generated Text  \\\n",
              "0   Eric Johnson proposes breaking up the engineer...   \n",
              "1   i'm going to try it and see how it goes. I've ...   \n",
              "2   water MR rate just captures community contribu...   \n",
              "3   the R&D wider MR rate doesn't really move beca...   \n",
              "4   MRs should be for GitLab team member, not exte...   \n",
              "5   the community is flatline and the size of the ...   \n",
              "6   mulberry has different metrics to prevent that...   \n",
              "7   a lag issue has been problematic for the data ...   \n",
              "8   the DRI needs to be your kind of data engineer...   \n",
              "9   Craig gums is still trying to figure out if th...   \n",
              "10  Steve and Rob are going to separate out and ha...   \n",
              "11  a first iteration of P.I shows percentage of d...   \n",
              "12  a dip in age and the count overall could be du...   \n",
              "13  99% of all bugs are overdue. I think we should...   \n",
              "14  iteration to measure and focus on the age of a...   \n",
              "15  nine thinks it's a good point. Nine thinks it'...   \n",
              "16  the work that we've done is catching up and ge...   \n",
              "17  Nero MR rate seems significantly below target ...   \n",
              "18  the expectation is that February is a short mo...   \n",
              "19  ignoring the seasonal dip, we raised it to 11....   \n",
              "20  the line 10 is a great number and focus on oth...   \n",
              "\n",
              "                                          Actual Text  \n",
              "0   Hi, this is Eric Johnson. It's February 18, 20...  \n",
              "1   Maybe we need four meetings a month, like it's...  \n",
              "2   That's that's that's, that's, that's reasoning...  \n",
              "3   Yeah, that's a, that's a potential bit of funk...  \n",
              "4   It should be contributions for GitLab team mem...  \n",
              "5   Like the logical thing is for the community to...  \n",
              "6   Yeah, so we have we have different metrics to ...  \n",
              "7   And that's that's what the definition is. Cool...  \n",
              "8   I don't know if you were commenting on. Hittin...  \n",
              "9   I did ask I saw that issue and I did talk to C...  \n",
              "10  It's definitely not just one of those things t...  \n",
              "11  Number seven, just provide provide update on p...  \n",
              "12  Yeah, this is where the point B on age and sup...  \n",
              "13  So if some some good portion of those are infe...  \n",
              "14  And then make this iteration to measure also m...  \n",
              "15  Did it breach the SLO or not? That's a good po...  \n",
              "16  We have had a much keener focus on us over the...  \n",
              "17  So we have some work to do long term to make s...  \n",
              "18  Yeah, so the expectation is is that February i...  \n",
              "19  And then ignoring the sort of the seasonal dip...  \n",
              "20  Let's hold the line 10 is then is a great numb...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2b5fb27-3aa5-4965-9c9f-55f46c157fcc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eric Johnson proposes breaking up the engineer...</td>\n",
              "      <td>Hi, this is Eric Johnson. It's February 18, 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i'm going to try it and see how it goes. I've ...</td>\n",
              "      <td>Maybe we need four meetings a month, like it's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>water MR rate just captures community contribu...</td>\n",
              "      <td>That's that's that's, that's, that's reasoning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the R&amp;D wider MR rate doesn't really move beca...</td>\n",
              "      <td>Yeah, that's a, that's a potential bit of funk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MRs should be for GitLab team member, not exte...</td>\n",
              "      <td>It should be contributions for GitLab team mem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the community is flatline and the size of the ...</td>\n",
              "      <td>Like the logical thing is for the community to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mulberry has different metrics to prevent that...</td>\n",
              "      <td>Yeah, so we have we have different metrics to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a lag issue has been problematic for the data ...</td>\n",
              "      <td>And that's that's what the definition is. Cool...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the DRI needs to be your kind of data engineer...</td>\n",
              "      <td>I don't know if you were commenting on. Hittin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Craig gums is still trying to figure out if th...</td>\n",
              "      <td>I did ask I saw that issue and I did talk to C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Steve and Rob are going to separate out and ha...</td>\n",
              "      <td>It's definitely not just one of those things t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>a first iteration of P.I shows percentage of d...</td>\n",
              "      <td>Number seven, just provide provide update on p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>a dip in age and the count overall could be du...</td>\n",
              "      <td>Yeah, this is where the point B on age and sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>99% of all bugs are overdue. I think we should...</td>\n",
              "      <td>So if some some good portion of those are infe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>iteration to measure and focus on the age of a...</td>\n",
              "      <td>And then make this iteration to measure also m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>nine thinks it's a good point. Nine thinks it'...</td>\n",
              "      <td>Did it breach the SLO or not? That's a good po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>the work that we've done is catching up and ge...</td>\n",
              "      <td>We have had a much keener focus on us over the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Nero MR rate seems significantly below target ...</td>\n",
              "      <td>So we have some work to do long term to make s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the expectation is that February is a short mo...</td>\n",
              "      <td>Yeah, so the expectation is is that February i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ignoring the seasonal dip, we raised it to 11....</td>\n",
              "      <td>And then ignoring the sort of the seasonal dip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>the line 10 is a great number and focus on oth...</td>\n",
              "      <td>Let's hold the line 10 is then is a great numb...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2b5fb27-3aa5-4965-9c9f-55f46c157fcc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2b5fb27-3aa5-4965-9c9f-55f46c157fcc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2b5fb27-3aa5-4965-9c9f-55f46c157fcc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}