{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eacdf6886bb844eab75188014a249f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d9c9aec0395414a9006d02898fe0086",
              "IPY_MODEL_873790b8c839472bbd0c076889269ae0",
              "IPY_MODEL_21e015e1a4f8444880ecfbd0e902a5fb",
              "IPY_MODEL_6ad5c183dcf04d4a95fcf51daf512f94",
              "IPY_MODEL_80dd67c58b6a4ba88422c0876879cddc"
            ],
            "layout": "IPY_MODEL_12016255d8ed405b9eaf855c920b1406"
          }
        },
        "5d9c9aec0395414a9006d02898fe0086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4745c7ed766408f85b71056f849ee62",
            "placeholder": "​",
            "style": "IPY_MODEL_09805fd6793949d8b28bee8c4e52922d",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "873790b8c839472bbd0c076889269ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7a58106535ba4293a1031aa5b734d3c3",
            "placeholder": "​",
            "style": "IPY_MODEL_4520462402a94b69bc4b73c026c597a3",
            "value": ""
          }
        },
        "21e015e1a4f8444880ecfbd0e902a5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7860458fedce4f7fb9886df67323060c",
            "style": "IPY_MODEL_acf0a6a4419c434eb47676c6fd1fb5c7",
            "value": true
          }
        },
        "6ad5c183dcf04d4a95fcf51daf512f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9049a08a0cc049e6a1a54e2d1ff7cd69",
            "style": "IPY_MODEL_ec576c8cdfb140e9aaf1bb6ad76f333c",
            "tooltip": ""
          }
        },
        "80dd67c58b6a4ba88422c0876879cddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219d3390dca0443f99bf11de4f461a7c",
            "placeholder": "​",
            "style": "IPY_MODEL_39a5bbadd0f24d5b9c6567f0eebdf63c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "12016255d8ed405b9eaf855c920b1406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e4745c7ed766408f85b71056f849ee62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09805fd6793949d8b28bee8c4e52922d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a58106535ba4293a1031aa5b734d3c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4520462402a94b69bc4b73c026c597a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7860458fedce4f7fb9886df67323060c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acf0a6a4419c434eb47676c6fd1fb5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9049a08a0cc049e6a1a54e2d1ff7cd69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec576c8cdfb140e9aaf1bb6ad76f333c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "219d3390dca0443f99bf11de4f461a7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a5bbadd0f24d5b9c6567f0eebdf63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05aaae2b277d4289972e53f953b1b3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4456b4fe505430ba9fce7743f7570c2",
              "IPY_MODEL_be28b437343a428491eeafcc2b7c4614",
              "IPY_MODEL_355bef7add1e4b7a9db7fb10e790a3ad"
            ],
            "layout": "IPY_MODEL_85b76105295c485296c59f3db1be11b5"
          }
        },
        "c4456b4fe505430ba9fce7743f7570c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2851f4a55aa4ea198259639f29cfa68",
            "placeholder": "​",
            "style": "IPY_MODEL_7415be3e3bfd41469f56dd95e01ea406",
            "value": "100%"
          }
        },
        "be28b437343a428491eeafcc2b7c4614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_325c646358a24cd48c144ccf53b720fe",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35a20f5080914d0b9ae53febb17ba2e6",
            "value": 3
          }
        },
        "355bef7add1e4b7a9db7fb10e790a3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b49a412d144189a0e3a440fbfb4e09",
            "placeholder": "​",
            "style": "IPY_MODEL_232725740aee4da89326362d9e217d7c",
            "value": " 3/3 [00:00&lt;00:00, 114.91it/s]"
          }
        },
        "85b76105295c485296c59f3db1be11b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2851f4a55aa4ea198259639f29cfa68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7415be3e3bfd41469f56dd95e01ea406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "325c646358a24cd48c144ccf53b720fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a20f5080914d0b9ae53febb17ba2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82b49a412d144189a0e3a440fbfb4e09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232725740aee4da89326362d9e217d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09a6661b388741d09aeeaeb8849ef699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c73bc77701dc428aa0a6ce501d636a62",
              "IPY_MODEL_eea26fc2220e4272b283a4d2c8ceb544",
              "IPY_MODEL_d42fd4175ebb4c90994c21daa07bad32"
            ],
            "layout": "IPY_MODEL_47399783b6534f0ca5fe361594d3995d"
          }
        },
        "c73bc77701dc428aa0a6ce501d636a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0c5c42bcf8547618f761e40d3b685a7",
            "placeholder": "​",
            "style": "IPY_MODEL_d640f20fecb6407590e31976a31767c8",
            "value": "100%"
          }
        },
        "eea26fc2220e4272b283a4d2c8ceb544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0889bc8f3c54e459672a69b075e55b2",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99e412d9274a4a8790833544a7e713da",
            "value": 3
          }
        },
        "d42fd4175ebb4c90994c21daa07bad32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_335e517a65c6416ab0f3ac7862b69f3b",
            "placeholder": "​",
            "style": "IPY_MODEL_dde3fc8c78bf48088427e2c55f3b40c5",
            "value": " 3/3 [00:00&lt;00:00, 85.14it/s]"
          }
        },
        "47399783b6534f0ca5fe361594d3995d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c5c42bcf8547618f761e40d3b685a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d640f20fecb6407590e31976a31767c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0889bc8f3c54e459672a69b075e55b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99e412d9274a4a8790833544a7e713da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "335e517a65c6416ab0f3ac7862b69f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde3fc8c78bf48088427e2c55f3b40c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3343be1ef6344700b8ce42f58b31320d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bcc9e4c489b45aba8099225fceede35",
              "IPY_MODEL_268562c403d84d75a41288d73d3e433d",
              "IPY_MODEL_bd7e796a69d54dc1b7a88802e2609774"
            ],
            "layout": "IPY_MODEL_2670ef7bc8f741908ce06cb3866f7394"
          }
        },
        "0bcc9e4c489b45aba8099225fceede35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e5227c216b740ef95181dcfcb7bfc79",
            "placeholder": "​",
            "style": "IPY_MODEL_49278e3cb6f94b469567ce7223a05836",
            "value": "100%"
          }
        },
        "268562c403d84d75a41288d73d3e433d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_666b6b73c542493ead9173c4f60ab091",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_336525c0faca4f6e9415176d8a5a5d94",
            "value": 3
          }
        },
        "bd7e796a69d54dc1b7a88802e2609774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124fd622c7834bfd8c416f31575eb00d",
            "placeholder": "​",
            "style": "IPY_MODEL_62945312282d4973904e6b1d4d23c38d",
            "value": " 3/3 [00:00&lt;00:00, 100.19it/s]"
          }
        },
        "2670ef7bc8f741908ce06cb3866f7394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e5227c216b740ef95181dcfcb7bfc79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49278e3cb6f94b469567ce7223a05836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "666b6b73c542493ead9173c4f60ab091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336525c0faca4f6e9415176d8a5a5d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "124fd622c7834bfd8c416f31575eb00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62945312282d4973904e6b1d4d23c38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f035f6ebd09a409b89462a68a1d505b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9adc44bc12a4ca79d6e40123f9d191a",
              "IPY_MODEL_564f20ec74024cc9a59c03188db72885",
              "IPY_MODEL_429459a861854880bc715b7380cec4ea"
            ],
            "layout": "IPY_MODEL_00325d9e92c54655a12c590606f5fdc4"
          }
        },
        "d9adc44bc12a4ca79d6e40123f9d191a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f8895ed9c24cb0a2627f7b437e591e",
            "placeholder": "​",
            "style": "IPY_MODEL_f1c76536a0b54de78a36a47e6aab4454",
            "value": "Map: 100%"
          }
        },
        "564f20ec74024cc9a59c03188db72885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_141fe415ca35497c8286807f00124311",
            "max": 27997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1b8487926e141ce9ff92d16fc44c4f9",
            "value": 27997
          }
        },
        "429459a861854880bc715b7380cec4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0ba7bf0b9844aba5e32175ebb086bf",
            "placeholder": "​",
            "style": "IPY_MODEL_3a322a26c86b43e48bcbd405ea67cdc8",
            "value": " 27997/27997 [00:24&lt;00:00, 1315.23 examples/s]"
          }
        },
        "00325d9e92c54655a12c590606f5fdc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a3f8895ed9c24cb0a2627f7b437e591e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c76536a0b54de78a36a47e6aab4454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "141fe415ca35497c8286807f00124311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b8487926e141ce9ff92d16fc44c4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c0ba7bf0b9844aba5e32175ebb086bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a322a26c86b43e48bcbd405ea67cdc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6005c3b0d1074da295cadb90dc8428cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cab8f1ba22341f58d71e99f1adec627",
              "IPY_MODEL_dff40ab818de49f58c62b1f8cb5edb55",
              "IPY_MODEL_37fd01bba9e346f8a6cca5ec029470e4"
            ],
            "layout": "IPY_MODEL_664191e5a5b6479cb8d0e63b78653d4b"
          }
        },
        "7cab8f1ba22341f58d71e99f1adec627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86ac1c1562cc40169730b154802cbc9c",
            "placeholder": "​",
            "style": "IPY_MODEL_af0c833c758745cf9aa6ce3bf442a91e",
            "value": "Map:  96%"
          }
        },
        "dff40ab818de49f58c62b1f8cb5edb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe316d5982c04bf198923c4f43dae154",
            "max": 3111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b835bd053884a099420ad1c79cabc89",
            "value": 3111
          }
        },
        "37fd01bba9e346f8a6cca5ec029470e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83a8a3a4e5f54b76b900ee4e4ddd2179",
            "placeholder": "​",
            "style": "IPY_MODEL_f17926dea54e48e9b2a56409e3270918",
            "value": " 3000/3111 [00:02&lt;00:00, 1297.27 examples/s]"
          }
        },
        "664191e5a5b6479cb8d0e63b78653d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "86ac1c1562cc40169730b154802cbc9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0c833c758745cf9aa6ce3bf442a91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe316d5982c04bf198923c4f43dae154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b835bd053884a099420ad1c79cabc89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83a8a3a4e5f54b76b900ee4e4ddd2179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17926dea54e48e9b2a56409e3270918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a06f188efbb40a181f639f68556a510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a7742eda0824b84a64e410e44b4627c",
              "IPY_MODEL_bc5a4a710bcd483b99f5eada6a7c5a5d",
              "IPY_MODEL_5deb8b19a6534a71bad091e73bf2ad73"
            ],
            "layout": "IPY_MODEL_8b1296cba4f141cda2e53bcacf324541"
          }
        },
        "4a7742eda0824b84a64e410e44b4627c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed92c23b43744c8a981728cb5613bbd",
            "placeholder": "​",
            "style": "IPY_MODEL_0ddf7777cc664480a7217eae2091eeb1",
            "value": "Downloading builder script: "
          }
        },
        "bc5a4a710bcd483b99f5eada6a7c5a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c14b99a85c4848984f7b2d0a0616e4",
            "max": 2169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c26ea386df5e456aa9aabea495b788d7",
            "value": 2169
          }
        },
        "5deb8b19a6534a71bad091e73bf2ad73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a921743bf34a4886ebd877311b8bd2",
            "placeholder": "​",
            "style": "IPY_MODEL_21bcdedc917e4d47b32d25c2eed490e9",
            "value": " 5.65k/? [00:00&lt;00:00, 83.3kB/s]"
          }
        },
        "8b1296cba4f141cda2e53bcacf324541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed92c23b43744c8a981728cb5613bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ddf7777cc664480a7217eae2091eeb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4c14b99a85c4848984f7b2d0a0616e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26ea386df5e456aa9aabea495b788d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8a921743bf34a4886ebd877311b8bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21bcdedc917e4d47b32d25c2eed490e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkIAt7QfTfME",
        "outputId": "d9a75b7b-b049-45a8-9877-90584ab200ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.4)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.98\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=90c07b6cc06eff54a065d8ae9c1cb866dd93a5a8e7fc7cc369aae7b8a3017971\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.14.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.1)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=2913459fad83a154d30c571d53264767608f8a327ab2d8ff7815f988af6d4066\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.19.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.14.2\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install sentencepiece\n",
        "! pip install rouge_score\n",
        "! pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import datasets\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "\n",
        "from tabulate import tabulate\n",
        "import nltk\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "DZDYIG2XTo6Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WANDB_INTEGRATION = True\n",
        "if WANDB_INTEGRATION:\n",
        "    import wandb\n",
        "\n",
        "    wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nGuwSyjxTqJc",
        "outputId": "a65a50b0-cf4b-48af-8a36-c23120f2e7e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"sshleifer/distilbart-xsum-12-3\"\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Set model parameters or use the default\n",
        "# print(model.config)\n",
        "\n",
        "# tokenization\n",
        "encoder_max_length = 256  # demo\n",
        "decoder_max_length = 64"
      ],
      "metadata": {
        "id": "zF6j_ukwTteO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYg0cQEyTzIL",
        "outputId": "5352e59c-52e1-402f-bd1b-19d5aa65ade1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.9/dist-packages (0.13.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (3.11.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "eacdf6886bb844eab75188014a249f96",
            "5d9c9aec0395414a9006d02898fe0086",
            "873790b8c839472bbd0c076889269ae0",
            "21e015e1a4f8444880ecfbd0e902a5fb",
            "6ad5c183dcf04d4a95fcf51daf512f94",
            "80dd67c58b6a4ba88422c0876879cddc",
            "12016255d8ed405b9eaf855c920b1406",
            "e4745c7ed766408f85b71056f849ee62",
            "09805fd6793949d8b28bee8c4e52922d",
            "7a58106535ba4293a1031aa5b734d3c3",
            "4520462402a94b69bc4b73c026c597a3",
            "7860458fedce4f7fb9886df67323060c",
            "acf0a6a4419c434eb47676c6fd1fb5c7",
            "9049a08a0cc049e6a1a54e2d1ff7cd69",
            "ec576c8cdfb140e9aaf1bb6ad76f333c",
            "219d3390dca0443f99bf11de4f461a7c",
            "39a5bbadd0f24d5b9c6567f0eebdf63c"
          ]
        },
        "id": "AfqCNDu6T0hs",
        "outputId": "74eb9155-a8a4-4808-9170-0207046af0a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py7zr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkVFj8gdnYV9",
        "outputId": "ee3e4e9d-2855-421e-9e6e-e2127a7023c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting py7zr\n",
            "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting pyppmd<1.1.0,>=0.18.1\n",
            "  Downloading pyppmd-1.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from py7zr) (5.9.4)\n",
            "Collecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.4/390.4 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp39-cp39-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1\n",
            "  Downloading inflate64-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n",
            "Successfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.5 pybcj-1.0.1 pycryptodomex-3.17 pyppmd-1.0.0 pyzstd-0.15.6 texttable-1.6.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def merge_splits(data):\n",
        "  data = datasets.concatenate_datasets([data[\"train\"], data[\"validation\"], data[\"test\"]])\n",
        "  return data\n",
        "\n",
        "data_AMI = merge_splits(load_dataset(\"knkarthick/AMI\"))\n",
        "data_samsum = merge_splits(load_dataset(\"samsum\"))\n",
        "data_dialogsum = merge_splits(load_dataset(\"knkarthick/dialogsum\"))\n",
        "\n",
        "# Take a look at the data\n",
        "for k, v in data_AMI[0].items():\n",
        "    print(k)\n",
        "    print(v)\n",
        "for k, v in data_samsum[0].items():\n",
        "    print(k)\n",
        "    print(v)\n",
        "for k, v in data_dialogsum[0].items():\n",
        "    print(k)\n",
        "    print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810,
          "referenced_widgets": [
            "05aaae2b277d4289972e53f953b1b3e1",
            "c4456b4fe505430ba9fce7743f7570c2",
            "be28b437343a428491eeafcc2b7c4614",
            "355bef7add1e4b7a9db7fb10e790a3ad",
            "85b76105295c485296c59f3db1be11b5",
            "e2851f4a55aa4ea198259639f29cfa68",
            "7415be3e3bfd41469f56dd95e01ea406",
            "325c646358a24cd48c144ccf53b720fe",
            "35a20f5080914d0b9ae53febb17ba2e6",
            "82b49a412d144189a0e3a440fbfb4e09",
            "232725740aee4da89326362d9e217d7c",
            "09a6661b388741d09aeeaeb8849ef699",
            "c73bc77701dc428aa0a6ce501d636a62",
            "eea26fc2220e4272b283a4d2c8ceb544",
            "d42fd4175ebb4c90994c21daa07bad32",
            "47399783b6534f0ca5fe361594d3995d",
            "f0c5c42bcf8547618f761e40d3b685a7",
            "d640f20fecb6407590e31976a31767c8",
            "e0889bc8f3c54e459672a69b075e55b2",
            "99e412d9274a4a8790833544a7e713da",
            "335e517a65c6416ab0f3ac7862b69f3b",
            "dde3fc8c78bf48088427e2c55f3b40c5",
            "3343be1ef6344700b8ce42f58b31320d",
            "0bcc9e4c489b45aba8099225fceede35",
            "268562c403d84d75a41288d73d3e433d",
            "bd7e796a69d54dc1b7a88802e2609774",
            "2670ef7bc8f741908ce06cb3866f7394",
            "3e5227c216b740ef95181dcfcb7bfc79",
            "49278e3cb6f94b469567ce7223a05836",
            "666b6b73c542493ead9173c4f60ab091",
            "336525c0faca4f6e9415176d8a5a5d94",
            "124fd622c7834bfd8c416f31575eb00d",
            "62945312282d4973904e6b1d4d23c38d"
          ]
        },
        "id": "8rWyNUUJT87P",
        "outputId": "215f62ae-1e68-4e57-f3b6-57df19503061"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--AMI-e0c25640a9a75f54/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05aaae2b277d4289972e53f953b1b3e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset samsum (/root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09a6661b388741d09aeeaeb8849ef699"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-caf2f3e75d9073aa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3343be1ef6344700b8ce42f58b31320d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id\n",
            "30\n",
            "dialogue\n",
            "Speaker A: Cool. Do you wanna give me the little cable thing? Yeah. Cool. Ah, that's why it won't meet. Okay, cool. Yep, cool. Okay, functional requirements. Alright, yeah. It's working. Cool, okay. So what I have, wh where I've got my information from is a survey where the usability lab um observed remote control use with um a hundred subjects and then they gave them a questionnaire. Um so it was all about, you know, how people feel about the look and feel of the remote control, you know. What's the most annoying things about remote controls and um the possibility of speech recognition and L_C_D_ screens in remote control. Not that they actually gave me any answers on the L_C_D_ screens, so I should have taken that bit out, but anyway. Um okay, so. What they found is that people don't like how current remote controls are, so you know, definitely you should be looking at something quite different. Um seventy five percent of users find most remote controls ugly. Uh the other twenty five percent have no fashion sense. Uh eighty percent of users would spend more to get um you know, a nice looking remote control. Um current remote controls, they don't match the user behaviour well, as you'll see on the next slide. Um I dunno what zapping is, but Oh, right. But you have that little thing that comes up at the bottom and tells you what's on. Um okay, fifty percent of users say they only use ten percent of the buttons, so that's going back to what, you know, we were saying earlier about, you know, do you need all the buttons on the remote control, they just make it look ugly. Okay? Cool. Um so this is my little graph thing. Mm k Okay, well, I can send it to all of you. What it is is um it's cones, 'cause I thought they'd be more exciting. Um but ooh where's it go? Back. Oh. Oh yes, cool. Okay, I'm gonna stop playing with the little pointy thing. Um okay, so like what it shows is how much things are used relatively and what you can clearly see from that is the thing that's used most is the channel selection. What you can't see is volume selection, it's a little bit higher than all the others. Yeah, so what the graph shows is that, you know, power, channel selection and volume selection are important, and the rest of them, you know, nobody really uses and so that's the the numbers along the top represent their like um their importance, you know, so on a scale of one to ten, how important is that and, you know, channel selection and volume selection are absolutely essential, and the power, well it's not quite so essential, apparently, although I don't understand how it couldn't be, um and everything else, I think, you know, you can forget about having those buttons on the remote control, 'cause they're just not needed, and they're not used. Okay. This is the bit that the email messed up for me and that's what I was fiddling about with at the beginning of the thing. Okay, cool. So um okay, so this is what people find annoying about remote controls. Uh that they get lost, that the uh you know, they're not intuitive and that they're bad for repetitive strain injury. I think if you're watching enough T_V_ to get repetitive strain injury from um you know, watching T_V_, then that's the least of your problems, but you know, it's up there. Um that yeah. Okay, so um I mean the the R_S_I_ thing would be that, like when you have the computer keyboards and you keep your wrists up would be something that encourages you want something with an ergonomic t design that encourages good use of the remote control and you know, not straining your wrists watching T_V_. Yes. Okay, cool. Right, um sorry this is pink because I was copying and pasting the table, and I didn't have time to white it out again. Um okay, but that shows how people whether they would pay more for voice recognition software. So you can see from that that, you know, younger people to the age of thirty five are quite likely to pay quite a lot more f well quite are quite likely to pay more for voice recognition software, whereas as people get older, they're a bit more sceptical about it and they're less willing to to try it. Um so clearly voice recognition is something to think about, but um you know I d I do wonder how well that would work given that a T_V_, you know, tends to be people talking and um, you know, how are you going to stop it from just flipping channels whilst watching T_V_. Um okay? Cool. Um okay, so these are my personal preferences. So you have sleek, stylish, sophisticated, you know, so something that's, you know, a bit cool. Um you know, functional, so it's useful, but minimalist. Um there's a there's an important thing that, you know, people use when, you know, when you're filling up your home, you know, a lot of people fill up their home with bits of crap, basically, you know, and you've got all this stuff, and you're just like, what the hell is that, who is ever gonna use it? You know, so things should either be functional or beautiful or preferably both, so I think we need to aim for both. Um okay, then a long battery life, like you were talking about earlier and um, you know, I was thinking that solar power would be quite cool because, you know, your remote control just sits there, and you could just sit it in the sunshine and save the environment a bit. Um and then like a locator, so you know, kind of like you have for a mobile phone or not a mobile phone Yeah, that's it, you know. I know, it's weird. My flatmate and I were talking about this on the way into uni this morning and I was like I need to get one for everything. So yeah, so maybe something where you clap and then it beeps, something a kind of sound that you don't often hear on the T_V_, you know, 'cause you don't want your remote control beeping every five minutes, 'cause you you'd then deliberately lose it by throwing it out the window or something. So okay? Cool. That's me. Cat's. Ca. Yeah, I mean that's the thing is that it didn't say in the survey, you know, whether, you know, these are the people that will pay more for a more stylish remote control, but I'm assuming, you know, yes. Well, that's when you go to uni, isn't it? So, you know Yeah. Oh, I've unplugged it. Do you want me to Yeah. Seventy six point three percent. Yeah. Yeah, I kn I mean I know what you're saying about the fifteen to twenty five year olds, but I mean it has been proven that that people of that age group have a higher disposable income because they don't have like I mean, you know, if you're at university, you're paying your rent, but you don't have a mortgage, you don't have a life insurance policy, you don't normally have a car, yeah, so. You're still learning to drive actually, so that just costs more than a car, but yeah. Um so I mean like it is an age group to target, really, I think. No, I mean that's what, that's like fifteen Pounds? You know, I think Yeah, I d I don't know many people without a T_V_. We didn't have a T_V_ last year, and everyone thought we were off our heads, you know. Yeah, I d well we've we've got quite a d decent T_V_. Yeah. I think I think the fact that, you know, ninety one point two percent of fifteen to twenty five year olds are saying yes, I would pay more for a voice recognition remote control, does say quite a lot really. You know, so I mean that and the disposable income and I don't think it's something to ignore, you know. Is not a massive difference, you know. No, do totally. You do have it in your mobile phone though, don't you? Because you have like I mean every mobile phone now has like call this person and it calls them. I don't know. Yeah. S so y you'd maybe need a code word. Do you know what I mean? So like when you say change, except that's being said quite a lot on T_V_, so maybe like, you know, remote. I mean how often do people say remote on T_V_? Although I only watch Charmed, so really I wouldn't know but like so you'd just say remote five, you know, remote ten, remote one two nine. I don't think there's a lot of uh voice recognition remote controls. Yeah, that would be another way to do it. Yeah, but then the code word would be even more important, because I mean Sky advertise on every channel, don't they, you know, so then it would be you'd be watching Charmed, and then the Sky advert would come on and it would change to Sky. Yeah, yeah, and that would be really annoying. Yeah. Do you not think that defeats the object of having voice recognition on a remote control though? Yeah, you know, so you have to have the remote control. It's more like if you lost it and it's down the sofa sometime, you can yell at it and it'll just change it, you can look for it later, yeah. Yeah, yeah, I suppose nearer to you but a b like if you have surround sound then Yeah. Yeah, 'cause it's it's quite important that you don't lose the the bit to locate the remote control. Yeah, definitely, yeah. Oh, so y you want our um PowerPoint presentations in there, hey? Okay. There you go. But is everyone's called functional requirements? Okay, so that's good. That's me done. Okay, cool.\n",
            "Speaker B: No. Mm. Um um wi on on a what? Oh project project documents, yeah, yeah, yeah, okay. Oh okay, yeah. Yes, I think so. Yeah, the last minute, yeah, yeah. Yeah. Um Okay. Hmm. Mm. Okay, yeah, afterwards, yeah, okay. Thanks. I think we need like some general discussion at the end probably. Yeah. Yeah, I think since since we were discussing some um design issues then I I I would like to continue okay, yeah. Thanks. Oh i Okay, I hope wait. Should it just There's just nothing. Oh right, right, right, um Okay. Nothin okay, something is coming up. No signal? Why? Oh. My my computer went blank now. Adjusting. But I don't see anything I don't see anything on my computer now. This is the problem, but Um. Uh now it's okay. No? No. Oh okay. Okay, that's fine, that's good. Okay, let's start from the beginning. So I'm going to speak about technical functions design uh just like some some first issues that came up. Um 'kay, so the method I was um adopting at this point, it's not um for the for the whole um period of the um all the project but it's just at th at this very moment. Um uh my method was um to look at um other um remote controls, uh so mostly just by searching on the web and to see what um functionality they used. And then um after having got this inspiration and having compared what I found on the web um just to think about what the de what the user really needs and what um what the user might desire as additional uh functionalities. And yeah, and then just to um put the main function of the remote control in in words. Um so the findings uh were um that the main function of the remote control is is just sending messages to the television set, so this quite straightforward. And uh w some of the main functions would be switching on, switching off, uh then the user would like to switch the channel um for example just m changing to the next channel to to flip through all all of the possible channels, or then mm uh the other possibility would be that um she might just want to choose one particular channel, so we would need the numbers. And and also the volume is very important. Um um I als okay. 'Kay. Um um among the findings I found that m m most of the curr mm presently available remote controls also include other mm functionalities um in their design, like operating a V_C_R_, but they don't seem to be able to deal with D_V_D_ players, but then there are surely there are many other functionali functions that could possibly be added to them, but according to the last minute update um actually um we do not want to have all this complicated functions added to our design. So my personal preferences would be uh to keep the mm the whole remote control small um just like the physical size. And then it must be easy to use, so it must follow some conventions um like whereabouts you find the on off button and maybe the colour tends to be red or something. Um then yeah, the must-have buttons would be on off and then the channel numbers and then um the one that allows us to go to the next or the previous channel, and then volume has to be there. But then um other functionalities um could be just uh there could be a menu button and you could change things on the screen then, um for example brightness and mm similar functions could be just um done through the menu. And yeah, the last question I had about whether we wanted to incorporate n uh more functionalities, the answer was already no because of the last minute update. So at the for the time being that's uh that's all. If you have questions Yeah, and also it's it's um other question is uh because there are so many different And there are so many different things that could possibly be included because besides video and D_V_D_ there are the mm um video C_D_s and whatever, so it might be problematic to to choose between all these possible things. Um well, I think the buttons are still mm kind of the most um easy for the user to use, I mean um what other options would you have? A little screen or something, but this would be really kind of I think a lot of learning for the user and and I mean the user just wants to get um get a result um quickly, not to spend time in like um giving several orders um I dunno. I think I th I would I would think the put the buttons, but if if you have other mm proposals um. Yeah. Yeah. Mm-hmm. Yep. Uh am I going in the right direction? No. Wait. Okay, here it comes. Okay, here you are. Um that's very good, very interesting. Mm-hmm. Yeah. Yeah, you share a television or something that yeah. It was seventy something, yeah, yeah. Yeah this this is not unaffordable, but the problem is whether people need it, whether they do have a T_V_ to use its full Yeah. Common, the students yeah, yeah. The s the stu yeah, and the remote control might not yeah, it might not even function with the old T_V_. Yeah, we're still yeah. Or w maybe we can just kind of uh uh Yeah, but at the same time I think maybe we can we can just decide to to have both of these groups as our target, because actually I mean they're all still re young people. Yeah. Yeah. Yeah. Yeah. An Yeah. Yeah. Yeah but uh um Yeah, yeah sure, yeah, yeah. Yeah. Yeah, w well now the v the voice recognition if if it works wonderfully w we could possibly do away with all buttons, but I think this is not really the right moment yet, because people are just so used to buttons and um, yeah it's it's kind of safer, so we we need both, so the voice recognition would be just an extra, it wouldn't really reduce the size of the remote. Yeah but m but on the other hand, remote control isn't as close to you you probably might just just uh speak into it and and the T_V_ would be already further away, so it might not pick up the other things coming from there. Yeah, but then the remote control I think I mean um the idea is kind of it's it's not that it's sitting there on on top of the television, because then you could already yell at the television and you wouldn't you you wouldn't need the remote control, so the remote control is still something you keep n near yourself. Yeah, yeah, yeah. No, but I I I was just defending the the fact why why we want to keep the remote control close to us, a and uh not to yell at it from the distance. Okay. Oh yeah, yeah. Okay, yeah, mm-hmm. The major ones, yeah. Mm-hmm. Mm-hmm. Yeah. Did you find it? It's just yeah, yeah. Oh so so we'll just put them i there, we we yeah, w we won't even okay. Yeah. Yeah. Uh something conceptual, yeah. Hmm. Sorry, but um the next meeting um are we going to have it um right after lunch or shall we prepare our To prepare, okay, yeah, that's good. Okay. Cool. Okay, see you.\n",
            "Speaker C: Mm. You said uh targ target groups, what does that mean? Uh okay, 'kay. So are Okay. Alright. I can go first, yeah. Right. Um so f from the Right sure. Uh okay. So n uh with uh with regard to the uh working design of this uh uh remote control uh I've identified um a few basic uh components of the remote and uh se uh from the design, functional design perspective um w I c we can now uh know wha what exactly the components are and how how they work together with each other. So this is the method that uh I'll mostly be following in my um in my uh role. Um the identification of the components, uh and uh since since I'm dealing only with the technical aspects, I would need feedback from the marketing person uh and uh from the user interface person. Uh we'll then integrate this into the product design at a technical level and uh basically update and come up with a new design, so it's a cyclical process. Okay, so these were the basic findings from today. The last three bullets have been integrated from uh the last minute uh email. Uh I just quickly jotted them down. Um so basically uh the as I told you the identification of how the remote control works and what are the various parts to it uh and what are the different processes um and how the parts uh communicate with each other. Um okay, so e the mee email said that teletext is now outdated, so we need to do away with that functionality of the remote control. Um also uh the remote control should be used only for television, because incorporating other features um makes it more comp complex. And the reason why teletext is outdated because uh of internet and uh the availability of internet over television. How however, our our remote control would only be dealing uh with the the use for television, in order to keep things simple. Um also the management wants that um our design should be unique uh it so it should incorporate um colour and the slogan uh that our company um has it as its standard. Okay, so he he here is a functional overview of the remote control. Um there's basically an energy source at the heart uh which feeds into the chip and the user interface. The user interf interface communicates with the chip, so I'll basic go over to the Okay. So if uh if this is our energy source and this is a cell, uh it communicates uh it feeds energy into the into the chip, which basically finds out h uh how how to do everything. There is a user interface here. So whe when the user presses a button, it feeds into the chip and the chip then generates a response and takes the response to an infrared terminal, um which then so the output of the chip is an infrared bit code, which is then communicated to the remote site, which h has an infrared receiver. Um the there can be uh a bulb here or something to indicate whether the remote is on or communicating. Um so these are the essent so a all the functionality of the remote control, whatever new functions that we need to do, um make the chip more complicated uh and bigger, basically. Okay. Um so i in my personal preferences um I'm hoping that we can ke keep the design as simple and clear as possible. This would uh help us uh to upgrade our technology at a future point of time. And uh also if we can incorporate uh the latest features in our chip design, so that our um uh remote control does not become outdated soon and it's compatible with mot most uh televisions. That's about it. So anything that you would like to know or No, I don't have any idea about what each component costs. Um yeah. Anything else? Yeah. Certainly, yeah. So so tha yeah, we definitely need to operate within our constraints, but um unfortunately I I do not have any data, so uh I just identified the functional components for that. Yeah, okay. Yeah. Mm 'kay. I it'll take some time. Oh, there it is, yeah. It'll come up, it um uh no signal. Yeah yeah, it says something now, adjusting Okay. Oh, that's strange. Okay. And one more time. Mm. Sorry, cou could you go back for a second? Uh switching on off channel, uh volume, okay, that's great. So in the u user interface requirements uh uh uh we we have been able to identify what are the basic buttons that we do want. Um but um so so at this stage, uh how we go about implementing those button we will not identify or I mean in we can completely do away with buttons and uh have some kind of a fancy user interface or something like that. But uh is is there any uh uh any thoughts on that? Right. Yeah, and it'll make the costs yeah. Right. Uh I think the co costs will also play a big role when we come to know about them. So well we can probably wait until t we have more knowledge on that. Uh i if the if the costs allow, we can have like an L_C_D_ display and uh with um because we do want something fancy and fashionable as well. So yeah? Cool. try to press oh, okay, yep. Mm. Right. Mm-hmm. Mm. Right. Mm-hmm. Hmm. Right. Mm. Mm. Mm. Some kind of a ring, some Right. Hmm. Okay, that's great, thanks. Mm. I think one of the very interesting things that came up in um uh Ka Kate Cat Cat's uh presentation was um uh this this issue of uh uh like voice recognition being more popular with uh younger people. So if we need to have a target group um then uh I think as far as the m motto of our company is concerned, if we want to have something sleek and uh you know, good looking uh we are better off targeting a younger audience then um you know, people who are comparatively elderly. Um. Right. Right. Bu but but the survey did say that f things like voice recognition are more popular with them, so if you want to put in something stylish, then uh th it'll certainly be more popular with this i ye with the younger people as compared to older people, yeah. Right, and Right. Mm. Right. But uh still, if if you can go back to that slide and uh, how popular was it? Oh, oh, okay. That's alright, if you can just look it up on your computer, wh uh um people between twenty five to thirty five, uh how popular was so it was sti still still quite popular amongst them. So even they are seventy six percent, is that high amount? Alright. Yeah. So you're more likely to b Yeah. Yeah. Mm. Bu but even even in the case of twenty five to thirty five it's quite popular, right? So mm uh are are are Mm. Mm. Um I was having a a general outlook on um m most like sophisticated features, but voice recognition itself I'm not very sure about, because one of the p uh things that Cat pointed out was uh uh how do we go about implementing it? Uh and uh Yeah. But how frequently do we use it anyway and um uh h ho how good is it, you know uh voice recognition softwares are still quite uh Yeah. Right. Right. Okay. O Right. Mm. Right. Yeah. Okay, so it seems like a feasible thing to implement uh for for a limited yeah. Mm. W What uh Mm. What wh uh what I was thinking is that there is this uh separation between what the channels are on T_V_ and how they are numbered on the remote control. If we can do with away with that, our product can be really popular uh in the sense that uh a person can say, I want to watch uh I_T_V_ one instead of saying that I want to go onto channel number forty five. Yeah, so if uh if something like that can be incorporated, some kind of Mm-hmm. Alright. Yeah, that's Right. Mm. Mm yeah and it might become very difficult from a distance for the television to understand what you're saying because of the noise factor for the remote control being cl I mean it'll it'll mm. Yeah. Mm. So uh wh another thing uh that can be used is that uh there can be a beeper button on the T_V_, so you can go and press that button and um and the remote control, wherever it is, it'll beep, so we we can probably come to know where it is. Right, yeah, yeah, yeah. Alright, yeah. Right. Okay. So where exactly is this i Ah, okay. Yeah. Yeah, yeah in that one, right yeah. No. Right. I guess I'll find out. Wha what was it again that I was supposed to look into? Con components, oh.\n",
            "Speaker D: All hooked up. Okay, so now we are here at the functional design meeting. Um hopefully this meeting I'll be doing a little bit less talking than I did last time 'cause this is when you get to show us what you've been doing individually. The agenda for the meeting, I put it in the sh shared documents folder. I don't know if that meant that you could see it or not. Did anyone? No. Oh well. Um I'll try and do that for the next meeting as well so if you check in there, there's a shared project documents folder. Um and it should be in there. Project documents, yeah. So I'll put it in there. Is it best if I send you an email maybe, to let you know it's there? Yep. I'll do that next time. Um I'll act as secretary for this meeting and just take minutes as we go through, and then I'll send them to you after the meeting. The main the main focus of this meeting is your presentations that you've been preparing during the time, so we'll go through each of you one by one. Um then we need to briefly discuss the new project requirements that were sent to us. I just sent at the last minute, I'm sorry about that, but we can see how that affects what you were you were doing. Um and then we need to, by the end of the meeting come to some kind of decision on who our target group's going to be and what the functions of the remote control that's the the main goal is to come up with those two things, target group and functions of the remote control. And we've got forty minutes to do that in. So I would say yeah? As uh who it is that we're going to be trying to sell this thing to, yeah. So we need to yeah, we need to have a fairly defined group that that we want to focus on and then look at the functions um of the dem remote control itself. So with that I think it's best if I hand over to you. Does anyone have a preference for going first? You wanna go first? Okay, so we need to unplug my laptop and plug in yours. I assume we just pull it out? Just before you start, to make it easier, would you three mind emailing me your presentations? Once we you don't have to do it now but when once you go back, just so that I don't have to scribble everything down. Hmm. Mm-hmm. Okay. Do you have any um i idea about costs at this point? Br Okay. 'Cause that's something to consider, I guess, if we're if we're using more advanced technology, it might increase the price. Yeah. That's fine. Are there any more questions, or shall we just skip straight to the next one and then we can discuss all of them together at the end? Yeah, I think that will do. Okay, so do you want to Yes, shall shall we pull this up? I think that has to come out of there. Yeah. Yeah, I thought those last minute things, they're gonna hit you the worst. It ta takes a little Oh, and have you you need to then also press on yours, function F_ eight, so the blue function key at the bottom and F_ eight. Now it's coming, computer no signal. Maybe again? Okay, adjusting. There we go, there we go. Oh, if you press if you press function and that again there's there's usually three modes, one where it's only here, one where it's only there, and one where it's both. Okay, so one more time. Should yeah just wait for a moment, adjusting. Okay. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Yeah. If I mean that was the the directive that came through from management, but if we had a a decent case for that we really think it's important to include video and D_V_D_, I could get back to them and see. It's w it's just whether it's worth arguing about. Mm-hmm. Yeah. Mm-hmm. Okay. Are there any questions for clarification of Maarika before we go on to the next one? Mm-hmm. Mm. Mm. Mm-hmm. Sure, we can discuss that maybe after the next one. Do you want to yeah. Oh, I'm getting hungry. You set? Uh we need to do the function key thing so that it comes up on here. Hello. Is it plugged in prop it's working? Okay. Excellent. It's um switching between channels, sort of randomly going through. Mm. Ooh, that's a bit difficult to see. If you explain it to us it'll be fine. Yeah. I liked the, I liked the litt ooh come back. No. Okay. Mm-hmm, that's the next one along, yeah? Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. The remote control. Mm-hmm. That's alright. Mm. Keys and things like that, yeah. Whistle and it screams at you, yeah. Mm-hmm. That's you, excellent. Um. I'm just gonna tick yes. So, we've got about ten, fifteen minutes to discuss Mm-hmm. Yeah. Mm-hmm. Yeah. Then again I guess the th where it was most popular was the fifteen to twenty five bracket and the I don't know how often they're buying televisions. Yeah, but you don't have much money, generally. I would've thought it's it's more that twenty five to thirty five, when people are really moving out and they've got their first job and they want their nice toys and O oh it's on sorry, we unplugged it. Here, let me Yeah. Mm-hmm. Yeah. Yeah, they've got no commitments and usually not a car and all of those things. Kids. Yeah. Yeah, and if we're if we're talking twenty five Euros as a price, that's not unaffordable, even for young people. Yeah. Yeah. But do they But the T_V_s are often kind of someone's old T_V_ that's blah blah and be a bit strange to have a fancy rome remote. Mm. Yeah. Yeah. Yeah. Yeah. Yeah, if we ta if we take fifteen to thirty five, but that then does imply that we should try and incorporate voice recognition. Is that gonna have a an implication for the technical specs? Mm-hmm. Yeah. Yeah. With um but with a T_V_ remote it's gonna be quite limited if we're t saying the main things people want to do is on off channel five, louder, tha that should be relatively simple. Mm. Yeah. Mm-hmm. Yeah, but maybe if you wanna look into that just to just to check. Um, so if we go for the the fifteen to thirty five age group and then of course we're going to get th anyone who's older than thirty five who wants to look young and hip and trendy and has the money, then they'll they'll still go for the same advertising. Yeah, I think we need both. Yeah. Mm. Uh-huh. Uh-huh. So that if that was in the the voice recognition, that would be great. Yeah. Yeah. Watch Sky and yeah. Mm-hmm. But that's definitely a possibility. Yeah. So that you can yell at it, yeah. Yeah. Alright. Mm. Yeah. Yeah. Yeah. Yeah. Mm-hmm. That's but then if you're buying the remote separately, but y you could have something, but i if it was something that you could like stick onto the T_V_ or something, some like a two p if you bought it in a two part pack, so one part attaches to the T_V_. The l Well that's right, but it solves the problem of having different noises. Yeah. Okay, I think we're gonna have to wrap this up um. But if we go away with that that kind of general um specification in mind that we're looking at fifteen to thirty five year olds, we want it to look simple, but still have the buttons so it's easy to use, but only those key buttons, the major buttons and then one sort of menu one, and then voice recognition included as an option um but that obviously needs a little bit more working out as to whether it's really feasible and some of those problems we were mentioning um. What we have to do now is to go back to our little places, complete our questionnaire and some sort of summarisation, which y you'll get immediately by email. Send me your presentations so that I can use them to make the minutes, and then we've got a lunch break and after lunch we go back to our own little stations and have thirty minutes more work. Um I'll put the minutes in that project documents folder, but I'll send you an email when I do it, so that you know. It should be on your desktop, so on the yeah. So I'll put it I'll put them there as soon as I've written them. Yeah, and email them round. Yeah, that would be great. Oh yeah, put them in there. Yeah, then you don't have to email them. No, they're all called something slightly different. Technical requirements and something something, yeah. So, if you put them in there, we'll all be able to see them and refer to them if we need to. Um as to where we're going from here, you're going to look at the components concept. Yeah? Whatever that means. Yeah. You'll be looking you'll be looking at the user interface concept, on something conceptual and you're watching trends to see how we go and surely voice recognition'll fall off the map or something that um we'll keep keep our options op hmm? Components, yeah. No, we have we have after lunch we have thirty minutes to ourselves to prepare, so that's fine, w before lunch we just have to complete the questionnaire and some sort of summary. Okay? Right on time. Okay, so you can I guess we'll see you for lunch in a sec?\n",
            "summary\n",
            "The project manager opens the meeting by stating that they will address functional design and then going over the agenda. The industrial designer gives his presentation, explaining how remote controls function and giving personal preference to a clear, simple design that upgrades the technology as well as incorporates the latest features in chip design. The interface specialist gives her presentation next, addressing the main purpose of a remote control. She pinpoints the main functions of on/off, channel-switching, numbers for choosing particular channels, and volume; and also suggests adding a menu button to change settings such as brightness on the screen. She gives preference to a remote that is small, easy to use, and follows some conventions. The group briefly discusses the possibility of using an LCD screen if cost allows it, since it is fancy and fashionable. The marketing expert presents, giving statistical information from a survey of 100 subjects. She prefers a remote that is sleek, stylish, sophisticated, cool, beautiful, functional, solar-powered, has long battery life, and has a locator. They discuss the target group, deciding it should be 15-35 year olds. After they talk about features they might include, the project manager closes the meeting by allocating tasks.\n",
            "id\n",
            "13818513\n",
            "dialogue\n",
            "Amanda: I baked  cookies. Do you want some?\r\n",
            "Jerry: Sure!\r\n",
            "Amanda: I'll bring you tomorrow :-)\n",
            "summary\n",
            "Amanda baked cookies and will bring Jerry some tomorrow.\n",
            "id\n",
            "train_0\n",
            "dialogue\n",
            "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
            "#Person2#: I found it would be a good idea to get a check-up.\n",
            "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
            "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
            "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
            "#Person2#: Ok.\n",
            "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
            "#Person2#: Yes.\n",
            "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
            "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
            "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
            "#Person2#: Ok, thanks doctor.\n",
            "summary\n",
            "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n",
            "topic\n",
            "get a check-up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_AMI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHsvwrodVzL2",
        "outputId": "37a37716-c94a-47e1-d29e-4213a7dc3418"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'dialogue', 'summary'],\n",
              "    num_rows: 279\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(example):\n",
        "    return {\n",
        "        \"dialogue\": example[\"dialogue\"],\n",
        "        \"summary\": example[\"summary\"],\n",
        "    }\n",
        "\n",
        "\n",
        "data_AMI = data_AMI.map(flatten, remove_columns=[\"id\"])\n",
        "data_samsum = data_samsum.map(flatten, remove_columns=[\"id\"])\n",
        "data_dialogsum = data_dialogsum.map(flatten, remove_columns=[\"id\", \"topic\"])\n",
        "\n",
        "dataset = datasets.concatenate_datasets([data_AMI, data_samsum, data_dialogsum])\n",
        "\n",
        "train_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.1).values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXy2TiIyULJF",
        "outputId": "34c8c29b-3990-46c3-ce7f-9efb83601f67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--AMI-e0c25640a9a75f54/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a528692253175ed4.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e/cache-fc768b42dfa7a15b.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-caf2f3e75d9073aa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-91f93b70e041b9ff.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMC2Zdy0oI07",
        "outputId": "0945ef2c-44a8-4c2d-8474-d5466b082f58"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['dialogue', 'summary'],\n",
              "    num_rows: 31108\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_txt[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXILDJYeWivy",
        "outputId": "f567bb3c-f795-4b30-b311-aaf35f125f7b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dialogue': \"#Person1#: Are you going to leave school at the end of the term? \\n#Person2#: Yes, I am. \\n#Person1#: What are you going to do? \\n#Person2#: I'm going to be a clerk. \\n#Person1#: What does a clerk do? \\n#Person2#: He works in an office. He writes letters and reports , and he types. \\n#Person1#: I want to be a vet. \\n#Person2#: A-what? \\n#Person1#: A vet-a veterinary surgeon. \\n#Person2#: Good gracious ! What's that? \\n#Person1#: A vet's a man who takes care of sick animals. He's an animal doctor. \\n#Person2#: I once read a story ahout a person who talked to animals. It was very interesting. \",\n",
              " 'summary': '#Person2# is going to leave school and become a clerk. #Person1# wants to be a vet.'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
        "    source, target = batch[\"dialogue\"], batch[\"summary\"]\n",
        "    source_tokenized = tokenizer(\n",
        "        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch\n",
        "\n",
        "\n",
        "train_data = train_data_txt.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=train_data_txt.column_names,\n",
        ")\n",
        "\n",
        "validation_data = validation_data_txt.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=validation_data_txt.column_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "f035f6ebd09a409b89462a68a1d505b8",
            "d9adc44bc12a4ca79d6e40123f9d191a",
            "564f20ec74024cc9a59c03188db72885",
            "429459a861854880bc715b7380cec4ea",
            "00325d9e92c54655a12c590606f5fdc4",
            "a3f8895ed9c24cb0a2627f7b437e591e",
            "f1c76536a0b54de78a36a47e6aab4454",
            "141fe415ca35497c8286807f00124311",
            "c1b8487926e141ce9ff92d16fc44c4f9",
            "7c0ba7bf0b9844aba5e32175ebb086bf",
            "3a322a26c86b43e48bcbd405ea67cdc8",
            "6005c3b0d1074da295cadb90dc8428cf",
            "7cab8f1ba22341f58d71e99f1adec627",
            "dff40ab818de49f58c62b1f8cb5edb55",
            "37fd01bba9e346f8a6cca5ec029470e4",
            "664191e5a5b6479cb8d0e63b78653d4b",
            "86ac1c1562cc40169730b154802cbc9c",
            "af0c833c758745cf9aa6ce3bf442a91e",
            "fe316d5982c04bf198923c4f43dae154",
            "2b835bd053884a099420ad1c79cabc89",
            "83a8a3a4e5f54b76b900ee4e4ddd2179",
            "f17926dea54e48e9b2a56409e3270918"
          ]
        },
        "id": "3fjrYExXW0-m",
        "outputId": "563eb936-1932-4821-9efd-da3d8221610d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/27997 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f035f6ebd09a409b89462a68a1d505b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3111 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6005c3b0d1074da295cadb90dc8428cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['input_ids'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lHe4B4XW8Of",
        "outputId": "fcffac61-706f-4d15-8186-3ef13efed2fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 6319,\n",
              " 47,\n",
              " 450,\n",
              " 128,\n",
              " 28605,\n",
              " 19685,\n",
              " 35661,\n",
              " 50121,\n",
              " 50118,\n",
              " 35689,\n",
              " 35,\n",
              " 1560,\n",
              " 289,\n",
              " 10950,\n",
              " 15,\n",
              " 10,\n",
              " 10348,\n",
              " 2946,\n",
              " 116,\n",
              " 50121,\n",
              " 50118,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 235,\n",
              " 328,\n",
              " 50121,\n",
              " 50118,\n",
              " 35689,\n",
              " 35,\n",
              " 686,\n",
              " 4,\n",
              " 2860,\n",
              " 822,\n",
              " 50121,\n",
              " 50118,\n",
              " 8138,\n",
              " 282,\n",
              " 279,\n",
              " 35,\n",
              " 14011,\n",
              " 527,\n",
              " 50121,\n",
              " 50118,\n",
              " 8138,\n",
              " 282,\n",
              " 279,\n",
              " 35,\n",
              " 38,\n",
              " 17672,\n",
              " 190,\n",
              " 4744,\n",
              " 402,\n",
              " 101,\n",
              " 14,\n",
              " 50121,\n",
              " 50118,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 1560,\n",
              " 289,\n",
              " 10950,\n",
              " 10889,\n",
              " 11,\n",
              " 42,\n",
              " 774,\n",
              " 328,\n",
              " 50121,\n",
              " 50118,\n",
              " 35689,\n",
              " 35,\n",
              " 11380,\n",
              " 6,\n",
              " 2098,\n",
              " 328,\n",
              " 50121,\n",
              " 50118,\n",
              " 35689,\n",
              " 35,\n",
              " 37,\n",
              " 685,\n",
              " 59,\n",
              " 291,\n",
              " 14091,\n",
              " 8,\n",
              " 1006,\n",
              " 66,\n",
              " 543,\n",
              " 50121,\n",
              " 50118,\n",
              " 35689,\n",
              " 35,\n",
              " 38,\n",
              " 1166,\n",
              " 1437,\n",
              " 50121,\n",
              " 50118,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 37,\n",
              " 18,\n",
              " 6967,\n",
              " 269,\n",
              " 50121,\n",
              " 50118,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 3378,\n",
              " 818,\n",
              " 1146,\n",
              " 6941,\n",
              " 7,\n",
              " 127,\n",
              " 2473,\n",
              " 50121,\n",
              " 50118,\n",
              " 8138,\n",
              " 282,\n",
              " 279,\n",
              " 35,\n",
              " 38,\n",
              " 101,\n",
              " 123,\n",
              " 350,\n",
              " 50121,\n",
              " 50118,\n",
              " 8138,\n",
              " 282,\n",
              " 279,\n",
              " 35,\n",
              " 8,\n",
              " 37,\n",
              " 3829,\n",
              " 11145,\n",
              " 17160,\n",
              " 18461,\n",
              " 642,\n",
              " 328,\n",
              " 50121,\n",
              " 50118,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 4832,\n",
              " 495,\n",
              " 50121,\n",
              " 50118,\n",
              " 8138,\n",
              " 282,\n",
              " 279,\n",
              " 35,\n",
              " 37,\n",
              " 300,\n",
              " 65,\n",
              " 25,\n",
              " 10,\n",
              " 1455,\n",
              " 50121,\n",
              " 50118,\n",
              " 35689,\n",
              " 35,\n",
              " 5373,\n",
              " 1114,\n",
              " 50121,\n",
              " 50118,\n",
              " 35689,\n",
              " 35,\n",
              " 53,\n",
              " 3035,\n",
              " 50121,\n",
              " 50118,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 38,\n",
              " 2145,\n",
              " 77,\n",
              " 24,\n",
              " 21,\n",
              " 15,\n",
              " 5,\n",
              " 340,\n",
              " 50121,\n",
              " 50118,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 14,\n",
              " 693,\n",
              " 54,\n",
              " 5798,\n",
              " 5,\n",
              " 1086,\n",
              " 631,\n",
              " 50121,\n",
              " 50118,\n",
              " 104,\n",
              " 4360,\n",
              " 3677,\n",
              " 1334,\n",
              " 35,\n",
              " 79,\n",
              " 18,\n",
              " 5373,\n",
              " 50121,\n",
              " 50118,\n",
              " 8138,\n",
              " 282,\n",
              " 279,\n",
              " 35,\n",
              " 4832,\n",
              " 495,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n",
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "\n",
        "metric = datasets.load_metric(\"rouge\")\n",
        "\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract a few results from ROUGE\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "6a06f188efbb40a181f639f68556a510",
            "4a7742eda0824b84a64e410e44b4627c",
            "bc5a4a710bcd483b99f5eada6a7c5a5d",
            "5deb8b19a6534a71bad091e73bf2ad73",
            "8b1296cba4f141cda2e53bcacf324541",
            "1ed92c23b43744c8a981728cb5613bbd",
            "0ddf7777cc664480a7217eae2091eeb1",
            "e4c14b99a85c4848984f7b2d0a0616e4",
            "c26ea386df5e456aa9aabea495b788d7",
            "a8a921743bf34a4886ebd877311b8bd2",
            "21bcdedc917e4d47b32d25c2eed490e9"
          ]
        },
        "id": "-R5cL3PyW_TX",
        "outputId": "c9fe116e-a7c6-4a65-9dc7-9eadffda7b27"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-16757958f45a>:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric(\"rouge\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a06f188efbb40a181f639f68556a510"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "IIuPsnICXEK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"results\",\n",
        "    num_train_epochs=1,  # demo\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=4,  # demo\n",
        "    per_device_eval_batch_size=4,\n",
        "    # learning_rate=3e-05,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    label_smoothing_factor=0.1,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=20,#50,\n",
        "    save_total_limit=3,\n",
        "    push_to_hub=True\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=validation_data,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "FTMMuBMKXFO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560e828f-ec9b-455e-ab94-91c44bd51690"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning https://huggingface.co/jainr3/results into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/jainr3/results into local empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if WANDB_INTEGRATION:\n",
        "    wandb_run = wandb.init(\n",
        "        project=\"bart_AMI\",\n",
        "        config={\n",
        "            \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
        "            \"learning_rate\": training_args.learning_rate,\n",
        "            \"dataset\": \"AMI\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%H%M%S\")\n",
        "    wandb_run.name = \"run\" + \"_\" + current_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "N4mrlOeEXHal",
        "outputId": "3d35cd8d-93a0-4832-a5b8-157715125f60"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjainr3\u001b[0m (\u001b[33mrahul96jain\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230415_163619-f5d7aliv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rahul96jain/bart_AMI/runs/f5d7aliv' target=\"_blank\">ruby-energy-4</a></strong> to <a href='https://wandb.ai/rahul96jain/bart_AMI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rahul96jain/bart_AMI' target=\"_blank\">https://wandb.ai/rahul96jain/bart_AMI</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rahul96jain/bart_AMI/runs/f5d7aliv' target=\"_blank\">https://wandb.ai/rahul96jain/bart_AMI/runs/f5d7aliv</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "nHt3G6d6XORh",
        "outputId": "8afd211a-bc45-4515-b856-3867c3136fdd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='778' max='778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [778/778 06:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 5.517122745513916,\n",
              " 'eval_rouge1': 18.2963,\n",
              " 'eval_rouge2': 3.6601,\n",
              " 'eval_rougeL': 14.0132,\n",
              " 'eval_rougeLsum': 15.3526,\n",
              " 'eval_gen_len': 21.99,\n",
              " 'eval_runtime': 428.2441,\n",
              " 'eval_samples_per_second': 7.265,\n",
              " 'eval_steps_per_second': 1.817}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%wandb\n",
        "# uncomment to display Wandb charts\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WioRBZowXRG3",
        "outputId": "fc63c37b-f253-4bf4-ac71-1a7defeb5a4a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2318' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2318/7000 21:26 < 43:20, 1.80 it/s, Epoch 0.33/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.347400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.872700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>4.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>4.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.967700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>4.040400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.699300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>3.666900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>3.833300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.620700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>3.626900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>3.659600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>3.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>3.598000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.319100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>3.441200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>3.469000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>3.392100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>3.442500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.519300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>3.353100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>3.633100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>3.595600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>3.452900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.303200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>3.212700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>3.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>3.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>3.320900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.380200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>3.276500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>3.334800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>3.351000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>3.321300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.380900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>3.336100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>3.251000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>3.296200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>3.384500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.321800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>3.280700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>3.250200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>3.387800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>3.216600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.231600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>3.211300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>3.335500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>3.358900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>3.217900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.443900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>3.278900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>3.171800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>3.336300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>3.405400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.316000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>3.167100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>3.280700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>3.177400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>3.370100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.165400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>3.134200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>3.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>3.358300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>3.169900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>3.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>3.156900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>3.214300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>3.380700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>3.387800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>3.169500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>3.262300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>3.106400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>3.182300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>3.246800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.348800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>3.155700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>3.368700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>3.089200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>3.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>3.258900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>3.320500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>3.109800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>3.192600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>3.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>3.090800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>3.214500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>3.249900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>3.145800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>3.040700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>3.197600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>3.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>3.264500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>3.308700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>3.116100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>3.231700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>3.073600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>3.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>3.127900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>3.256500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.118000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>3.286900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>3.321300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>3.128700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>3.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>3.150100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>3.195600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>3.255300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>3.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>3.132100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>3.182500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>3.025300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>3.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>3.226700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>3.218600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>3.254300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-65357ea511ed>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# uncomment to display Wandb charts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m         )\n\u001b[0;32m-> 1662\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1663\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2699\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2731\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2732\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 )\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1379\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1243\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    856\u001b[0m                     )\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                     layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m    859\u001b[0m                         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "M0vFbvWsXTA-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8fed8c0-baa6-469c-d6b3-18fe1d7db533"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1556' max='778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [778/778 37:43]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2318' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2318/7000 21:26 < 43:20, 1.80 it/s, Epoch 0.33/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.347400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.872700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>4.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>4.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.967700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>4.040400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.699300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>3.666900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>3.833300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.620700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>3.626900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>3.659600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>3.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>3.598000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.319100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>3.441200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>3.469000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>3.392100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>3.442500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.519300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>3.353100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>3.633100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>3.595600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>3.452900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.303200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>3.212700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>3.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>3.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>3.320900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.380200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>3.276500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>3.334800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>3.351000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>3.321300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.380900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>3.336100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>3.251000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>3.296200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>3.384500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.321800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>3.280700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>3.250200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>3.387800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>3.216600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.231600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>3.211300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>3.335500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>3.358900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>3.217900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.443900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>3.278900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>3.171800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>3.336300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>3.405400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.316000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>3.167100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>3.280700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>3.177400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>3.370100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.165400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>3.134200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>3.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>3.358300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>3.169900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>3.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>3.156900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>3.214300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>3.380700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>3.387800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>3.169500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>3.262300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>3.106400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>3.182300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>3.246800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.348800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>3.155700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>3.368700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>3.089200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>3.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>3.258900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>3.320500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>3.109800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>3.192600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>3.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>3.090800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>3.214500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>3.249900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>3.145800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>3.040700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>3.197600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>3.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>3.264500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>3.308700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>3.116100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>3.231700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>3.073600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>3.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>3.127900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>3.256500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.118000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>3.286900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>3.321300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>3.128700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>3.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>3.150100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>3.195600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>3.255300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>3.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>3.132100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>3.182500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>3.025300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>3.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>3.226700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>3.218600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>3.254300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2317</td>\n",
              "      <td>3.254300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 3.0154919624328613,\n",
              " 'eval_rouge1': 46.2466,\n",
              " 'eval_rouge2': 21.7289,\n",
              " 'eval_rougeL': 38.0362,\n",
              " 'eval_rougeLsum': 41.8935,\n",
              " 'eval_gen_len': 25.8284}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if WANDB_INTEGRATION:\n",
        "    wandb_run.finish()"
      ],
      "metadata": {
        "id": "z4y98GK7XUtv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "outputId": "9ead5365-0aed-4a75-f131-5dbd9052b610"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/rouge1</td><td>▁█</td></tr><tr><td>eval/rouge2</td><td>▁█</td></tr><tr><td>eval/rougeL</td><td>▁█</td></tr><tr><td>eval/rougeLsum</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▃▄▅▆▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆</td></tr><tr><td>train/loss</td><td>█▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▁▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>25.8284</td></tr><tr><td>eval/loss</td><td>3.01549</td></tr><tr><td>eval/rouge1</td><td>46.2466</td></tr><tr><td>eval/rouge2</td><td>21.7289</td></tr><tr><td>eval/rougeL</td><td>38.0362</td></tr><tr><td>eval/rougeLsum</td><td>41.8935</td></tr><tr><td>eval/runtime</td><td>554.679</td></tr><tr><td>eval/samples_per_second</td><td>5.609</td></tr><tr><td>eval/steps_per_second</td><td>1.403</td></tr><tr><td>train/epoch</td><td>0.33</td></tr><tr><td>train/global_step</td><td>2317</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>3.2543</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-energy-4</strong> at: <a href='https://wandb.ai/rahul96jain/bart_AMI/runs/f5d7aliv' target=\"_blank\">https://wandb.ai/rahul96jain/bart_AMI/runs/f5d7aliv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230415_163619-f5d7aliv/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "20dlgjYJZaQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "uF1h5NTJhj_T"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(test_samples, model):\n",
        "    inputs = tokenizer(\n",
        "        test_samples[\"dialogue\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=encoder_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return outputs, output_str\n",
        "\n",
        "\n",
        "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "test_samples = validation_data_txt.select(range(16))\n",
        "\n",
        "summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n",
        "summaries_after_tuning = generate_summary(test_samples, model)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HePcpf54XpoA",
        "outputId": "c60b6c56-ab71-4511-a819-aa4a11519b11"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (62) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    tabulate(\n",
        "        zip(\n",
        "            range(len(summaries_after_tuning)),\n",
        "            summaries_after_tuning,\n",
        "            summaries_before_tuning,\n",
        "        ),\n",
        "        headers=[\"Id\", \"Summary after\", \"Summary before\"],\n",
        "    )\n",
        ")\n",
        "print(\"\\nTarget summaries:\\n\")\n",
        "print(\n",
        "    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",
        ")\n",
        "print(\"\\nSource dialogue:\\n\")\n",
        "print(tabulate(list(enumerate(test_samples[\"dialogue\"])), headers=[\"Id\", \"Dialogue\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DaBUTudXuX3",
        "outputId": "bbd11672-4b94-4c0c-8fea-7b0a9bf15317"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Id  Summary after                                                                                                                                                                                                Summary before\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------\n",
            "   0  #Person1# can't decide which classes to take are at the same time. #Person2# suggests taking the chemistry classes in the spring.                                                                            A group of students at the University of California, Berkeley, have been sharing their course schedule for the next semester.\n",
            "   1  #Person1# found an apartment in today's apartment ads. #Person2# thinks the apartment looks great.                                                                                                           A group of people in the Czech Republic have been discussing how to find an apartment.\n",
            "   2  Mike and Paul will go out to the center in 15 minutes to check out the'sights'.                                                                                                                              A group of friends in the French capital, Paris, have been sharing their thoughts on how to get to work.\n",
            "   3  #Person1# and Ted are going on holiday this year. Ted doesn't like living with his wife's parents' for a few weeks.                                                                                          A group of people in the UK have been sharing their holiday plans.\n",
            "   4  #Person1# tells #Person2# the church reservations and the buffet and the cake are all set.                                                                                                                   A group of people in the US have been discussing how to get married.\n",
            "   5  Faith won't be able to meet Adam before 8.                                                                                                                                                                   A look at some of the better stories of the week in the run-up to Christmas.\n",
            "   6  Andy will send Pam's report to Mr. Hendricks.                                                                                                                                                                Andy and Leslie, the chief executive of the Isle of Man, are discussing a report to the Prime Minister.\n",
            "   7  #Person2# needs to review all the text books for the final exam. #Person1# thinks the exam is not simple as you may imagine.                                                                                 A group of students at a university in the Czech Republic have been discussing how to prepare for their final exam.\n",
            "   8  Sanchez will carry Joe's boots to training.                                                                                                                                                                  Joe Sanchez has been asked to carry his boots to training for the first time.\n",
            "   9  #Person2# doesn't know how to fill out the tax-free allowance form. #Person1# suggests asking the accountant or the lawyer of the law firm.                                                                  A group of people in the Czech Republic have been discussing how to pay tax.\n",
            "  10  Lenny will be at Lenny's place for Christmas. Lenny is visiting family for Boxing Day.                                                                                                                       A conversation has broken out between Barracow and Cracow in Poland.\n",
            "  11  Jessie's boyfriend sent Martha a message. Martha thinks she should wear it more often.                                                                                                                       A woman in her 20s has been sharing her story with her friend Tom.\n",
            "  12  Anna doesn't want to argue anymore because #Person2# didn't try to prevent it. Anna thinks they can still talk.                                                                                              A group of people in the Netherlands have been talking to each other for the first time.\n",
            "  13  #Person2# tells #Person1# the roommates watch the Korean soap operas until mid-night. #Person 2# wants to sleep and tells them to turn off the TV and have some quiet time when the room should quiet down.  A friend of one of four people who live in a dorm in South Korea has been sharing their frustration.\n",
            "  14  Dorothy and Donald will meet in Central Park in 10 minutes. Dorothy will change at Queensboro Plaza to take N to Central Park.                                                                               A group of friends in New York City have been sharing their thoughts on where they should be travelling.\n",
            "  15  #Person2# tells #Person1# how to catch the bus for the zoo.                                                                                                                                                  A group of people in Beijing have been sharing their thoughts on how to catch a bus for the zoo.\n",
            "\n",
            "Target summaries:\n",
            "\n",
            "  Id  Target summary\n",
            "----  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  The two courses #Person1# needs to take are at the same time. #Person2# suggests #Person1# take one of them next semester. #Person1# then finds it clashes with his potential work at the lab next semester. #Person2# suggests #Person1# go to the lab after the class.\n",
            "   1  #Person1# tells #Person2# that #Person1# has found a great, inexpensive apartment in the ads. #Person2# is glad to hear that.\n",
            "   2  Mike and Paul are going to Castle Hill in the center. Mike will lend Paul his bus fare.\n",
            "   3  Ted's wife will stay with her parents for a few weeks, but Ted doesn't like living with them. #Person1# will go to China with her husband.\n",
            "   4  #Person2# asks #Person1# if their wedding preparation is all set up as each other's mother expects.\n",
            "   5  Adam and Faith will meet at 8:30.\n",
            "   6  Pam is done with the report. She should send it to Mr. Hendricks at a.hendricks@asterix.com.\n",
            "   7  #Person2# shares with #Person1# the preparation techniques for the final exam.\n",
            "   8  Sanchez will bring Joe's boots to their training.\n",
            "   9  #Person1# doesn't know about tax-free allowance. #Person2# advises #Person1# to seek an accountant and make the declaration soon.\n",
            "  10  Lenny invites Barack to come to his place in Cracow during Christmas. They can play FIFA on the Playstation 4 Lenny bought.\n",
            "  11  Jessie's boyfriend sent Martha the unambiguous message. Samantha thinks Martha should tell Jessie about that.\n",
            "  12  #Person2# thinks Anna and #Person2# are both responsible for the argument. Anna asks #Person2# to go away.\n",
            "  13  #Person2# hasn't been sleeping very well since #Person2#'s roommates watch the Korean soap operas till mid-night and #Person2# finds it hard to tell them about this.\n",
            "  14  Dorothy is in Queens, at Woodside Station. Donald will meet her at Queensboro Plaza. They will go to Central Park to meet Betty close to Jose Marti statue in 20 minutes.\n",
            "  15  #Person2# shows #Person1# where to catch the bus for the zoo.\n",
            "\n",
            "Source dialogue:\n",
            "\n",
            "  Id  Dialogue\n",
            "----  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  #Person1#: I can't decide which classes to take. I don't like any of the ones I've signed up for and two of the ones I really have to take are at the same time.\n",
            "      #Person2#: Pass me the course schedule book. Which classes are at the same time?\n",
            "      #Person1#: Biology 201 and introduction to chemistry. The both required classes.\n",
            "      #Person2#: Let's find out if either of them is offered next semester. Look here, the chemistry classes. You can just take it in the spring.\n",
            "      #Person1#: Yes, that's true and the biology class is in a series so I need to take 201 this semester. The only problem with taking chemistry next semester is that it meets every day at 8:00 AM.\n",
            "      #Person2#: What's wrong with that? Is that too early for you?\n",
            "      #Person1#: Not too early, but I was trying not to take classes on Fridays. I want to work in the lab that whole day. I might be able to work for one of my professors.\n",
            "      #Person2#: Maybe you can start work after the class is over. It's only an hour lecture. I'm sure the professor will understand.\n",
            "      #Person1#: I hope so.\n",
            "   1  #Person1#: I found an apartment to rent.\n",
            "      #Person2#: Where did you find this apartment?\n",
            "      #Person1#: I found it in today's apartment ads.\n",
            "      #Person2#: Really? I can't believe you actually found an apartment in the ads.\n",
            "      #Person1#: I actually found it in the ads, and it's not too expensive either.\n",
            "      #Person2#: I want to hear more about this apartment.\n",
            "      #Person1#: All you really need to know is that the apartment looks great.\n",
            "      #Person2#: How much will you have to pay for rent?\n",
            "      #Person1#: Every month I'd only have to pay $ 725.\n",
            "      #Person2#: For where we live, that is really inexpensive.\n",
            "      #Person1#: It is, isn't it?\n",
            "      #Person2#: I'm glad to hear that you finally found an apartment.\n",
            "   2  Mike: I'm bored. Do you want to do something?\n",
            "      Paul: Yeah. But what?\n",
            "      Mike: Dunno. We could go out to the center and like hang out on Castle Hill.\n",
            "      Paul: I don't have any money.\n",
            "      Mike: We could just sit on the grass and check out the 'sights'.\n",
            "      Paul: We could. Can you led me the bus fare?\n",
            "      Mike: Yep. I'll come by yours in 15 min. Will you be ready?\n",
            "      Paul: fuck yeah!\n",
            "   3  #Person1#: Ted, where are you going for your holiday this year?\n",
            "      #Person2#: I haven't decided yet. My wife is going to stay at her parents' for a few weeks. They live in the countryside, you know.\n",
            "      #Person1#: Why not go with her? You can enjoy fresh air there.\n",
            "      #Person2#: Well, to be honest, I don't like living with my wife's parents. So maybe I'll just stay at home. What about you?\n",
            "      #Person1#: I'll spend a few weeks in China. My husband and I want to see around the country.\n",
            "      #Person2#: China is a great country. There are many great places to visit there. I'm sure you'll have great fun.\n",
            "   4  #Person1#: There's so much to do and so little time.\n",
            "      #Person2#: I know. Did your mom double check on the church reservations?\n",
            "      #Person1#: Yes. We're going to be married in my hometown church, the first minute of the new millennium!\n",
            "      #Person2#: OK. . . and what about the buffet and the cake? Did your mom call the caterer?\n",
            "      #Person1#: All set. And we're having a red bean cake and dim sum for the Taiwanese guests, just like your mom wanted.\n",
            "      #Person2#: Great. She'll be so happy.\n",
            "   5  Adam: 7.30?\n",
            "      Faith: I won't manage before 8\n",
            "      Adam: 8.30 then?\n",
            "      Faith: Much better!\n",
            "   6  Pam: I'm done with the report\n",
            "      Pam: Where should I send it?\n",
            "      Andy: To Mr. Hendricks\n",
            "      Leslie: a.hendricks@asterix.com\n",
            "   7  #Person1#: Are these your text books? Biochemistry, General Ecology, Botany, Cell Genetics, Molecular Genetics. . .\n",
            "      #Person2#: Yes. I gotta review all of them for the final exam. It is just around the corner.\n",
            "      #Person1#: Oh, right! Do you have many exams at the end of each semester?\n",
            "      #Person2#: That depends. Some semesters have many, some don't. And some courses don't have exams but only ask for papers. That's easy.\n",
            "      #Person1#: And when do you prepare for your final exam?\n",
            "      #Person2#: Honestly speaking, most students prepare it one month before the exam.\n",
            "      #Person1#: Really? You only review your lessons in one month? Does it work?\n",
            "      #Person2#: Of course, it's useful. And it's very crucial to have the copies of teacher's notes, because most questions in the exam are based on them.\n",
            "      #Person1#: Wow, and all the key points are included in them? You're so smart!\n",
            "      #Person2#: But the exam is not as simple as you may imagine. We have to stay up late.\n",
            "      #Person1#: Do you have the classrooms open for the whole night?\n",
            "      #Person2#: Yes, some people even pack up his bed quilt and sleep there. That's a little bit crazy.\n",
            "   8  Joe: Hello\n",
            "      Joe: Please remember to carry my boots to training\n",
            "      Sanchez: Sure I will.\n",
            "   9  #Person1#: Have you declared your income and are you prepared to pay tax?\n",
            "      #Person2#: Not yet. I don't know how to fill out the form. What is the tax-free allowance for supporting a dependent?\n",
            "      #Person1#: I don't really know. Why not ask the accountant or the lawyer of the law firm? They will tell you which is subject or not subject to taxation. He can even help you avoid paying tax legally.\n",
            "      #Person2#: If I don't pay my taxes, would the tax officials discover it?\n",
            "      #Person1#: Certainly. No one who evades tax can escape from their detection. They ' ll check your income through computers. You'd better make a declaration to the tax authorities as soon as possible. If you fail to meet the deadline, you will be fined.\n",
            "  10  Barack: are you gonna be home for christmas?\n",
            "      Lenny: hey :) visiting my family for boxing day but other than that, ye\n",
            "      Barack: great, i am taking the whole week off - till new years\n",
            "      Lenny: so you will be in Cracow for christmas?\n",
            "      Barack: yeah, we should hang out\n",
            "      Lenny: most definitely :D you should come to my place, i bought a playstation 4\n",
            "      Barack: tempting :D do you have the new fifa?\n",
            "      Lenny: is that a question?\n",
            "      Barack: ok you've convinced me ;D\n",
            "      Lenny: call me closer to christmas so we can set up a precise time and date\n",
            "      Barack: yeah cool\n",
            "  11  Martha: Jessie's bf sent me a message\n",
            "      Samantha: What??\n",
            "      Fiona: OMG\n",
            "      Martha: <photo_file>\n",
            "      Samantha: \"Hi Martha, you looked cute in that green dress today\"\n",
            "      Samantha: \"You should wear it more often\"\n",
            "      Fiona: What a bastard\n",
            "      Fiona: Did you tell Jessie?\n",
            "      Martha: You think I should?\n",
            "      Martha: I'm not sure. She can take it the wrong way\n",
            "      Samantha: Right.\n",
            "      Samantha: She can be a bit unstable.\n",
            "      Samantha: But she should know that Tom is an asshole.\n",
            "  12  #Person1#: I really hate to say this, but don't go away mad, just go away.\n",
            "      #Person2#: I knew this would happen some day.\n",
            "      #Person1#: Then, why didn't you try to prevent it in the beginning?\n",
            "      #Person2#: Well. It's not all my fault, Anna. You are responsible, too.\n",
            "      #Person1#: I don't want to argue anymore. Please get out of my life!\n",
            "      #Person2#: I think we can still talk.\n",
            "      #Person1#: No way! Please don't follow me around.\n",
            "      #Person2#: Talk it easy, Anna. You really don't hate me. do you?\n",
            "      #Person1#: Yes, I do. Leave me alone!\n",
            "  13  #Person1#: Hi dude, you look upset, what's up?\n",
            "      #Person2#: haven't been sleeping well recently.\n",
            "      #Person1#: what's the problem?\n",
            "      #Person2#: every night my roommates watch the Korean soap operas till mid-night. I am not a big fan of Korean shows and I don't know how to tell them to stop without hurting their feelings.\n",
            "      #Person1#: well, you can simply tell them you want to sleep, or make an arrangement for a time when the room should quiet down.\n",
            "      #Person2#: yeah, I know, but I find these sorts of things hard to say. They won't like it if I tell them to turn off the TV. Now I just hope the show will end soon.\n",
            "      #Person1#: I understand. I used to live in a dorm with four people. I was great in some aspects. We always went out and and had fun together. But on the other hand, when I wanted some quiet time, and people kept\n",
            "      #Person2#: yeah, I crave my own space. i just so tired of having people around me all time.\n",
            "  14  Betty: Where are you?\n",
            "      Dorothy: in Queens, Woodside station\n",
            "      Donald: Dorothy, will you change at Queensboro Plaza? I can wait here for you\n",
            "      Donald: Then we can take N to Central Park together\n",
            "      Dorothy: Yes, I should be there in 10min\n",
            "      Donald: 👍 I'll be at the platform\n",
            "      Betty: So should we meet in 30min in Central Park?\n",
            "      Donald: even 20min, I guess\n",
            "      Betty: Where exactly?\n",
            "      Donald: Do you know where is the statue of Jose Marti?\n",
            "      Betty: I'm not sure I know which one it is\n",
            "      Donald: The one with a guy in a suit on a very crazy horse\n",
            "      Betty: ahahah, ok, I know it\n",
            "      Dorothy: 😂\n",
            "      Donald: perfect!\n",
            "  15  #Person1#: Good morning, Sir.\n",
            "      #Person2#: Morning.\n",
            "      #Person1#: Is this where I catch the bus for the zoo?\n",
            "      #Person2#: Yes. You can take No. 846 from here, but you have to get off at Nanchengmen stop and change to No. 106.\n",
            "      #Person1#: That's a little troublesome.\n",
            "      #Person2#: Actually, if you go to the bus stop in the next block, you can take No. 105 which will let you right off in front of the zoo gate.\n",
            "      #Person1#: Maybe that's what I'll do. Thanks a lot.\n",
            "      #Person2#: You're welcome.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference test"
      ],
      "metadata": {
        "id": "eD3wd59DeABW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = \" Hi, this is Eric Johnson. It's February 18, 2021, and this is the engineering key review at GitLab. So I've got number four in the agenda, which is a proposal to break up this meeting into four department key reviews. So currently this is engineering. Development quality, security, and UX infrastructure and support to their own key reviews already. I have the reasons why increased visibility able to go deeper. Increased the objectivity with which my reports can manage their groups, allow me more time to focus on new markets and allow me to shift into more of a question asker mode, then generating content and answering questions in these meetings. And to avoid adding three net new meetings to stakeholders counters, I propose we do a sort of two month rotation. So month one development quality go month two security and UX would go. How do people feel about that proposal? I think in the group conversations it's working really well. So I'm supportive and this is the smallest thing. Maybe we need four meetings a month, like it's the biggest department, it's super central. But you proposed this. I don't. I could see either way. So let's stick with the proposal. Go, we'll try it and we'll we can be flexible. I mean, development is larger. Maybe they go more frequently or something. I'll see how it goes. All right. And then I've got number five, which is we've got R&D overall MR rate. And we also have R&D wider MR rate, both as top level KPIs for engineering. So the difference between them in the simplest sense is that R&D wider MR rate includes both community contributions and community MRs. The problems I see with this are that one, the wider MR rate, the one that includes internally and external MRs, it duplicates the overall MR rate, which is. The wider MR rate should just be external, right? And then overall should be narrow plus wider. Oh, yeah. Like we say the wider community. Right, right, right. Okay. So there's. I have to check the taxonomy. Well, like, can you can you confirm? That's that's that's, that's, that's reasoning is my understanding as well. Yeah, I believe water MR rate just captures community contributions. Only and no internal. Yeah, and the reason we measure data is that like one of the most likely failure modes is that we lose the community. Yeah. So we're get, or we're gets goofy is the. When you look at a specific team within the company, there could be contributions outside of that that aren't community contributions. They would be viewed community contributions by that group, but effectively they're not from outside the company. So that's why we use wider to kind of reflect that. And narrow is very specific to the team. But are you saying that if someone in plan contributes to verify its viewed as wider? Not quite that plan plan and verify are just fine. It's when you look at like the development versus infrastructure infrastructure will oftentimes contribute to developments work, but it won't be counted as MRs. Yeah, that's a, that's a potential bit of funkiness that we should talk about separately. I didn't have that in my sort of critique of this, but that that doesn't necessarily make intuitive sense to me. So, so then I think part of my critique of this can be thrown out because it's not as duplicative as I thought, but I still think there's a problem with R&D wider MR rate, which is this thing doesn't really move. In part because it's a rate, so it feels like the way to drive this up is to specifically drive community authors to contribute more than one MR per month. That's how this moves up because it's a productivity rate like we use internally. And that doesn't necessarily feel like the right thing because there's scenarios in which this goes up. We've actually got less contributions overall and less contributors overall. Wait, wait, wait a second. So you're saying that R&D wider MR rate is number MRs per external contributor. Oh my goodness, that should not be the thing. It should be contributions for GitLab team member. So to contribute those, the thing above the division is the external ones. The thing below is the number of team members at GitLab. Is that the case, Lily? I'm checking right now. I think so in our MRs per team member. So unless we start calling people outside the company team member, then it shouldn't be that. Yeah, just clarifying here. So our numerator is community contributions and then our denominator is GitLab team members. So it's not per external member. So we've got what we're doing there, Eric, is we're not trying to say how many MRs does someone send if they send something? How many MRs from external do we get for the size of our organization? Sorry, I have a childhood emergency outside the door. So maybe explain the context behind this. The context is as we grow as a company, we should make sure we keep the community up. Like the logical thing is for the community to flatline and the size of the org to go and before you know, you've kind of outgrown the wider community. Yeah, what I'm seeing is we created this pre-sophisticated taxonomy with prefixes and postfixes to talk about these things. But in reality, we've only got two of them. And it's we keep forgetting, we have a hard time discussing this thing. So I'd rather just name them simply two names for what they are rather than using the taxonomy. But also like in F, I have this proposal of like, what if we just track as a KPI of the percentage of total MRs that come from the community over time? And we would see that drop. I love that. Let's do that instead. But the thing, the thing why we have this complex thing is because you can game that you want to game that you just produce fewer MRs with the engineers that get one. So if you drive that really hard and say this is your number one goal, it's very easy to achieve is just tell all your engineers to produce half. Yeah, so we have we have different metrics to prevent that from happening the same way that like support SLAs and asset kind of buttress one another. I think we're we're robust to that. But simplifying this would make these conversations. If you as our CTO don't even understand them, we went overboard. So I'm supportive. And I forgot and I was agreeing this stuff this morning and like, there's a problem with this and then you just remind me of the context. So yeah, I can't really have my head. A percentage that come from the community. I love that. It's what all our investors ask about. Let's do that. Okay. Cool. So, um, Lily, if you can work with Max to make that transition of the great. And I'll hold the one that we're talking about. That's from the mulberry. Thanks. I'm on the call. Sorry, it was a bit late. Timeline. We do have PIs on the raw number of community MRs and we can make the shift. And why they're confirming from the definition, I think why they only counts for community. And that's that's what the definition is. Cool. All right. So number six, then Christopher. Sorry, I was looking up to see if I had the percentage graph because I think we played around with this at one point and had a draft of that. Probably about five months back, if I can remember, Lily. Just in FYI month of February, if you were looking at any particular metrics, particularly in development at MR rate. We haven't had updates in four days. There's apparently a lag issue that's been problematic for the data team to basically get updated metrics and they're working on that. Okay. I'm sorry, Max. You get the next one. So yeah, there's some some color there on the on the medication, the lag later on. On to on to seven. We continue. I said FYI in addition to the TBI status. I'm sorry. I wanted to just touch on the postgres replication issue there real quick. I've been trying to get my arms wrapped around it. Um, do we have the right attention to this? This is kind of Eric. I don't know if you were commenting on. Hitting towards this in the last meeting around some of the infrastructure improvements on the product side. I'm just not quite sure whose responsibility is to focus on getting a handle on some of the constraints we have on replication. So what I was mentioning in the in the product queue review about an hour ago is I think is sort of like unrelated. And so I think the DRI needs to be your kind of data engineering team. But of course there's a dependency on infrastructure because that's where the data is being piqued from. They they do on that data source. So let's say for the replication lag on that slave host where I'm sorry not the on the the secondary host where the data is being pulled from like infrastructure would be the DRI for that. And so any escalations but well all those. And I know we have an action plan for that as far as creating another dedicated host just for the data team to pull from. I did ask I saw that issue and I did talk to Craig gums a little bit as well on the database side just to see if there's some database improvements and I'm still trying to figure out, you know, if it's truly just dedicated computation old sort of resource a server. Or if there's actually some some database tuning that needs to occur, do you have a sense of that. There's so I'd say it's it's three different things. It's having a dedicated host that doesn't have conflicting query traffic coming from other other workloads. There are some tuning performance or tuning improvements to be made. And then there's also improvements in and this is where it does maybe relate a little bit to what the topic was in the last review basically the overall demand on the database layer from from dot com activities and like improving those. It's definitely not just one of those things that one of the most specific actions we're going to take though is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there. And not having conflicting query. And conflicting queries affect the ability to update the replication. Steve, I definitely want to partner with you on this one because I think the the demand on those databases is only going to increase. It's not going down. And I think we need to get. I'm still unclear on where to focus and to get the biggest bang for the buck. I think of the computational resource dedication that's going to be a good thing, but I'll probably going to squeeze the balloon. Next area will will honor itself. Okay, I'll put into the infricky review for next week. Okay, on this issue. Thank you, Steve. So then back to mecon 7 or. Yes. Thank you. And Rob was in these assassins that this morning as well. We have the attention there. Number seven, just provide provide update on previous conversations. We continue to improve defect tracking and against SLOs. There is a first iteration P.I that we are experimenting to show percentage of defects meeting. And we are going to be able to see the SLOs key findings as ones are hovering at 80% as to at 60. We've been focused mostly on S1 as to this point as hence why S3 and S4s are a lower. And this will likely be the case. We are also in point B are working on the measurement for average open box age. This would give us a whole picture of what's what's left. So the age goes up and down. We are cleaning the backlog. The average age should go down as well. There's no P.I yet, but I just want to update and show up beyond this. It's not a off track. Number C Craig on S2. Yeah, just looking through the charts. And I noted that there's a spike in meantime to close. Yeah, and just want to see if you had any insight into that for us. This is the S2. Yeah, this is where the point B on age and supplemental charts in the back end helps. So I haven't seen a dip in age nor the count overall. I think it's the latter. We need to dig in a bit deeper in that. And also the data lag. I would like to re-evaluate when we have a whole picture of when everything is synced in as well. Christie, you have some insights. Yeah, I'm just wondering if part of this could be the fact that we changed the severity across the board for MRs to S2. And so we may have some older bugs in there that hadn't been addressed because they were at a lower severity. Now we've moved them to S2 and maybe that caused a little spike. That could be the case that we did in a limited fashion. It won't be a huge volume. We also iterated after that to pin on priority since product owns prioritization. So I wouldn't account it entirely to that. I mean, this isn't the infertile key review, but. I know that they've gotten backed up on those issues. So if some some good portion of those are infertile created or related, then that may be lifting it as well. I can take the deeper dig in and then provide an update next time. I think we need extra debug slicing of the data here. So you would like to go to point eight. Yeah, we are now measuring S1 as to SLO achievement with closed bugs. But if you then look at the number of bugs, it's exponential growth. And then it will be trivial to us to achieve 100% SLO achievement. If you just look at close bugs, even though there would be a major problem in the company, 99% of all bugs are overdue. As long as I only close ones that are still within the SLO, I'll have great achievement. So I think we shouldn't be looking at the closed bugs. I think we should be looking at open bugs. The entire population or percentage of those is within the SLO time. I think we're doing it the wrong way. Thanks for the thanks for the feedbacks that. Hence why we wanted to have the average age to measure what's outside in the open. And then make this iteration to measure also measure focus on the age of all opened, including open bugs. This is also something we have discussed with Christopher in the next iteration as well. And we happy when happy to adjust. So the key. Yes, go ahead. So average age would get closer to it. It's not what I'm proposing. What I'm proposing is off the open bugs are percentages outside of SLO. So display it as a percentage. You do now just do it about the open bugs month or close. Got it. Okay. The exceeding SLO for open bugs. Yeah, or open bugs that are within SLO. So you have a chart that should go up and to the right like everything else. Sounds great. We can take it to the next data metrics work stream to deliver this. Cool. Thanks. Is it pretty good? Yeah, I like it. You make you have to figure out how to. Because we like to be able to have charts that we can historically reconstruct if we need to. So in tickets close out, you need to go through their history to figure out at this time when it was open. Did it breach the SLO or not? That's a good point. This might be much harder computationally. And so I totally respect if we can do it for that reason. Yeah, I think that's a good point. Yeah, I think that's a good point. Cool. Nine. Yeah, I just wanted to ask the team like I went through all the key meeting metrics. Everything looked in line with prior periods and look good. Is there anything the team wants to call out? It's mostly that we should be watching. Yeah, I'll call out. So the good news is in Q4. We had our smallest decline over several quarters. So we only went down by a tenth of a point. The quarter previous was point six or six tenths of a point and the quarter before that was a full point. So. We see this as an improvement, even though it was still a decline, but it's still a decline. Obviously, we want this actually tracking in an upward direction. We also don't have enough data to know whether or not this is an actual real trend up. So I'm optimistic. I think this is a good thing. We have had a much keener focus on us over the past several quarters. And that's why I think, okay, the work that we've done. I think actually is catching up and getting noticed in sus, but we got to keep an eye on it. We can't. We cannot assume that that's the case. Yeah, and the bug discussion above just kind of points out that like we have an underlying problem right now in our metrics measurement. So if we change the measurements to reflect that, then hopefully we're in good shape. If we don't and we flat line and address it so that we flat line open S1s and S2s, you will see a temporary jump in and above SLOs. As we clear out that back, I'll go over that period of time. So we have a point C, which is similar to infrastructure. We need to get more security work prioritized or hearing that from the team, but neither that problem or that activity is sort of currently reflected in our security metrics. So we have some work to do long term to make sure the we see things like that in the metrics and the measurements that we're making. So back to you said 10. So now that Nero MR rate seems significantly below target. And maybe I helped that it would bounce back from December. I think it bounced back, but not back on target. Any any context there? What's going on? Yeah, so with family and friends days, we actually had some heavier of vacation days. And we historically have one thing to know is that we are actually at a higher MR rate. If you look, if you go back the last 18 months, we're actually at a higher Nero MR rate than we were back in each month this year. So if you compare October to October, November to November and January, I'm sorry, October, November, December and January, comparatively to last year, which will find is we're between a half point and a 1.5. MR rate above where we were in the month of previous year. That's great contact. Thank you, Chris, for good work. Yeah, so the expectation is is that February is a short month. We were at I think 16 work days with friends and family day and other things. Obviously seven carriages in Texas doesn't help things either for the folks who are working in Texas. But hopefully the rest of the team is being effective. I was hoping to see a better result right now, but with four or five days, particularly around release week. That's usually when we see do do see a little bit higher activity. So that's not accounted for yet. But you know, Marches, Marches when I'm expecting kind of see a real rebound much like we did last year. Awesome. Thanks. The other context I'll give is we now do time series targets. So when we change the target, you'll see they're reflected in the line. So if we were to look back historically here, the goal here was actually lower and Christopher was ambitious. So we kept raising it. We kept meeting that. So it should stare step here and we could go back and reconstruct that if we really wanted to. And then ignoring the sort of the seasonal dip here, we raised it to I think 11. And then we realize we're kind of hitting that point of doing and raising returns and the right thing to do business wise. And this is in our FY 22 direction is hold the line at productivity. Let's start to raise other things related to quality security, availability and what not. So that's kind of what you are, you're seeing this bump is we raised it and we realized, okay, that's not the we shouldn't raise it anymore. And we brought it back down to 10. So 10 will be the dark going forward. I'm going to try to get better a lot of other things while preventing this from dipping. And just want to call out that it's not necessary. Like, and higher MR rates should also help to address security and quality and other things because you're more productive. So you can fix more things so it's not necessarily opposite. But I agree with that. Let's hold the line 10 is then is a great number and and focus on other indicators to improve that makes it on a sense. Cool. Well said. All right, that's the agenda. Anyone want to vocalize anything else? Great. Well, thanks everybody. And I'm going to go check on my four year old and see if she got what whatever she needed. So cheers and toxic.\""
      ],
      "metadata": {
        "id": "BH2q7sAHeBOR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_inference_summary(test_samples, model):\n",
        "    inputs = tokenizer(\n",
        "        test_samples,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=encoder_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return outputs, output_str\n",
        "\n",
        "\n",
        "#model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "#test_samples = validation_data_txt.select(range(16))\n",
        "\n",
        "#summaries_before_tuning = generate_inference_summary(test_samples, model_before_tuning)[1]\n",
        "#summaries_after_tuning = generate_inference_summary(test_samples, model)[1]\n",
        "\n",
        "\n",
        "def get_input_sentences(start_idx):\n",
        "  # Get whole sentences up to 1000 words; don't break sentences up\n",
        "  end_idx = start_idx + 1000\n",
        "  text = result[start_idx:end_idx]\n",
        "  end_sentence_chars = [\".\", \"?\", \"!\"]\n",
        "  next_start_idx = end_idx\n",
        "  while text[-1] not in end_sentence_chars and end_idx < len(result):\n",
        "      text = text[:-1]\n",
        "      next_start_idx -= 1\n",
        "  return text, next_start_idx\n",
        "\n",
        "start = 0\n",
        "input_text = []\n",
        "summarized_text = []\n",
        "while start < len(result):\n",
        "  input, start = get_input_sentences(start)\n",
        "  input_text.append(input)\n",
        "  print(\"input text \\n\" + input)\n",
        "  out = generate_inference_summary(input, model)[1]\n",
        "  print(\"Summarized text\\n\", out)\n",
        "  summarized_text.append(out)\n",
        "\n",
        "\n",
        "print(summarized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El4T2pP3eIk7",
        "outputId": "408452bf-eb46-4016-9bc8-981c4638a657"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input text \n",
            " Hi, this is Eric Johnson. It's February 18, 2021, and this is the engineering key review at GitLab. So I've got number four in the agenda, which is a proposal to break up this meeting into four department key reviews. So currently this is engineering. Development quality, security, and UX infrastructure and support to their own key reviews already. I have the reasons why increased visibility able to go deeper. Increased the objectivity with which my reports can manage their groups, allow me more time to focus on new markets and allow me to shift into more of a question asker mode, then generating content and answering questions in these meetings. And to avoid adding three net new meetings to stakeholders counters, I propose we do a sort of two month rotation. So month one development quality go month two security and UX would go. How do people feel about that proposal? I think in the group conversations it's working really well. So I'm supportive and this is the smallest thing.\n",
            "Summarized text\n",
            " ['Eric Johnson is introducing a proposal to break up the engineering key review into four department key reviews. Eric thinks people feel about that proposal.']\n",
            "input text \n",
            " Maybe we need four meetings a month, like it's the biggest department, it's super central. But you proposed this. I don't. I could see either way. So let's stick with the proposal. Go, we'll try it and we'll we can be flexible. I mean, development is larger. Maybe they go more frequently or something. I'll see how it goes. All right. And then I've got number five, which is we've got R&D overall MR rate. And we also have R&D wider MR rate, both as top level KPIs for engineering. So the difference between them in the simplest sense is that R&D wider MR rate includes both community contributions and community MRs. The problems I see with this are that one, the wider MR rate, the one that includes internally and external MRs, it duplicates the overall MR rate, which is. The wider MR rate should just be external, right? And then overall should be narrow plus wider. Oh, yeah. Like we say the wider community. Right, right, right. Okay. So there's. I have to check the taxonomy.\n",
            "Summarized text\n",
            " [\" I've got some information about the R&D wider MR rate and the overall MR rate, and the wider community rate are both community contributions and community MRs.\"]\n",
            "input text \n",
            " Well, like, can you can you confirm? That's that's that's, that's, that's reasoning is my understanding as well. Yeah, I believe water MR rate just captures community contributions. Only and no internal. Yeah, and the reason we measure data is that like one of the most likely failure modes is that we lose the community. Yeah. So we're get, or we're gets goofy is the. When you look at a specific team within the company, there could be contributions outside of that that aren't community contributions. They would be viewed community contributions by that group, but effectively they're not from outside the company. So that's why we use wider to kind of reflect that. And narrow is very specific to the team. But are you saying that if someone in plan contributes to verify its viewed as wider? Not quite that plan plan and verify are just fine.\n",
            "Summarized text\n",
            " [' I believe water MR rate just captures community contributions and no internal rate. The reason we measure data is that one of the most likely failure modes is that we lose the community. The team will use wider to reflect that and narrow is very specific to the team.']\n",
            "input text \n",
            " It's when you look at like the development versus infrastructure infrastructure will oftentimes contribute to developments work, but it won't be counted as MRs. Yeah, that's a, that's a potential bit of funkiness that we should talk about separately. I didn't have that in my sort of critique of this, but that that doesn't necessarily make intuitive sense to me. So, so then I think part of my critique of this can be thrown out because it's not as duplicative as I thought, but I still think there's a problem with R&D wider MR rate, which is this thing doesn't really move. In part because it's a rate, so it feels like the way to drive this up is to specifically drive community authors to contribute more than one MR per month. That's how this moves up because it's a productivity rate like we use internally. And that doesn't necessarily feel like the right thing because there's scenarios in which this goes up. We've actually got less contributions overall and less contributors overall.\n",
            "Summarized text\n",
            " [\"It's when you look at like the development versus infrastructure infrastructure will oftentimes contribute to developments work but it won't be counted as MRs.\"]\n",
            "input text \n",
            " Wait, wait, wait a second. So you're saying that R&D wider MR rate is number MRs per external contributor. Oh my goodness, that should not be the thing. It should be contributions for GitLab team member. So to contribute those, the thing above the division is the external ones. The thing below is the number of team members at GitLab. Is that the case, Lily? I'm checking right now. I think so in our MRs per team member. So unless we start calling people outside the company team member, then it shouldn't be that. Yeah, just clarifying here. So our numerator is community contributions and then our denominator is GitLab team members. So it's not per external member. So we've got what we're doing there, Eric, is we're not trying to say how many MRs does someone send if they send something? How many MRs from external do we get for the size of our organization? Sorry, I have a childhood emergency outside the door. So maybe explain the context behind this.\n",
            "Summarized text\n",
            " ['Lily tells Lily that R&D wider MR rate is number MRs per external contributor should not be the number of team members at GitLab. Lily has a childhood emergency outside the door.']\n",
            "input text \n",
            " The context is as we grow as a company, we should make sure we keep the community up. Like the logical thing is for the community to flatline and the size of the org to go and before you know, you've kind of outgrown the wider community. Yeah, what I'm seeing is we created this pre-sophisticated taxonomy with prefixes and postfixes to talk about these things. But in reality, we've only got two of them. And it's we keep forgetting, we have a hard time discussing this thing. So I'd rather just name them simply two names for what they are rather than using the taxonomy. But also like in F, I have this proposal of like, what if we just track as a KPI of the percentage of total MRs that come from the community over time? And we would see that drop. I love that. Let's do that instead. But the thing, the thing why we have this complex thing is because you can game that you want to game that you just produce fewer MRs with the engineers that get one.\n",
            "Summarized text\n",
            " [\"I'm seeing what I'm seeing is a pre-sophisticated taxonomy with prefixes and postfixes to talk about these things but in reality we've only got two names for what they are.\"]\n",
            "input text \n",
            " So if you drive that really hard and say this is your number one goal, it's very easy to achieve is just tell all your engineers to produce half. Yeah, so we have we have different metrics to prevent that from happening the same way that like support SLAs and asset kind of buttress one another. I think we're we're robust to that. But simplifying this would make these conversations. If you as our CTO don't even understand them, we went overboard. So I'm supportive. And I forgot and I was agreeing this stuff this morning and like, there's a problem with this and then you just remind me of the context. So yeah, I can't really have my head. A percentage that come from the community. I love that. It's what all our investors ask about. Let's do that. Okay. Cool. So, um, Lily, if you can work with Max to make that transition of the great. And I'll hold the one that we're talking about. That's from the mulberry. Thanks. I'm on the call. Sorry, it was a bit late. Timeline.\n",
            "Summarized text\n",
            " ['Lily is on the call and she will work with Max to make that transition of the great.']\n",
            "input text \n",
            " We do have PIs on the raw number of community MRs and we can make the shift. And why they're confirming from the definition, I think why they only counts for community. And that's that's what the definition is. Cool. All right. So number six, then Christopher. Sorry, I was looking up to see if I had the percentage graph because I think we played around with this at one point and had a draft of that. Probably about five months back, if I can remember, Lily. Just in FYI month of February, if you were looking at any particular metrics, particularly in development at MR rate. We haven't had updates in four days. There's apparently a lag issue that's been problematic for the data team to basically get updated metrics and they're working on that. Okay. I'm sorry, Max. You get the next one. So yeah, there's some some color there on the on the medication, the lag later on. On to on to seven. We continue. I said FYI in addition to the TBI status. I'm sorry.\n",
            "Summarized text\n",
            " [\"Lily and Christopher are discussing the definition of community MRs. They haven't had updates in four days.\"]\n",
            "input text \n",
            " I wanted to just touch on the postgres replication issue there real quick. I've been trying to get my arms wrapped around it. Um, do we have the right attention to this? This is kind of Eric. I don't know if you were commenting on. Hitting towards this in the last meeting around some of the infrastructure improvements on the product side. I'm just not quite sure whose responsibility is to focus on getting a handle on some of the constraints we have on replication. So what I was mentioning in the in the product queue review about an hour ago is I think is sort of like unrelated. And so I think the DRI needs to be your kind of data engineering team. But of course there's a dependency on infrastructure because that's where the data is being piqued from. They they do on that data source. So let's say for the replication lag on that slave host where I'm sorry not the on the the secondary host where the data is being pulled from like infrastructure would be the DRI for that.\n",
            "Summarized text\n",
            " ['Eric has been trying to get his arms wrapped around the postgres replication issue. Eric was mentioning in the last meeting about an hour ago that the DRI needs to be your kind of data engineering team to focus on getting a handle on some constraints on replication and the replication lag on that slave host']\n",
            "input text \n",
            " And so any escalations but well all those. And I know we have an action plan for that as far as creating another dedicated host just for the data team to pull from. I did ask I saw that issue and I did talk to Craig gums a little bit as well on the database side just to see if there's some database improvements and I'm still trying to figure out, you know, if it's truly just dedicated computation old sort of resource a server. Or if there's actually some some database tuning that needs to occur, do you have a sense of that. There's so I'd say it's it's three different things. It's having a dedicated host that doesn't have conflicting query traffic coming from other other workloads. There are some tuning performance or tuning improvements to be made. And then there's also improvements in and this is where it does maybe relate a little bit to what the topic was in the last review basically the overall demand on the database layer from from dot com activities and like improving those.\n",
            "Summarized text\n",
            " [' We have an action plan for creating another dedicated host just for the data team to pull from.']\n",
            "input text \n",
            " It's definitely not just one of those things that one of the most specific actions we're going to take though is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there. And not having conflicting query. And conflicting queries affect the ability to update the replication. Steve, I definitely want to partner with you on this one because I think the the demand on those databases is only going to increase. It's not going down. And I think we need to get. I'm still unclear on where to focus and to get the biggest bang for the buck. I think of the computational resource dedication that's going to be a good thing, but I'll probably going to squeeze the balloon. Next area will will honor itself. Okay, I'll put into the infricky review for next week. Okay, on this issue. Thank you, Steve. So then back to mecon 7 or. Yes. Thank you. And Rob was in these assassins that this morning as well. We have the attention there.\n",
            "Summarized text\n",
            " [\"It's not just one of those things that one of the most specific actions we're going to take is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there and not having conflicting queries. Steve will put into the infricky review\"]\n",
            "input text \n",
            " Number seven, just provide provide update on previous conversations. We continue to improve defect tracking and against SLOs. There is a first iteration P.I that we are experimenting to show percentage of defects meeting. And we are going to be able to see the SLOs key findings as ones are hovering at 80% as to at 60. We've been focused mostly on S1 as to this point as hence why S3 and S4s are a lower. And this will likely be the case. We are also in point B are working on the measurement for average open box age. This would give us a whole picture of what's what's left. So the age goes up and down. We are cleaning the backlog. The average age should go down as well. There's no P.I yet, but I just want to update and show up beyond this. It's not a off track. Number C Craig on S2. Yeah, just looking through the charts. And I noted that there's a spike in meantime to close. Yeah, and just want to see if you had any insight into that for us. This is the S2.\n",
            "Summarized text\n",
            " [' number seven tells us that we continue to improve defect tracking and against SLOs. We are going to be able to show percentage of defects meeting as ones are hovering at 80% as to at 60. They are working on the measurement for average open box age.']\n",
            "input text \n",
            " Yeah, this is where the point B on age and supplemental charts in the back end helps. So I haven't seen a dip in age nor the count overall. I think it's the latter. We need to dig in a bit deeper in that. And also the data lag. I would like to re-evaluate when we have a whole picture of when everything is synced in as well. Christie, you have some insights. Yeah, I'm just wondering if part of this could be the fact that we changed the severity across the board for MRs to S2. And so we may have some older bugs in there that hadn't been addressed because they were at a lower severity. Now we've moved them to S2 and maybe that caused a little spike. That could be the case that we did in a limited fashion. It won't be a huge volume. We also iterated after that to pin on priority since product owns prioritization. So I wouldn't account it entirely to that. I mean, this isn't the infertile key review, but. I know that they've gotten backed up on those issues.\n",
            "Summarized text\n",
            " ['The data lag in the back end and the count of MRs and the data lag. The team needs to re-evaluate when we have a whole picture of when everything is synced in as well.']\n",
            "input text \n",
            " So if some some good portion of those are infertile created or related, then that may be lifting it as well. I can take the deeper dig in and then provide an update next time. I think we need extra debug slicing of the data here. So you would like to go to point eight. Yeah, we are now measuring S1 as to SLO achievement with closed bugs. But if you then look at the number of bugs, it's exponential growth. And then it will be trivial to us to achieve 100% SLO achievement. If you just look at close bugs, even though there would be a major problem in the company, 99% of all bugs are overdue. As long as I only close ones that are still within the SLO, I'll have great achievement. So I think we shouldn't be looking at the closed bugs. I think we should be looking at open bugs. The entire population or percentage of those is within the SLO time. I think we're doing it the wrong way. Thanks for the thanks for the feedbacks that.\n",
            "Summarized text\n",
            " [' We are now measuring S1 as to SLO achievement with closed bugs but the entire population or percentage of those is within the SLO time.']\n",
            "input text \n",
            " Hence why we wanted to have the average age to measure what's outside in the open. And then make this iteration to measure also measure focus on the age of all opened, including open bugs. This is also something we have discussed with Christopher in the next iteration as well. And we happy when happy to adjust. So the key. Yes, go ahead. So average age would get closer to it. It's not what I'm proposing. What I'm proposing is off the open bugs are percentages outside of SLO. So display it as a percentage. You do now just do it about the open bugs month or close. Got it. Okay. The exceeding SLO for open bugs. Yeah, or open bugs that are within SLO. So you have a chart that should go up and to the right like everything else. Sounds great. We can take it to the next data metrics work stream to deliver this. Cool. Thanks. Is it pretty good? Yeah, I like it. You make you have to figure out how to. Because we like to be able to have charts that we can historically reconstruct if we need to.\n",
            "Summarized text\n",
            " [\"The average age to measure what's outside in the open and then make this iteration to measure and measure focus on the age of all opened, including open bugs. The average age would get closer to it as a percentage of the open bugs are outside of SLO.\"]\n",
            "input text \n",
            " So in tickets close out, you need to go through their history to figure out at this time when it was open. Did it breach the SLO or not? That's a good point. This might be much harder computationally. And so I totally respect if we can do it for that reason. Yeah, I think that's a good point. Yeah, I think that's a good point. Cool. Nine. Yeah, I just wanted to ask the team like I went through all the key meeting metrics. Everything looked in line with prior periods and look good. Is there anything the team wants to call out? It's mostly that we should be watching. Yeah, I'll call out. So the good news is in Q4. We had our smallest decline over several quarters. So we only went down by a tenth of a point. The quarter previous was point six or six tenths of a point and the quarter before that was a full point. So. We see this as an improvement, even though it was still a decline, but it's still a decline. Obviously, we want this actually tracking in an upward direction.\n",
            "Summarized text\n",
            " ['The team will call out all the key meeting metrics in Q4. The quarter previous was point six or six tenths of a point and the quarter before that was a full point.']\n",
            "input text \n",
            " We also don't have enough data to know whether or not this is an actual real trend up. So I'm optimistic. I think this is a good thing. We have had a much keener focus on us over the past several quarters. And that's why I think, okay, the work that we've done. I think actually is catching up and getting noticed in sus, but we got to keep an eye on it. We can't. We cannot assume that that's the case. Yeah, and the bug discussion above just kind of points out that like we have an underlying problem right now in our metrics measurement. So if we change the measurements to reflect that, then hopefully we're in good shape. If we don't and we flat line and address it so that we flat line open S1s and S2s, you will see a temporary jump in and above SLOs. As we clear out that back, I'll go over that period of time. So we have a point C, which is similar to infrastructure.\n",
            "Summarized text\n",
            " [\" We don't have enough data to know whether or not this is an actual trend up. We have had a much keener focus on us over the past several quarters and we have a temporary jump in and above SLOs.\"]\n",
            "input text \n",
            " We need to get more security work prioritized or hearing that from the team, but neither that problem or that activity is sort of currently reflected in our security metrics. So we have some work to do long term to make sure the we see things like that in the metrics and the measurements that we're making. So back to you said 10. So now that Nero MR rate seems significantly below target. And maybe I helped that it would bounce back from December. I think it bounced back, but not back on target. Any any context there? What's going on? Yeah, so with family and friends days, we actually had some heavier of vacation days. And we historically have one thing to know is that we are actually at a higher MR rate. If you look, if you go back the last 18 months, we're actually at a higher Nero MR rate than we were back in each month this year.\n",
            "Summarized text\n",
            " [\" We need to get more security work prioritized or hearing that from the team, but neither that problem or that activity is currently reflected in our security metrics, so we have some work to do long term to make sure the we see things like that in the metrics and the measurements that we're making\"]\n",
            "input text \n",
            " So if you compare October to October, November to November and January, I'm sorry, October, November, December and January, comparatively to last year, which will find is we're between a half point and a 1.5. MR rate above where we were in the month of previous year. That's great contact. Thank you, Chris, for good work. Yeah, so the expectation is is that February is a short month. We were at I think 16 work days with friends and family day and other things. Obviously seven carriages in Texas doesn't help things either for the folks who are working in Texas. But hopefully the rest of the team is being effective. I was hoping to see a better result right now, but with four or five days, particularly around release week. That's usually when we see do do see a little bit higher activity. So that's not accounted for yet. But you know, Marches, Marches when I'm expecting kind of see a real rebound much like we did last year. Awesome. Thanks.\n",
            "Summarized text\n",
            " ['The MR rate is between a half point and a 1.5. MR rate above where the previous year was in the month of previous year. Chris was hoping to see a little bit higher activity around release week.']\n",
            "input text \n",
            " The other context I'll give is we now do time series targets. So when we change the target, you'll see they're reflected in the line. So if we were to look back historically here, the goal here was actually lower and Christopher was ambitious. So we kept raising it. We kept meeting that. So it should stare step here and we could go back and reconstruct that if we really wanted to. And then ignoring the sort of the seasonal dip here, we raised it to I think 11. And then we realize we're kind of hitting that point of doing and raising returns and the right thing to do business wise. And this is in our FY 22 direction is hold the line at productivity. Let's start to raise other things related to quality security, availability and what not. So that's kind of what you are, you're seeing this bump is we raised it and we realized, okay, that's not the we shouldn't raise it anymore. And we brought it back down to 10. So 10 will be the dark going forward.\n",
            "Summarized text\n",
            " [\"The goal here was lower and Christopher was ambitious so they kept meeting that they kept raising it to 11.11. The other context I'll give is we now do time series targets so we can go back and reconstruct that if we really wanted to.\"]\n",
            "input text \n",
            " I'm going to try to get better a lot of other things while preventing this from dipping. And just want to call out that it's not necessary. Like, and higher MR rates should also help to address security and quality and other things because you're more productive. So you can fix more things so it's not necessarily opposite. But I agree with that. Let's hold the line 10 is then is a great number and and focus on other indicators to improve that makes it on a sense. Cool. Well said. All right, that's the agenda. Anyone want to vocalize anything else? Great. Well, thanks everybody. And I'm going to go check on my four year old and see if she got what whatever she needed. So cheers and toxic.\n",
            "Summarized text\n",
            " [\"I'm going to try to get better a lot of other things while preventing this from dipping.\"]\n",
            "[['Eric Johnson is introducing a proposal to break up the engineering key review into four department key reviews. Eric thinks people feel about that proposal.'], [\" I've got some information about the R&D wider MR rate and the overall MR rate, and the wider community rate are both community contributions and community MRs.\"], [' I believe water MR rate just captures community contributions and no internal rate. The reason we measure data is that one of the most likely failure modes is that we lose the community. The team will use wider to reflect that and narrow is very specific to the team.'], [\"It's when you look at like the development versus infrastructure infrastructure will oftentimes contribute to developments work but it won't be counted as MRs.\"], ['Lily tells Lily that R&D wider MR rate is number MRs per external contributor should not be the number of team members at GitLab. Lily has a childhood emergency outside the door.'], [\"I'm seeing what I'm seeing is a pre-sophisticated taxonomy with prefixes and postfixes to talk about these things but in reality we've only got two names for what they are.\"], ['Lily is on the call and she will work with Max to make that transition of the great.'], [\"Lily and Christopher are discussing the definition of community MRs. They haven't had updates in four days.\"], ['Eric has been trying to get his arms wrapped around the postgres replication issue. Eric was mentioning in the last meeting about an hour ago that the DRI needs to be your kind of data engineering team to focus on getting a handle on some constraints on replication and the replication lag on that slave host'], [' We have an action plan for creating another dedicated host just for the data team to pull from.'], [\"It's not just one of those things that one of the most specific actions we're going to take is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there and not having conflicting queries. Steve will put into the infricky review\"], [' number seven tells us that we continue to improve defect tracking and against SLOs. We are going to be able to show percentage of defects meeting as ones are hovering at 80% as to at 60. They are working on the measurement for average open box age.'], ['The data lag in the back end and the count of MRs and the data lag. The team needs to re-evaluate when we have a whole picture of when everything is synced in as well.'], [' We are now measuring S1 as to SLO achievement with closed bugs but the entire population or percentage of those is within the SLO time.'], [\"The average age to measure what's outside in the open and then make this iteration to measure and measure focus on the age of all opened, including open bugs. The average age would get closer to it as a percentage of the open bugs are outside of SLO.\"], ['The team will call out all the key meeting metrics in Q4. The quarter previous was point six or six tenths of a point and the quarter before that was a full point.'], [\" We don't have enough data to know whether or not this is an actual trend up. We have had a much keener focus on us over the past several quarters and we have a temporary jump in and above SLOs.\"], [\" We need to get more security work prioritized or hearing that from the team, but neither that problem or that activity is currently reflected in our security metrics, so we have some work to do long term to make sure the we see things like that in the metrics and the measurements that we're making\"], ['The MR rate is between a half point and a 1.5. MR rate above where the previous year was in the month of previous year. Chris was hoping to see a little bit higher activity around release week.'], [\"The goal here was lower and Christopher was ambitious so they kept meeting that they kept raising it to 11.11. The other context I'll give is we now do time series targets so we can go back and reconstruct that if we really wanted to.\"], [\"I'm going to try to get better a lot of other things while preventing this from dipping.\"]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = \"\"\n",
        "for x in summarized_text:\n",
        "    for y in x:\n",
        "        summary += y"
      ],
      "metadata": {
        "id": "K9FiUVCTgMrW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "6n3X0dxwgJmG",
        "outputId": "8e60fcd1-e67f-46d3-e7a5-dc15ab74a43d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Eric Johnson is introducing a proposal to break up the engineering key review into four department key reviews. Eric thinks people feel about that proposal. I've got some information about the R&D wider MR rate and the overall MR rate, and the wider community rate are both community contributions and community MRs. I believe water MR rate just captures community contributions and no internal rate. The reason we measure data is that one of the most likely failure modes is that we lose the community. The team will use wider to reflect that and narrow is very specific to the team.It's when you look at like the development versus infrastructure infrastructure will oftentimes contribute to developments work but it won't be counted as MRs.Lily tells Lily that R&D wider MR rate is number MRs per external contributor should not be the number of team members at GitLab. Lily has a childhood emergency outside the door.I'm seeing what I'm seeing is a pre-sophisticated taxonomy with prefixes and postfixes to talk about these things but in reality we've only got two names for what they are.Lily is on the call and she will work with Max to make that transition of the great.Lily and Christopher are discussing the definition of community MRs. They haven't had updates in four days.Eric has been trying to get his arms wrapped around the postgres replication issue. Eric was mentioning in the last meeting about an hour ago that the DRI needs to be your kind of data engineering team to focus on getting a handle on some constraints on replication and the replication lag on that slave host We have an action plan for creating another dedicated host just for the data team to pull from.It's not just one of those things that one of the most specific actions we're going to take is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there and not having conflicting queries. Steve will put into the infricky review number seven tells us that we continue to improve defect tracking and against SLOs. We are going to be able to show percentage of defects meeting as ones are hovering at 80% as to at 60. They are working on the measurement for average open box age.The data lag in the back end and the count of MRs and the data lag. The team needs to re-evaluate when we have a whole picture of when everything is synced in as well. We are now measuring S1 as to SLO achievement with closed bugs but the entire population or percentage of those is within the SLO time.The average age to measure what's outside in the open and then make this iteration to measure and measure focus on the age of all opened, including open bugs. The average age would get closer to it as a percentage of the open bugs are outside of SLO.The team will call out all the key meeting metrics in Q4. The quarter previous was point six or six tenths of a point and the quarter before that was a full point. We don't have enough data to know whether or not this is an actual trend up. We have had a much keener focus on us over the past several quarters and we have a temporary jump in and above SLOs. We need to get more security work prioritized or hearing that from the team, but neither that problem or that activity is currently reflected in our security metrics, so we have some work to do long term to make sure the we see things like that in the metrics and the measurements that we're makingThe MR rate is between a half point and a 1.5. MR rate above where the previous year was in the month of previous year. Chris was hoping to see a little bit higher activity around release week.The goal here was lower and Christopher was ambitious so they kept meeting that they kept raising it to 11.11. The other context I'll give is we now do time series targets so we can go back and reconstruct that if we really wanted to.I'm going to try to get better a lot of other things while preventing this from dipping.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}