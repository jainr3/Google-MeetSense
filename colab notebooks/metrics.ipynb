{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXbzrpyil3l42sTweDT7w2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vHvLDi4j2lmX"
      },
      "outputs": [],
      "source": [
        "text = \"Hi, this is Eric Johnson. It's February 18, 2021, and this is the engineering key review at GitLab. So I've got number four in the agenda, which is a proposal to break up this meeting into four department key reviews. So currently this is engineering. Development quality, security, and UX infrastructure and support to their own key reviews already. I have the reasons why increased visibility able to go deeper. Increased the objectivity with which my reports can manage their groups, allow me more time to focus on new markets and allow me to shift into more of a question asker mode, then generating content and answering questions in these meetings. And to avoid adding three net new meetings to stakeholders counters, I propose we do a sort of two month rotation. So month one development quality go month two security and UX would go. How do people feel about that proposal? I think in the group conversations it's working really well. So I'm supportive and this is the smallest thing. Maybe we need four meetings a month, like it's the biggest department, it's super central. But you proposed this. I don't. I could see either way. So let's stick with the proposal. Go, we'll try it and we'll we can be flexible. I mean, development is larger. Maybe they go more frequently or something. I'll see how it goes. All right. And then I've got number five, which is we've got R&D overall MR rate. And we also have R&D wider MR rate, both as top level KPIs for engineering. So the difference between them in the simplest sense is that R&D wider MR rate includes both community contributions and community MRs. The problems I see with this are that one, the wider MR rate, the one that includes internally and external MRs, it duplicates the overall MR rate, which is. The wider MR rate should just be external, right? And then overall should be narrow plus wider. Oh, yeah. Like we say the wider community. Right, right, right. Okay. So there's. I have to check the taxonomy. Well, like, can you can you confirm? That's that's that's, that's, that's reasoning is my understanding as well. Yeah, I believe water MR rate just captures community contributions. Only and no internal. Yeah, and the reason we measure data is that like one of the most likely failure modes is that we lose the community. Yeah. So we're get, or we're gets goofy is the. When you look at a specific team within the company, there could be contributions outside of that that aren't community contributions. They would be viewed community contributions by that group, but effectively they're not from outside the company. So that's why we use wider to kind of reflect that. And narrow is very specific to the team. But are you saying that if someone in plan contributes to verify its viewed as wider? Not quite that plan plan and verify are just fine. It's when you look at like the development versus infrastructure infrastructure will oftentimes contribute to developments work, but it won't be counted as MRs. Yeah, that's a, that's a potential bit of funkiness that we should talk about separately. I didn't have that in my sort of critique of this, but that that doesn't necessarily make intuitive sense to me. So, so then I think part of my critique of this can be thrown out because it's not as duplicative as I thought, but I still think there's a problem with R&D wider MR rate, which is this thing doesn't really move. In part because it's a rate, so it feels like the way to drive this up is to specifically drive community authors to contribute more than one MR per month. That's how this moves up because it's a productivity rate like we use internally. And that doesn't necessarily feel like the right thing because there's scenarios in which this goes up. We've actually got less contributions overall and less contributors overall. Wait, wait, wait a second. So you're saying that R&D wider MR rate is number MRs per external contributor. Oh my goodness, that should not be the thing. It should be contributions for GitLab team member. So to contribute those, the thing above the division is the external ones. The thing below is the number of team members at GitLab. Is that the case, Lily? I'm checking right now. I think so in our MRs per team member. So unless we start calling people outside the company team member, then it shouldn't be that. Yeah, just clarifying here. So our numerator is community contributions and then our denominator is GitLab team members. So it's not per external member. So we've got what we're doing there, Eric, is we're not trying to say how many MRs does someone send if they send something? How many MRs from external do we get for the size of our organization? Sorry, I have a childhood emergency outside the door. So maybe explain the context behind this. The context is as we grow as a company, we should make sure we keep the community up. Like the logical thing is for the community to flatline and the size of the org to go and before you know, you've kind of outgrown the wider community. Yeah, what I'm seeing is we created this pre-sophisticated taxonomy with prefixes and postfixes to talk about these things. But in reality, we've only got two of them. And it's we keep forgetting, we have a hard time discussing this thing. So I'd rather just name them simply two names for what they are rather than using the taxonomy. But also like in F, I have this proposal of like, what if we just track as a KPI of the percentage of total MRs that come from the community over time? And we would see that drop. I love that. Let's do that instead. But the thing, the thing why we have this complex thing is because you can game that you want to game that you just produce fewer MRs with the engineers that get one. So if you drive that really hard and say this is your number one goal, it's very easy to achieve is just tell all your engineers to produce half. Yeah, so we have we have different metrics to prevent that from happening the same way that like support SLAs and asset kind of buttress one another. I think we're we're robust to that. But simplifying this would make these conversations. If you as our CTO don't even understand them, we went overboard. So I'm supportive. And I forgot and I was agreeing this stuff this morning and like, there's a problem with this and then you just remind me of the context. So yeah, I can't really have my head. A percentage that come from the community. I love that. It's what all our investors ask about. Let's do that. Okay. Cool. So, um, Lily, if you can work with Max to make that transition of the great. And I'll hold the one that we're talking about. That's from the mulberry. Thanks. I'm on the call. Sorry, it was a bit late. Timeline. We do have PIs on the raw number of community MRs and we can make the shift. And why they're confirming from the definition, I think why they only counts for community. And that's that's what the definition is. Cool. All right. So number six, then Christopher. Sorry, I was looking up to see if I had the percentage graph because I think we played around with this at one point and had a draft of that. Probably about five months back, if I can remember, Lily. Just in FYI month of February, if you were looking at any particular metrics, particularly in development at MR rate. We haven't had updates in four days. There's apparently a lag issue that's been problematic for the data team to basically get updated metrics and they're working on that. Okay. I'm sorry, Max. You get the next one. So yeah, there's some some color there on the on the medication, the lag later on. On to on to seven. We continue. I said FYI in addition to the TBI status. I'm sorry. I wanted to just touch on the postgres replication issue there real quick. I've been trying to get my arms wrapped around it. Um, do we have the right attention to this? This is kind of Eric. I don't know if you were commenting on. Hitting towards this in the last meeting around some of the infrastructure improvements on the product side. I'm just not quite sure whose responsibility is to focus on getting a handle on some of the constraints we have on replication. So what I was mentioning in the in the product queue review about an hour ago is I think is sort of like unrelated. And so I think the DRI needs to be your kind of data engineering team. But of course there's a dependency on infrastructure because that's where the data is being piqued from. They they do on that data source. So let's say for the replication lag on that slave host where I'm sorry not the on the the secondary host where the data is being pulled from like infrastructure would be the DRI for that. And so any escalations but well all those. And I know we have an action plan for that as far as creating another dedicated host just for the data team to pull from. I did ask I saw that issue and I did talk to Craig gums a little bit as well on the database side just to see if there's some database improvements and I'm still trying to figure out, you know, if it's truly just dedicated computation old sort of resource a server. Or if there's actually some some database tuning that needs to occur, do you have a sense of that. There's so I'd say it's it's three different things. It's having a dedicated host that doesn't have conflicting query traffic coming from other other workloads. There are some tuning performance or tuning improvements to be made. And then there's also improvements in and this is where it does maybe relate a little bit to what the topic was in the last review basically the overall demand on the database layer from from dot com activities and like improving those. It's definitely not just one of those things that one of the most specific actions we're going to take though is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there. And not having conflicting query. And conflicting queries affect the ability to update the replication. Steve, I definitely want to partner with you on this one because I think the the demand on those databases is only going to increase. It's not going down. And I think we need to get. I'm still unclear on where to focus and to get the biggest bang for the buck. I think of the computational resource dedication that's going to be a good thing, but I'll probably going to squeeze the balloon. Next area will will honor itself. Okay, I'll put into the infricky review for next week. Okay, on this issue. Thank you, Steve. So then back to mecon 7 or. Yes. Thank you. And Rob was in these assassins that this morning as well. We have the attention there. Number seven, just provide provide update on previous conversations. We continue to improve defect tracking and against SLOs. There is a first iteration P.I that we are experimenting to show percentage of defects meeting. And we are going to be able to see the SLOs key findings as ones are hovering at 80% as to at 60. We've been focused mostly on S1 as to this point as hence why S3 and S4s are a lower. And this will likely be the case. We are also in point B are working on the measurement for average open box age. This would give us a whole picture of what's what's left. So the age goes up and down. We are cleaning the backlog. The average age should go down as well. There's no P.I yet, but I just want to update and show up beyond this. It's not a off track. Number C Craig on S2. Yeah, just looking through the charts. And I noted that there's a spike in meantime to close. Yeah, and just want to see if you had any insight into that for us. This is the S2. Yeah, this is where the point B on age and supplemental charts in the back end helps. So I haven't seen a dip in age nor the count overall. I think it's the latter. We need to dig in a bit deeper in that. And also the data lag. I would like to re-evaluate when we have a whole picture of when everything is synced in as well. Christie, you have some insights. Yeah, I'm just wondering if part of this could be the fact that we changed the severity across the board for MRs to S2. And so we may have some older bugs in there that hadn't been addressed because they were at a lower severity. Now we've moved them to S2 and maybe that caused a little spike. That could be the case that we did in a limited fashion. It won't be a huge volume. We also iterated after that to pin on priority since product owns prioritization. So I wouldn't account it entirely to that. I mean, this isn't the infertile key review, but. I know that they've gotten backed up on those issues. So if some some good portion of those are infertile created or related, then that may be lifting it as well. I can take the deeper dig in and then provide an update next time. I think we need extra debug slicing of the data here. So you would like to go to point eight. Yeah, we are now measuring S1 as to SLO achievement with closed bugs. But if you then look at the number of bugs, it's exponential growth. And then it will be trivial to us to achieve 100% SLO achievement. If you just look at close bugs, even though there would be a major problem in the company, 99% of all bugs are overdue. As long as I only close ones that are still within the SLO, I'll have great achievement. So I think we shouldn't be looking at the closed bugs. I think we should be looking at open bugs. The entire population or percentage of those is within the SLO time. I think we're doing it the wrong way. Thanks for the thanks for the feedbacks that. Hence why we wanted to have the average age to measure what's outside in the open. And then make this iteration to measure also measure focus on the age of all opened, including open bugs. This is also something we have discussed with Christopher in the next iteration as well. And we happy when happy to adjust. So the key. Yes, go ahead. So average age would get closer to it. It's not what I'm proposing. What I'm proposing is off the open bugs are percentages outside of SLO. So display it as a percentage. You do now just do it about the open bugs month or close. Got it. Okay. The exceeding SLO for open bugs. Yeah, or open bugs that are within SLO. So you have a chart that should go up and to the right like everything else. Sounds great. We can take it to the next data metrics work stream to deliver this. Cool. Thanks. Is it pretty good? Yeah, I like it. You make you have to figure out how to. Because we like to be able to have charts that we can historically reconstruct if we need to. So in tickets close out, you need to go through their history to figure out at this time when it was open. Did it breach the SLO or not? That's a good point. This might be much harder computationally. And so I totally respect if we can do it for that reason. Yeah, I think that's a good point. Yeah, I think that's a good point. Cool. Nine. Yeah, I just wanted to ask the team like I went through all the key meeting metrics. Everything looked in line with prior periods and look good. Is there anything the team wants to call out? It's mostly that we should be watching. Yeah, I'll call out. So the good news is in Q4. We had our smallest decline over several quarters. So we only went down by a tenth of a point. The quarter previous was point six or six tenths of a point and the quarter before that was a full point. So. We see this as an improvement, even though it was still a decline, but it's still a decline. Obviously, we want this actually tracking in an upward direction. We also don't have enough data to know whether or not this is an actual real trend up. So I'm optimistic. I think this is a good thing. We have had a much keener focus on us over the past several quarters. And that's why I think, okay, the work that we've done. I think actually is catching up and getting noticed in sus, but we got to keep an eye on it. We can't. We cannot assume that that's the case. Yeah, and the bug discussion above just kind of points out that like we have an underlying problem right now in our metrics measurement. So if we change the measurements to reflect that, then hopefully we're in good shape. If we don't and we flat line and address it so that we flat line open S1s and S2s, you will see a temporary jump in and above SLOs. As we clear out that back, I'll go over that period of time. So we have a point C, which is similar to infrastructure. We need to get more security work prioritized or hearing that from the team, but neither that problem or that activity is sort of currently reflected in our security metrics. So we have some work to do long term to make sure the we see things like that in the metrics and the measurements that we're making. So back to you said 10. So now that Nero MR rate seems significantly below target. And maybe I helped that it would bounce back from December. I think it bounced back, but not back on target. Any any context there? What's going on? Yeah, so with family and friends days, we actually had some heavier of vacation days. And we historically have one thing to know is that we are actually at a higher MR rate. If you look, if you go back the last 18 months, we're actually at a higher Nero MR rate than we were back in each month this year. So if you compare October to October, November to November and January, I'm sorry, October, November, December and January, comparatively to last year, which will find is we're between a half point and a 1.5. MR rate above where we were in the month of previous year. That's great contact. Thank you, Chris, for good work. Yeah, so the expectation is is that February is a short month. We were at I think 16 work days with friends and family day and other things. Obviously seven carriages in Texas doesn't help things either for the folks who are working in Texas. But hopefully the rest of the team is being effective. I was hoping to see a better result right now, but with four or five days, particularly around release week. That's usually when we see do do see a little bit higher activity. So that's not accounted for yet. But you know, Marches, Marches when I'm expecting kind of see a real rebound much like we did last year. Awesome. Thanks. The other context I'll give is we now do time series targets. So when we change the target, you'll see they're reflected in the line. So if we were to look back historically here, the goal here was actually lower and Christopher was ambitious. So we kept raising it. We kept meeting that. So it should stare step here and we could go back and reconstruct that if we really wanted to. And then ignoring the sort of the seasonal dip here, we raised it to I think 11. And then we realize we're kind of hitting that point of doing and raising returns and the right thing to do business wise. And this is in our FY 22 direction is hold the line at productivity. Let's start to raise other things related to quality security, availability and what not. So that's kind of what you are, you're seeing this bump is we raised it and we realized, okay, that's not the we shouldn't raise it anymore. And we brought it back down to 10. So 10 will be the dark going forward. I'm going to try to get better a lot of other things while preventing this from dipping. And just want to call out that it's not necessary. Like, and higher MR rates should also help to address security and quality and other things because you're more productive. So you can fix more things so it's not necessarily opposite. But I agree with that. Let's hold the line 10 is then is a great number and and focus on other indicators to improve that makes it on a sense. Cool. Well said. All right, that's the agenda. Anyone want to vocalize anything else? Great. Well, thanks everybody. And I'm going to go check on my four year old and see if she got what whatever she needed. So cheers and toxic.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filler Words"
      ],
      "metadata": {
        "id": "Um2dZyHB20hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.toastmasters.org/magazine/magazine-issues/2019/feb/drop-those-crutches#:~:text=These%20include%20words%20such%20as,overuse%2C%20and%202)%20meaninglessness.\n",
        "# https://huggingface.co/spaces/rafiuddin/whisper-conversation-analysis/blob/main/app.py#L8\n",
        "# https://www.thesaurus.com/e/writing/filler-words/\n",
        "filler_word_list=[\"um\",\"huh\",\"oh\",\"er\",\"ah\",\"uh\",\"very\",\"really\",\"highly\",\"like\",\"so\",\"and\",\"but\",\"ok\",\"okay\",\"well\",\"now\",\"literally\",\"definitely\",\"actually\",\"basically\",\"totally\",\"seriously\",\"right\",\"just\"]\n",
        "filler_two_words_list = [\"i guess\", \"i mean\", \"you know\", \"i suppose\"]"
      ],
      "metadata": {
        "id": "Nwm1oslG2ois"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, string\n",
        "\n",
        "word_counts = {}\n",
        "\n",
        "a = string.punctuation.replace(\"'\", \"\")\n",
        "\n",
        "text_tokens = re.sub(r'[0-9]', '', text)\n",
        "#text_tokens = re.sub(r'[^\\w\\s]', '', text_tokens)\n",
        "text_tokens = re.sub(r'[{}]'.format(a), '', text_tokens)\n",
        "text_tokens = text_tokens.strip().split()\n",
        "\n",
        "for word in text_tokens:\n",
        "    lower_word = word.lower()\n",
        "    if lower_word not in word_counts:\n",
        "        word_counts[lower_word] = 0\n",
        "    word_counts[lower_word] += 1"
      ],
      "metadata": {
        "id": "l2_FTRV22_mt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnbSjFXm5WA8",
        "outputId": "ca28bc71-c359-4c12-b7b3-832413dd7787"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', 'this', 'is', 'Eric', 'Johnson', \"It's\", 'February', 'and', 'this', 'is', 'the', 'engineering', 'key', 'review', 'at', 'GitLab', 'So', \"I've\", 'got', 'number', 'four', 'in', 'the', 'agenda', 'which', 'is', 'a', 'proposal', 'to', 'break', 'up', 'this', 'meeting', 'into', 'four', 'department', 'key', 'reviews', 'So', 'currently', 'this', 'is', 'engineering', 'Development', 'quality', 'security', 'and', 'UX', 'infrastructure', 'and', 'support', 'to', 'their', 'own', 'key', 'reviews', 'already', 'I', 'have', 'the', 'reasons', 'why', 'increased', 'visibility', 'able', 'to', 'go', 'deeper', 'Increased', 'the', 'objectivity', 'with', 'which', 'my', 'reports', 'can', 'manage', 'their', 'groups', 'allow', 'me', 'more', 'time', 'to', 'focus', 'on', 'new', 'markets', 'and', 'allow', 'me', 'to', 'shift', 'into', 'more', 'of', 'a', 'question', 'asker', 'mode', 'then', 'generating', 'content', 'and', 'answering', 'questions', 'in', 'these', 'meetings', 'And', 'to', 'avoid', 'adding', 'three', 'net', 'new', 'meetings', 'to', 'stakeholders', 'counters', 'I', 'propose', 'we', 'do', 'a', 'sort', 'of', 'two', 'month', 'rotation', 'So', 'month', 'one', 'development', 'quality', 'go', 'month', 'two', 'security', 'and', 'UX', 'would', 'go', 'How', 'do', 'people', 'feel', 'about', 'that', 'proposal', 'I', 'think', 'in', 'the', 'group', 'conversations', \"it's\", 'working', 'really', 'well', 'So', \"I'm\", 'supportive', 'and', 'this', 'is', 'the', 'smallest', 'thing', 'Maybe', 'we', 'need', 'four', 'meetings', 'a', 'month', 'like', \"it's\", 'the', 'biggest', 'department', \"it's\", 'super', 'central', 'But', 'you', 'proposed', 'this', 'I', \"don't\", 'I', 'could', 'see', 'either', 'way', 'So', \"let's\", 'stick', 'with', 'the', 'proposal', 'Go', \"we'll\", 'try', 'it', 'and', \"we'll\", 'we', 'can', 'be', 'flexible', 'I', 'mean', 'development', 'is', 'larger', 'Maybe', 'they', 'go', 'more', 'frequently', 'or', 'something', \"I'll\", 'see', 'how', 'it', 'goes', 'All', 'right', 'And', 'then', \"I've\", 'got', 'number', 'five', 'which', 'is', \"we've\", 'got', 'RD', 'overall', 'MR', 'rate', 'And', 'we', 'also', 'have', 'RD', 'wider', 'MR', 'rate', 'both', 'as', 'top', 'level', 'KPIs', 'for', 'engineering', 'So', 'the', 'difference', 'between', 'them', 'in', 'the', 'simplest', 'sense', 'is', 'that', 'RD', 'wider', 'MR', 'rate', 'includes', 'both', 'community', 'contributions', 'and', 'community', 'MRs', 'The', 'problems', 'I', 'see', 'with', 'this', 'are', 'that', 'one', 'the', 'wider', 'MR', 'rate', 'the', 'one', 'that', 'includes', 'internally', 'and', 'external', 'MRs', 'it', 'duplicates', 'the', 'overall', 'MR', 'rate', 'which', 'is', 'The', 'wider', 'MR', 'rate', 'should', 'just', 'be', 'external', 'right', 'And', 'then', 'overall', 'should', 'be', 'narrow', 'plus', 'wider', 'Oh', 'yeah', 'Like', 'we', 'say', 'the', 'wider', 'community', 'Right', 'right', 'right', 'Okay', 'So', \"there's\", 'I', 'have', 'to', 'check', 'the', 'taxonomy', 'Well', 'like', 'can', 'you', 'can', 'you', 'confirm', \"That's\", \"that's\", \"that's\", \"that's\", \"that's\", 'reasoning', 'is', 'my', 'understanding', 'as', 'well', 'Yeah', 'I', 'believe', 'water', 'MR', 'rate', 'just', 'captures', 'community', 'contributions', 'Only', 'and', 'no', 'internal', 'Yeah', 'and', 'the', 'reason', 'we', 'measure', 'data', 'is', 'that', 'like', 'one', 'of', 'the', 'most', 'likely', 'failure', 'modes', 'is', 'that', 'we', 'lose', 'the', 'community', 'Yeah', 'So', \"we're\", 'get', 'or', \"we're\", 'gets', 'goofy', 'is', 'the', 'When', 'you', 'look', 'at', 'a', 'specific', 'team', 'within', 'the', 'company', 'there', 'could', 'be', 'contributions', 'outside', 'of', 'that', 'that', \"aren't\", 'community', 'contributions', 'They', 'would', 'be', 'viewed', 'community', 'contributions', 'by', 'that', 'group', 'but', 'effectively', \"they're\", 'not', 'from', 'outside', 'the', 'company', 'So', \"that's\", 'why', 'we', 'use', 'wider', 'to', 'kind', 'of', 'reflect', 'that', 'And', 'narrow', 'is', 'very', 'specific', 'to', 'the', 'team', 'But', 'are', 'you', 'saying', 'that', 'if', 'someone', 'in', 'plan', 'contributes', 'to', 'verify', 'its', 'viewed', 'as', 'wider', 'Not', 'quite', 'that', 'plan', 'plan', 'and', 'verify', 'are', 'just', 'fine', \"It's\", 'when', 'you', 'look', 'at', 'like', 'the', 'development', 'versus', 'infrastructure', 'infrastructure', 'will', 'oftentimes', 'contribute', 'to', 'developments', 'work', 'but', 'it', \"won't\", 'be', 'counted', 'as', 'MRs', 'Yeah', \"that's\", 'a', \"that's\", 'a', 'potential', 'bit', 'of', 'funkiness', 'that', 'we', 'should', 'talk', 'about', 'separately', 'I', \"didn't\", 'have', 'that', 'in', 'my', 'sort', 'of', 'critique', 'of', 'this', 'but', 'that', 'that', \"doesn't\", 'necessarily', 'make', 'intuitive', 'sense', 'to', 'me', 'So', 'so', 'then', 'I', 'think', 'part', 'of', 'my', 'critique', 'of', 'this', 'can', 'be', 'thrown', 'out', 'because', \"it's\", 'not', 'as', 'duplicative', 'as', 'I', 'thought', 'but', 'I', 'still', 'think', \"there's\", 'a', 'problem', 'with', 'RD', 'wider', 'MR', 'rate', 'which', 'is', 'this', 'thing', \"doesn't\", 'really', 'move', 'In', 'part', 'because', \"it's\", 'a', 'rate', 'so', 'it', 'feels', 'like', 'the', 'way', 'to', 'drive', 'this', 'up', 'is', 'to', 'specifically', 'drive', 'community', 'authors', 'to', 'contribute', 'more', 'than', 'one', 'MR', 'per', 'month', \"That's\", 'how', 'this', 'moves', 'up', 'because', \"it's\", 'a', 'productivity', 'rate', 'like', 'we', 'use', 'internally', 'And', 'that', \"doesn't\", 'necessarily', 'feel', 'like', 'the', 'right', 'thing', 'because', \"there's\", 'scenarios', 'in', 'which', 'this', 'goes', 'up', \"We've\", 'actually', 'got', 'less', 'contributions', 'overall', 'and', 'less', 'contributors', 'overall', 'Wait', 'wait', 'wait', 'a', 'second', 'So', \"you're\", 'saying', 'that', 'RD', 'wider', 'MR', 'rate', 'is', 'number', 'MRs', 'per', 'external', 'contributor', 'Oh', 'my', 'goodness', 'that', 'should', 'not', 'be', 'the', 'thing', 'It', 'should', 'be', 'contributions', 'for', 'GitLab', 'team', 'member', 'So', 'to', 'contribute', 'those', 'the', 'thing', 'above', 'the', 'division', 'is', 'the', 'external', 'ones', 'The', 'thing', 'below', 'is', 'the', 'number', 'of', 'team', 'members', 'at', 'GitLab', 'Is', 'that', 'the', 'case', 'Lily', \"I'm\", 'checking', 'right', 'now', 'I', 'think', 'so', 'in', 'our', 'MRs', 'per', 'team', 'member', 'So', 'unless', 'we', 'start', 'calling', 'people', 'outside', 'the', 'company', 'team', 'member', 'then', 'it', \"shouldn't\", 'be', 'that', 'Yeah', 'just', 'clarifying', 'here', 'So', 'our', 'numerator', 'is', 'community', 'contributions', 'and', 'then', 'our', 'denominator', 'is', 'GitLab', 'team', 'members', 'So', \"it's\", 'not', 'per', 'external', 'member', 'So', \"we've\", 'got', 'what', \"we're\", 'doing', 'there', 'Eric', 'is', \"we're\", 'not', 'trying', 'to', 'say', 'how', 'many', 'MRs', 'does', 'someone', 'send', 'if', 'they', 'send', 'something', 'How', 'many', 'MRs', 'from', 'external', 'do', 'we', 'get', 'for', 'the', 'size', 'of', 'our', 'organization', 'Sorry', 'I', 'have', 'a', 'childhood', 'emergency', 'outside', 'the', 'door', 'So', 'maybe', 'explain', 'the', 'context', 'behind', 'this', 'The', 'context', 'is', 'as', 'we', 'grow', 'as', 'a', 'company', 'we', 'should', 'make', 'sure', 'we', 'keep', 'the', 'community', 'up', 'Like', 'the', 'logical', 'thing', 'is', 'for', 'the', 'community', 'to', 'flatline', 'and', 'the', 'size', 'of', 'the', 'org', 'to', 'go', 'and', 'before', 'you', 'know', \"you've\", 'kind', 'of', 'outgrown', 'the', 'wider', 'community', 'Yeah', 'what', \"I'm\", 'seeing', 'is', 'we', 'created', 'this', 'presophisticated', 'taxonomy', 'with', 'prefixes', 'and', 'postfixes', 'to', 'talk', 'about', 'these', 'things', 'But', 'in', 'reality', \"we've\", 'only', 'got', 'two', 'of', 'them', 'And', \"it's\", 'we', 'keep', 'forgetting', 'we', 'have', 'a', 'hard', 'time', 'discussing', 'this', 'thing', 'So', \"I'd\", 'rather', 'just', 'name', 'them', 'simply', 'two', 'names', 'for', 'what', 'they', 'are', 'rather', 'than', 'using', 'the', 'taxonomy', 'But', 'also', 'like', 'in', 'F', 'I', 'have', 'this', 'proposal', 'of', 'like', 'what', 'if', 'we', 'just', 'track', 'as', 'a', 'KPI', 'of', 'the', 'percentage', 'of', 'total', 'MRs', 'that', 'come', 'from', 'the', 'community', 'over', 'time', 'And', 'we', 'would', 'see', 'that', 'drop', 'I', 'love', 'that', \"Let's\", 'do', 'that', 'instead', 'But', 'the', 'thing', 'the', 'thing', 'why', 'we', 'have', 'this', 'complex', 'thing', 'is', 'because', 'you', 'can', 'game', 'that', 'you', 'want', 'to', 'game', 'that', 'you', 'just', 'produce', 'fewer', 'MRs', 'with', 'the', 'engineers', 'that', 'get', 'one', 'So', 'if', 'you', 'drive', 'that', 'really', 'hard', 'and', 'say', 'this', 'is', 'your', 'number', 'one', 'goal', \"it's\", 'very', 'easy', 'to', 'achieve', 'is', 'just', 'tell', 'all', 'your', 'engineers', 'to', 'produce', 'half', 'Yeah', 'so', 'we', 'have', 'we', 'have', 'different', 'metrics', 'to', 'prevent', 'that', 'from', 'happening', 'the', 'same', 'way', 'that', 'like', 'support', 'SLAs', 'and', 'asset', 'kind', 'of', 'buttress', 'one', 'another', 'I', 'think', \"we're\", \"we're\", 'robust', 'to', 'that', 'But', 'simplifying', 'this', 'would', 'make', 'these', 'conversations', 'If', 'you', 'as', 'our', 'CTO', \"don't\", 'even', 'understand', 'them', 'we', 'went', 'overboard', 'So', \"I'm\", 'supportive', 'And', 'I', 'forgot', 'and', 'I', 'was', 'agreeing', 'this', 'stuff', 'this', 'morning', 'and', 'like', \"there's\", 'a', 'problem', 'with', 'this', 'and', 'then', 'you', 'just', 'remind', 'me', 'of', 'the', 'context', 'So', 'yeah', 'I', \"can't\", 'really', 'have', 'my', 'head', 'A', 'percentage', 'that', 'come', 'from', 'the', 'community', 'I', 'love', 'that', \"It's\", 'what', 'all', 'our', 'investors', 'ask', 'about', \"Let's\", 'do', 'that', 'Okay', 'Cool', 'So', 'um', 'Lily', 'if', 'you', 'can', 'work', 'with', 'Max', 'to', 'make', 'that', 'transition', 'of', 'the', 'great', 'And', \"I'll\", 'hold', 'the', 'one', 'that', \"we're\", 'talking', 'about', \"That's\", 'from', 'the', 'mulberry', 'Thanks', \"I'm\", 'on', 'the', 'call', 'Sorry', 'it', 'was', 'a', 'bit', 'late', 'Timeline', 'We', 'do', 'have', 'PIs', 'on', 'the', 'raw', 'number', 'of', 'community', 'MRs', 'and', 'we', 'can', 'make', 'the', 'shift', 'And', 'why', \"they're\", 'confirming', 'from', 'the', 'definition', 'I', 'think', 'why', 'they', 'only', 'counts', 'for', 'community', 'And', \"that's\", \"that's\", 'what', 'the', 'definition', 'is', 'Cool', 'All', 'right', 'So', 'number', 'six', 'then', 'Christopher', 'Sorry', 'I', 'was', 'looking', 'up', 'to', 'see', 'if', 'I', 'had', 'the', 'percentage', 'graph', 'because', 'I', 'think', 'we', 'played', 'around', 'with', 'this', 'at', 'one', 'point', 'and', 'had', 'a', 'draft', 'of', 'that', 'Probably', 'about', 'five', 'months', 'back', 'if', 'I', 'can', 'remember', 'Lily', 'Just', 'in', 'FYI', 'month', 'of', 'February', 'if', 'you', 'were', 'looking', 'at', 'any', 'particular', 'metrics', 'particularly', 'in', 'development', 'at', 'MR', 'rate', 'We', \"haven't\", 'had', 'updates', 'in', 'four', 'days', \"There's\", 'apparently', 'a', 'lag', 'issue', \"that's\", 'been', 'problematic', 'for', 'the', 'data', 'team', 'to', 'basically', 'get', 'updated', 'metrics', 'and', \"they're\", 'working', 'on', 'that', 'Okay', \"I'm\", 'sorry', 'Max', 'You', 'get', 'the', 'next', 'one', 'So', 'yeah', \"there's\", 'some', 'some', 'color', 'there', 'on', 'the', 'on', 'the', 'medication', 'the', 'lag', 'later', 'on', 'On', 'to', 'on', 'to', 'seven', 'We', 'continue', 'I', 'said', 'FYI', 'in', 'addition', 'to', 'the', 'TBI', 'status', \"I'm\", 'sorry', 'I', 'wanted', 'to', 'just', 'touch', 'on', 'the', 'postgres', 'replication', 'issue', 'there', 'real', 'quick', \"I've\", 'been', 'trying', 'to', 'get', 'my', 'arms', 'wrapped', 'around', 'it', 'Um', 'do', 'we', 'have', 'the', 'right', 'attention', 'to', 'this', 'This', 'is', 'kind', 'of', 'Eric', 'I', \"don't\", 'know', 'if', 'you', 'were', 'commenting', 'on', 'Hitting', 'towards', 'this', 'in', 'the', 'last', 'meeting', 'around', 'some', 'of', 'the', 'infrastructure', 'improvements', 'on', 'the', 'product', 'side', \"I'm\", 'just', 'not', 'quite', 'sure', 'whose', 'responsibility', 'is', 'to', 'focus', 'on', 'getting', 'a', 'handle', 'on', 'some', 'of', 'the', 'constraints', 'we', 'have', 'on', 'replication', 'So', 'what', 'I', 'was', 'mentioning', 'in', 'the', 'in', 'the', 'product', 'queue', 'review', 'about', 'an', 'hour', 'ago', 'is', 'I', 'think', 'is', 'sort', 'of', 'like', 'unrelated', 'And', 'so', 'I', 'think', 'the', 'DRI', 'needs', 'to', 'be', 'your', 'kind', 'of', 'data', 'engineering', 'team', 'But', 'of', 'course', \"there's\", 'a', 'dependency', 'on', 'infrastructure', 'because', \"that's\", 'where', 'the', 'data', 'is', 'being', 'piqued', 'from', 'They', 'they', 'do', 'on', 'that', 'data', 'source', 'So', \"let's\", 'say', 'for', 'the', 'replication', 'lag', 'on', 'that', 'slave', 'host', 'where', \"I'm\", 'sorry', 'not', 'the', 'on', 'the', 'the', 'secondary', 'host', 'where', 'the', 'data', 'is', 'being', 'pulled', 'from', 'like', 'infrastructure', 'would', 'be', 'the', 'DRI', 'for', 'that', 'And', 'so', 'any', 'escalations', 'but', 'well', 'all', 'those', 'And', 'I', 'know', 'we', 'have', 'an', 'action', 'plan', 'for', 'that', 'as', 'far', 'as', 'creating', 'another', 'dedicated', 'host', 'just', 'for', 'the', 'data', 'team', 'to', 'pull', 'from', 'I', 'did', 'ask', 'I', 'saw', 'that', 'issue', 'and', 'I', 'did', 'talk', 'to', 'Craig', 'gums', 'a', 'little', 'bit', 'as', 'well', 'on', 'the', 'database', 'side', 'just', 'to', 'see', 'if', \"there's\", 'some', 'database', 'improvements', 'and', \"I'm\", 'still', 'trying', 'to', 'figure', 'out', 'you', 'know', 'if', \"it's\", 'truly', 'just', 'dedicated', 'computation', 'old', 'sort', 'of', 'resource', 'a', 'server', 'Or', 'if', \"there's\", 'actually', 'some', 'some', 'database', 'tuning', 'that', 'needs', 'to', 'occur', 'do', 'you', 'have', 'a', 'sense', 'of', 'that', \"There's\", 'so', \"I'd\", 'say', \"it's\", \"it's\", 'three', 'different', 'things', \"It's\", 'having', 'a', 'dedicated', 'host', 'that', \"doesn't\", 'have', 'conflicting', 'query', 'traffic', 'coming', 'from', 'other', 'other', 'workloads', 'There', 'are', 'some', 'tuning', 'performance', 'or', 'tuning', 'improvements', 'to', 'be', 'made', 'And', 'then', \"there's\", 'also', 'improvements', 'in', 'and', 'this', 'is', 'where', 'it', 'does', 'maybe', 'relate', 'a', 'little', 'bit', 'to', 'what', 'the', 'topic', 'was', 'in', 'the', 'last', 'review', 'basically', 'the', 'overall', 'demand', 'on', 'the', 'database', 'layer', 'from', 'from', 'dot', 'com', 'activities', 'and', 'like', 'improving', 'those', \"It's\", 'definitely', 'not', 'just', 'one', 'of', 'those', 'things', 'that', 'one', 'of', 'the', 'most', 'specific', 'actions', \"we're\", 'going', 'to', 'take', 'though', 'is', 'separating', 'out', 'and', 'having', 'a', 'dedicated', 'host', 'so', 'that', \"we're\", 'just', 'dealing', 'with', 'the', 'profile', 'of', 'the', 'data', 'engineering', 'traffic', 'on', 'there', 'And', 'not', 'having', 'conflicting', 'query', 'And', 'conflicting', 'queries', 'affect', 'the', 'ability', 'to', 'update', 'the', 'replication', 'Steve', 'I', 'definitely', 'want', 'to', 'partner', 'with', 'you', 'on', 'this', 'one', 'because', 'I', 'think', 'the', 'the', 'demand', 'on', 'those', 'databases', 'is', 'only', 'going', 'to', 'increase', \"It's\", 'not', 'going', 'down', 'And', 'I', 'think', 'we', 'need', 'to', 'get', \"I'm\", 'still', 'unclear', 'on', 'where', 'to', 'focus', 'and', 'to', 'get', 'the', 'biggest', 'bang', 'for', 'the', 'buck', 'I', 'think', 'of', 'the', 'computational', 'resource', 'dedication', \"that's\", 'going', 'to', 'be', 'a', 'good', 'thing', 'but', \"I'll\", 'probably', 'going', 'to', 'squeeze', 'the', 'balloon', 'Next', 'area', 'will', 'will', 'honor', 'itself', 'Okay', \"I'll\", 'put', 'into', 'the', 'infricky', 'review', 'for', 'next', 'week', 'Okay', 'on', 'this', 'issue', 'Thank', 'you', 'Steve', 'So', 'then', 'back', 'to', 'mecon', 'or', 'Yes', 'Thank', 'you', 'And', 'Rob', 'was', 'in', 'these', 'assassins', 'that', 'this', 'morning', 'as', 'well', 'We', 'have', 'the', 'attention', 'there', 'Number', 'seven', 'just', 'provide', 'provide', 'update', 'on', 'previous', 'conversations', 'We', 'continue', 'to', 'improve', 'defect', 'tracking', 'and', 'against', 'SLOs', 'There', 'is', 'a', 'first', 'iteration', 'PI', 'that', 'we', 'are', 'experimenting', 'to', 'show', 'percentage', 'of', 'defects', 'meeting', 'And', 'we', 'are', 'going', 'to', 'be', 'able', 'to', 'see', 'the', 'SLOs', 'key', 'findings', 'as', 'ones', 'are', 'hovering', 'at', 'as', 'to', 'at', \"We've\", 'been', 'focused', 'mostly', 'on', 'S', 'as', 'to', 'this', 'point', 'as', 'hence', 'why', 'S', 'and', 'Ss', 'are', 'a', 'lower', 'And', 'this', 'will', 'likely', 'be', 'the', 'case', 'We', 'are', 'also', 'in', 'point', 'B', 'are', 'working', 'on', 'the', 'measurement', 'for', 'average', 'open', 'box', 'age', 'This', 'would', 'give', 'us', 'a', 'whole', 'picture', 'of', \"what's\", \"what's\", 'left', 'So', 'the', 'age', 'goes', 'up', 'and', 'down', 'We', 'are', 'cleaning', 'the', 'backlog', 'The', 'average', 'age', 'should', 'go', 'down', 'as', 'well', \"There's\", 'no', 'PI', 'yet', 'but', 'I', 'just', 'want', 'to', 'update', 'and', 'show', 'up', 'beyond', 'this', \"It's\", 'not', 'a', 'off', 'track', 'Number', 'C', 'Craig', 'on', 'S', 'Yeah', 'just', 'looking', 'through', 'the', 'charts', 'And', 'I', 'noted', 'that', \"there's\", 'a', 'spike', 'in', 'meantime', 'to', 'close', 'Yeah', 'and', 'just', 'want', 'to', 'see', 'if', 'you', 'had', 'any', 'insight', 'into', 'that', 'for', 'us', 'This', 'is', 'the', 'S', 'Yeah', 'this', 'is', 'where', 'the', 'point', 'B', 'on', 'age', 'and', 'supplemental', 'charts', 'in', 'the', 'back', 'end', 'helps', 'So', 'I', \"haven't\", 'seen', 'a', 'dip', 'in', 'age', 'nor', 'the', 'count', 'overall', 'I', 'think', \"it's\", 'the', 'latter', 'We', 'need', 'to', 'dig', 'in', 'a', 'bit', 'deeper', 'in', 'that', 'And', 'also', 'the', 'data', 'lag', 'I', 'would', 'like', 'to', 'reevaluate', 'when', 'we', 'have', 'a', 'whole', 'picture', 'of', 'when', 'everything', 'is', 'synced', 'in', 'as', 'well', 'Christie', 'you', 'have', 'some', 'insights', 'Yeah', \"I'm\", 'just', 'wondering', 'if', 'part', 'of', 'this', 'could', 'be', 'the', 'fact', 'that', 'we', 'changed', 'the', 'severity', 'across', 'the', 'board', 'for', 'MRs', 'to', 'S', 'And', 'so', 'we', 'may', 'have', 'some', 'older', 'bugs', 'in', 'there', 'that', \"hadn't\", 'been', 'addressed', 'because', 'they', 'were', 'at', 'a', 'lower', 'severity', 'Now', \"we've\", 'moved', 'them', 'to', 'S', 'and', 'maybe', 'that', 'caused', 'a', 'little', 'spike', 'That', 'could', 'be', 'the', 'case', 'that', 'we', 'did', 'in', 'a', 'limited', 'fashion', 'It', \"won't\", 'be', 'a', 'huge', 'volume', 'We', 'also', 'iterated', 'after', 'that', 'to', 'pin', 'on', 'priority', 'since', 'product', 'owns', 'prioritization', 'So', 'I', \"wouldn't\", 'account', 'it', 'entirely', 'to', 'that', 'I', 'mean', 'this', \"isn't\", 'the', 'infertile', 'key', 'review', 'but', 'I', 'know', 'that', \"they've\", 'gotten', 'backed', 'up', 'on', 'those', 'issues', 'So', 'if', 'some', 'some', 'good', 'portion', 'of', 'those', 'are', 'infertile', 'created', 'or', 'related', 'then', 'that', 'may', 'be', 'lifting', 'it', 'as', 'well', 'I', 'can', 'take', 'the', 'deeper', 'dig', 'in', 'and', 'then', 'provide', 'an', 'update', 'next', 'time', 'I', 'think', 'we', 'need', 'extra', 'debug', 'slicing', 'of', 'the', 'data', 'here', 'So', 'you', 'would', 'like', 'to', 'go', 'to', 'point', 'eight', 'Yeah', 'we', 'are', 'now', 'measuring', 'S', 'as', 'to', 'SLO', 'achievement', 'with', 'closed', 'bugs', 'But', 'if', 'you', 'then', 'look', 'at', 'the', 'number', 'of', 'bugs', \"it's\", 'exponential', 'growth', 'And', 'then', 'it', 'will', 'be', 'trivial', 'to', 'us', 'to', 'achieve', 'SLO', 'achievement', 'If', 'you', 'just', 'look', 'at', 'close', 'bugs', 'even', 'though', 'there', 'would', 'be', 'a', 'major', 'problem', 'in', 'the', 'company', 'of', 'all', 'bugs', 'are', 'overdue', 'As', 'long', 'as', 'I', 'only', 'close', 'ones', 'that', 'are', 'still', 'within', 'the', 'SLO', \"I'll\", 'have', 'great', 'achievement', 'So', 'I', 'think', 'we', \"shouldn't\", 'be', 'looking', 'at', 'the', 'closed', 'bugs', 'I', 'think', 'we', 'should', 'be', 'looking', 'at', 'open', 'bugs', 'The', 'entire', 'population', 'or', 'percentage', 'of', 'those', 'is', 'within', 'the', 'SLO', 'time', 'I', 'think', \"we're\", 'doing', 'it', 'the', 'wrong', 'way', 'Thanks', 'for', 'the', 'thanks', 'for', 'the', 'feedbacks', 'that', 'Hence', 'why', 'we', 'wanted', 'to', 'have', 'the', 'average', 'age', 'to', 'measure', \"what's\", 'outside', 'in', 'the', 'open', 'And', 'then', 'make', 'this', 'iteration', 'to', 'measure', 'also', 'measure', 'focus', 'on', 'the', 'age', 'of', 'all', 'opened', 'including', 'open', 'bugs', 'This', 'is', 'also', 'something', 'we', 'have', 'discussed', 'with', 'Christopher', 'in', 'the', 'next', 'iteration', 'as', 'well', 'And', 'we', 'happy', 'when', 'happy', 'to', 'adjust', 'So', 'the', 'key', 'Yes', 'go', 'ahead', 'So', 'average', 'age', 'would', 'get', 'closer', 'to', 'it', \"It's\", 'not', 'what', \"I'm\", 'proposing', 'What', \"I'm\", 'proposing', 'is', 'off', 'the', 'open', 'bugs', 'are', 'percentages', 'outside', 'of', 'SLO', 'So', 'display', 'it', 'as', 'a', 'percentage', 'You', 'do', 'now', 'just', 'do', 'it', 'about', 'the', 'open', 'bugs', 'month', 'or', 'close', 'Got', 'it', 'Okay', 'The', 'exceeding', 'SLO', 'for', 'open', 'bugs', 'Yeah', 'or', 'open', 'bugs', 'that', 'are', 'within', 'SLO', 'So', 'you', 'have', 'a', 'chart', 'that', 'should', 'go', 'up', 'and', 'to', 'the', 'right', 'like', 'everything', 'else', 'Sounds', 'great', 'We', 'can', 'take', 'it', 'to', 'the', 'next', 'data', 'metrics', 'work', 'stream', 'to', 'deliver', 'this', 'Cool', 'Thanks', 'Is', 'it', 'pretty', 'good', 'Yeah', 'I', 'like', 'it', 'You', 'make', 'you', 'have', 'to', 'figure', 'out', 'how', 'to', 'Because', 'we', 'like', 'to', 'be', 'able', 'to', 'have', 'charts', 'that', 'we', 'can', 'historically', 'reconstruct', 'if', 'we', 'need', 'to', 'So', 'in', 'tickets', 'close', 'out', 'you', 'need', 'to', 'go', 'through', 'their', 'history', 'to', 'figure', 'out', 'at', 'this', 'time', 'when', 'it', 'was', 'open', 'Did', 'it', 'breach', 'the', 'SLO', 'or', 'not', \"That's\", 'a', 'good', 'point', 'This', 'might', 'be', 'much', 'harder', 'computationally', 'And', 'so', 'I', 'totally', 'respect', 'if', 'we', 'can', 'do', 'it', 'for', 'that', 'reason', 'Yeah', 'I', 'think', \"that's\", 'a', 'good', 'point', 'Yeah', 'I', 'think', \"that's\", 'a', 'good', 'point', 'Cool', 'Nine', 'Yeah', 'I', 'just', 'wanted', 'to', 'ask', 'the', 'team', 'like', 'I', 'went', 'through', 'all', 'the', 'key', 'meeting', 'metrics', 'Everything', 'looked', 'in', 'line', 'with', 'prior', 'periods', 'and', 'look', 'good', 'Is', 'there', 'anything', 'the', 'team', 'wants', 'to', 'call', 'out', \"It's\", 'mostly', 'that', 'we', 'should', 'be', 'watching', 'Yeah', \"I'll\", 'call', 'out', 'So', 'the', 'good', 'news', 'is', 'in', 'Q', 'We', 'had', 'our', 'smallest', 'decline', 'over', 'several', 'quarters', 'So', 'we', 'only', 'went', 'down', 'by', 'a', 'tenth', 'of', 'a', 'point', 'The', 'quarter', 'previous', 'was', 'point', 'six', 'or', 'six', 'tenths', 'of', 'a', 'point', 'and', 'the', 'quarter', 'before', 'that', 'was', 'a', 'full', 'point', 'So', 'We', 'see', 'this', 'as', 'an', 'improvement', 'even', 'though', 'it', 'was', 'still', 'a', 'decline', 'but', \"it's\", 'still', 'a', 'decline', 'Obviously', 'we', 'want', 'this', 'actually', 'tracking', 'in', 'an', 'upward', 'direction', 'We', 'also', \"don't\", 'have', 'enough', 'data', 'to', 'know', 'whether', 'or', 'not', 'this', 'is', 'an', 'actual', 'real', 'trend', 'up', 'So', \"I'm\", 'optimistic', 'I', 'think', 'this', 'is', 'a', 'good', 'thing', 'We', 'have', 'had', 'a', 'much', 'keener', 'focus', 'on', 'us', 'over', 'the', 'past', 'several', 'quarters', 'And', \"that's\", 'why', 'I', 'think', 'okay', 'the', 'work', 'that', \"we've\", 'done', 'I', 'think', 'actually', 'is', 'catching', 'up', 'and', 'getting', 'noticed', 'in', 'sus', 'but', 'we', 'got', 'to', 'keep', 'an', 'eye', 'on', 'it', 'We', \"can't\", 'We', 'cannot', 'assume', 'that', \"that's\", 'the', 'case', 'Yeah', 'and', 'the', 'bug', 'discussion', 'above', 'just', 'kind', 'of', 'points', 'out', 'that', 'like', 'we', 'have', 'an', 'underlying', 'problem', 'right', 'now', 'in', 'our', 'metrics', 'measurement', 'So', 'if', 'we', 'change', 'the', 'measurements', 'to', 'reflect', 'that', 'then', 'hopefully', \"we're\", 'in', 'good', 'shape', 'If', 'we', \"don't\", 'and', 'we', 'flat', 'line', 'and', 'address', 'it', 'so', 'that', 'we', 'flat', 'line', 'open', 'Ss', 'and', 'Ss', 'you', 'will', 'see', 'a', 'temporary', 'jump', 'in', 'and', 'above', 'SLOs', 'As', 'we', 'clear', 'out', 'that', 'back', \"I'll\", 'go', 'over', 'that', 'period', 'of', 'time', 'So', 'we', 'have', 'a', 'point', 'C', 'which', 'is', 'similar', 'to', 'infrastructure', 'We', 'need', 'to', 'get', 'more', 'security', 'work', 'prioritized', 'or', 'hearing', 'that', 'from', 'the', 'team', 'but', 'neither', 'that', 'problem', 'or', 'that', 'activity', 'is', 'sort', 'of', 'currently', 'reflected', 'in', 'our', 'security', 'metrics', 'So', 'we', 'have', 'some', 'work', 'to', 'do', 'long', 'term', 'to', 'make', 'sure', 'the', 'we', 'see', 'things', 'like', 'that', 'in', 'the', 'metrics', 'and', 'the', 'measurements', 'that', \"we're\", 'making', 'So', 'back', 'to', 'you', 'said', 'So', 'now', 'that', 'Nero', 'MR', 'rate', 'seems', 'significantly', 'below', 'target', 'And', 'maybe', 'I', 'helped', 'that', 'it', 'would', 'bounce', 'back', 'from', 'December', 'I', 'think', 'it', 'bounced', 'back', 'but', 'not', 'back', 'on', 'target', 'Any', 'any', 'context', 'there', \"What's\", 'going', 'on', 'Yeah', 'so', 'with', 'family', 'and', 'friends', 'days', 'we', 'actually', 'had', 'some', 'heavier', 'of', 'vacation', 'days', 'And', 'we', 'historically', 'have', 'one', 'thing', 'to', 'know', 'is', 'that', 'we', 'are', 'actually', 'at', 'a', 'higher', 'MR', 'rate', 'If', 'you', 'look', 'if', 'you', 'go', 'back', 'the', 'last', 'months', \"we're\", 'actually', 'at', 'a', 'higher', 'Nero', 'MR', 'rate', 'than', 'we', 'were', 'back', 'in', 'each', 'month', 'this', 'year', 'So', 'if', 'you', 'compare', 'October', 'to', 'October', 'November', 'to', 'November', 'and', 'January', \"I'm\", 'sorry', 'October', 'November', 'December', 'and', 'January', 'comparatively', 'to', 'last', 'year', 'which', 'will', 'find', 'is', \"we're\", 'between', 'a', 'half', 'point', 'and', 'a', 'MR', 'rate', 'above', 'where', 'we', 'were', 'in', 'the', 'month', 'of', 'previous', 'year', \"That's\", 'great', 'contact', 'Thank', 'you', 'Chris', 'for', 'good', 'work', 'Yeah', 'so', 'the', 'expectation', 'is', 'is', 'that', 'February', 'is', 'a', 'short', 'month', 'We', 'were', 'at', 'I', 'think', 'work', 'days', 'with', 'friends', 'and', 'family', 'day', 'and', 'other', 'things', 'Obviously', 'seven', 'carriages', 'in', 'Texas', \"doesn't\", 'help', 'things', 'either', 'for', 'the', 'folks', 'who', 'are', 'working', 'in', 'Texas', 'But', 'hopefully', 'the', 'rest', 'of', 'the', 'team', 'is', 'being', 'effective', 'I', 'was', 'hoping', 'to', 'see', 'a', 'better', 'result', 'right', 'now', 'but', 'with', 'four', 'or', 'five', 'days', 'particularly', 'around', 'release', 'week', \"That's\", 'usually', 'when', 'we', 'see', 'do', 'do', 'see', 'a', 'little', 'bit', 'higher', 'activity', 'So', \"that's\", 'not', 'accounted', 'for', 'yet', 'But', 'you', 'know', 'Marches', 'Marches', 'when', \"I'm\", 'expecting', 'kind', 'of', 'see', 'a', 'real', 'rebound', 'much', 'like', 'we', 'did', 'last', 'year', 'Awesome', 'Thanks', 'The', 'other', 'context', \"I'll\", 'give', 'is', 'we', 'now', 'do', 'time', 'series', 'targets', 'So', 'when', 'we', 'change', 'the', 'target', \"you'll\", 'see', \"they're\", 'reflected', 'in', 'the', 'line', 'So', 'if', 'we', 'were', 'to', 'look', 'back', 'historically', 'here', 'the', 'goal', 'here', 'was', 'actually', 'lower', 'and', 'Christopher', 'was', 'ambitious', 'So', 'we', 'kept', 'raising', 'it', 'We', 'kept', 'meeting', 'that', 'So', 'it', 'should', 'stare', 'step', 'here', 'and', 'we', 'could', 'go', 'back', 'and', 'reconstruct', 'that', 'if', 'we', 'really', 'wanted', 'to', 'And', 'then', 'ignoring', 'the', 'sort', 'of', 'the', 'seasonal', 'dip', 'here', 'we', 'raised', 'it', 'to', 'I', 'think', 'And', 'then', 'we', 'realize', \"we're\", 'kind', 'of', 'hitting', 'that', 'point', 'of', 'doing', 'and', 'raising', 'returns', 'and', 'the', 'right', 'thing', 'to', 'do', 'business', 'wise', 'And', 'this', 'is', 'in', 'our', 'FY', 'direction', 'is', 'hold', 'the', 'line', 'at', 'productivity', \"Let's\", 'start', 'to', 'raise', 'other', 'things', 'related', 'to', 'quality', 'security', 'availability', 'and', 'what', 'not', 'So', \"that's\", 'kind', 'of', 'what', 'you', 'are', \"you're\", 'seeing', 'this', 'bump', 'is', 'we', 'raised', 'it', 'and', 'we', 'realized', 'okay', \"that's\", 'not', 'the', 'we', \"shouldn't\", 'raise', 'it', 'anymore', 'And', 'we', 'brought', 'it', 'back', 'down', 'to', 'So', 'will', 'be', 'the', 'dark', 'going', 'forward', \"I'm\", 'going', 'to', 'try', 'to', 'get', 'better', 'a', 'lot', 'of', 'other', 'things', 'while', 'preventing', 'this', 'from', 'dipping', 'And', 'just', 'want', 'to', 'call', 'out', 'that', \"it's\", 'not', 'necessary', 'Like', 'and', 'higher', 'MR', 'rates', 'should', 'also', 'help', 'to', 'address', 'security', 'and', 'quality', 'and', 'other', 'things', 'because', \"you're\", 'more', 'productive', 'So', 'you', 'can', 'fix', 'more', 'things', 'so', \"it's\", 'not', 'necessarily', 'opposite', 'But', 'I', 'agree', 'with', 'that', \"Let's\", 'hold', 'the', 'line', 'is', 'then', 'is', 'a', 'great', 'number', 'and', 'and', 'focus', 'on', 'other', 'indicators', 'to', 'improve', 'that', 'makes', 'it', 'on', 'a', 'sense', 'Cool', 'Well', 'said', 'All', 'right', \"that's\", 'the', 'agenda', 'Anyone', 'want', 'to', 'vocalize', 'anything', 'else', 'Great', 'Well', 'thanks', 'everybody', 'And', \"I'm\", 'going', 'to', 'go', 'check', 'on', 'my', 'four', 'year', 'old', 'and', 'see', 'if', 'she', 'got', 'what', 'whatever', 'she', 'needed', 'So', 'cheers', 'and', 'toxic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S2YCWBF6v29",
        "outputId": "03252d01-99a8-4bca-ea1c-6aca83a507e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hi': 1, 'this': 52, 'is': 66, 'eric': 3, 'johnson': 1, \"it's\": 26, 'february': 3, 'and': 108, 'the': 177, 'engineering': 5, 'key': 7, 'review': 5, 'at': 19, 'gitlab': 4, 'so': 71, \"i've\": 3, 'got': 9, 'number': 11, 'four': 6, 'in': 50, 'agenda': 2, 'which': 8, 'a': 68, 'proposal': 4, 'to': 118, 'break': 1, 'up': 12, 'meeting': 5, 'into': 4, 'department': 2, 'reviews': 2, 'currently': 2, 'development': 5, 'quality': 4, 'security': 6, 'ux': 2, 'infrastructure': 7, 'support': 2, 'their': 3, 'own': 1, 'already': 1, 'i': 70, 'have': 33, 'reasons': 1, 'why': 8, 'increased': 2, 'visibility': 1, 'able': 3, 'go': 15, 'deeper': 3, 'objectivity': 1, 'with': 18, 'my': 8, 'reports': 1, 'can': 14, 'manage': 1, 'groups': 1, 'allow': 2, 'me': 4, 'more': 7, 'time': 8, 'focus': 6, 'on': 41, 'new': 2, 'markets': 1, 'shift': 2, 'of': 61, 'question': 1, 'asker': 1, 'mode': 1, 'then': 19, 'generating': 1, 'content': 1, 'answering': 1, 'questions': 1, 'these': 4, 'meetings': 3, 'avoid': 1, 'adding': 1, 'three': 2, 'net': 1, 'stakeholders': 1, 'counters': 1, 'propose': 1, 'we': 98, 'do': 17, 'sort': 6, 'two': 4, 'month': 10, 'rotation': 1, 'one': 15, 'would': 11, 'how': 6, 'people': 2, 'feel': 2, 'about': 8, 'that': 93, 'think': 25, 'group': 2, 'conversations': 3, 'working': 4, 'really': 5, 'well': 12, \"i'm\": 19, 'supportive': 2, 'smallest': 2, 'thing': 15, 'maybe': 6, 'need': 7, 'like': 26, 'biggest': 2, 'super': 1, 'central': 1, 'but': 24, 'you': 41, 'proposed': 1, \"don't\": 5, 'could': 5, 'see': 17, 'either': 2, 'way': 4, \"let's\": 6, 'stick': 1, \"we'll\": 2, 'try': 2, 'it': 37, 'be': 28, 'flexible': 1, 'mean': 2, 'larger': 1, 'they': 8, 'frequently': 1, 'or': 15, 'something': 3, \"i'll\": 8, 'goes': 3, 'all': 9, 'right': 14, 'five': 3, \"we've\": 7, 'rd': 5, 'overall': 7, 'mr': 16, 'rate': 16, 'also': 10, 'wider': 11, 'both': 2, 'as': 28, 'top': 1, 'level': 1, 'kpis': 1, 'for': 23, 'difference': 1, 'between': 2, 'them': 5, 'simplest': 1, 'sense': 4, 'includes': 2, 'community': 16, 'contributions': 8, 'mrs': 11, 'problems': 1, 'are': 21, 'internally': 2, 'external': 6, 'duplicates': 1, 'should': 12, 'just': 27, 'narrow': 2, 'plus': 1, 'oh': 2, 'yeah': 24, 'say': 5, 'okay': 8, \"there's\": 13, 'check': 2, 'taxonomy': 3, 'confirm': 1, \"that's\": 26, 'reasoning': 1, 'understanding': 1, 'believe': 1, 'water': 1, 'captures': 1, 'only': 6, 'no': 2, 'internal': 1, 'reason': 2, 'measure': 4, 'data': 12, 'most': 2, 'likely': 2, 'failure': 1, 'modes': 1, 'lose': 1, \"we're\": 15, 'get': 11, 'gets': 1, 'goofy': 1, 'when': 9, 'look': 7, 'specific': 3, 'team': 14, 'within': 4, 'company': 5, 'there': 12, 'outside': 6, \"aren't\": 1, 'viewed': 2, 'by': 2, 'effectively': 1, \"they're\": 4, 'not': 21, 'from': 16, 'use': 2, 'kind': 9, 'reflect': 2, 'very': 2, 'saying': 2, 'if': 28, 'someone': 2, 'plan': 4, 'contributes': 1, 'verify': 2, 'its': 1, 'quite': 2, 'fine': 1, 'versus': 1, 'will': 8, 'oftentimes': 1, 'contribute': 3, 'developments': 1, 'work': 8, \"won't\": 2, 'counted': 1, 'potential': 1, 'bit': 6, 'funkiness': 1, 'talk': 3, 'separately': 1, \"didn't\": 1, 'critique': 2, \"doesn't\": 5, 'necessarily': 3, 'make': 8, 'intuitive': 1, 'part': 3, 'thrown': 1, 'out': 11, 'because': 11, 'duplicative': 1, 'thought': 1, 'still': 6, 'problem': 5, 'move': 1, 'feels': 1, 'drive': 3, 'specifically': 1, 'authors': 1, 'than': 3, 'per': 4, 'moves': 1, 'productivity': 2, 'scenarios': 1, 'actually': 8, 'less': 2, 'contributors': 1, 'wait': 3, 'second': 1, \"you're\": 3, 'contributor': 1, 'goodness': 1, 'member': 4, 'those': 8, 'above': 4, 'division': 1, 'ones': 3, 'below': 2, 'members': 2, 'case': 4, 'lily': 3, 'checking': 1, 'now': 8, 'our': 10, 'unless': 1, 'start': 2, 'calling': 1, \"shouldn't\": 3, 'clarifying': 1, 'here': 6, 'numerator': 1, 'denominator': 1, 'what': 13, 'doing': 3, 'trying': 3, 'many': 2, 'does': 2, 'send': 2, 'size': 2, 'organization': 1, 'sorry': 7, 'childhood': 1, 'emergency': 1, 'door': 1, 'explain': 1, 'context': 5, 'behind': 1, 'grow': 1, 'sure': 3, 'keep': 3, 'logical': 1, 'flatline': 1, 'org': 1, 'before': 2, 'know': 8, \"you've\": 1, 'outgrown': 1, 'seeing': 2, 'created': 2, 'presophisticated': 1, 'prefixes': 1, 'postfixes': 1, 'things': 10, 'reality': 1, 'forgetting': 1, 'hard': 2, 'discussing': 1, \"i'd\": 2, 'rather': 2, 'name': 1, 'simply': 1, 'names': 1, 'using': 1, 'f': 1, 'track': 2, 'kpi': 1, 'percentage': 6, 'total': 1, 'come': 2, 'over': 4, 'drop': 1, 'love': 2, 'instead': 1, 'complex': 1, 'game': 2, 'want': 7, 'produce': 2, 'fewer': 1, 'engineers': 2, 'your': 3, 'goal': 2, 'easy': 1, 'achieve': 2, 'tell': 1, 'half': 2, 'different': 2, 'metrics': 8, 'prevent': 1, 'happening': 1, 'same': 1, 'slas': 1, 'asset': 1, 'buttress': 1, 'another': 2, 'robust': 1, 'simplifying': 1, 'cto': 1, 'even': 3, 'understand': 1, 'went': 3, 'overboard': 1, 'forgot': 1, 'was': 13, 'agreeing': 1, 'stuff': 1, 'morning': 2, 'remind': 1, \"can't\": 2, 'head': 1, 'investors': 1, 'ask': 3, 'cool': 5, 'um': 2, 'max': 2, 'transition': 1, 'great': 6, 'hold': 3, 'talking': 1, 'mulberry': 1, 'thanks': 6, 'call': 4, 'late': 1, 'timeline': 1, 'pis': 1, 'raw': 1, 'confirming': 1, 'definition': 2, 'counts': 1, 'six': 3, 'christopher': 3, 'looking': 5, 'had': 7, 'graph': 1, 'played': 1, 'around': 4, 'point': 15, 'draft': 1, 'probably': 2, 'months': 2, 'back': 13, 'remember': 1, 'fyi': 2, 'were': 7, 'any': 5, 'particular': 1, 'particularly': 2, \"haven't\": 2, 'updates': 1, 'days': 5, 'apparently': 1, 'lag': 4, 'issue': 4, 'been': 4, 'problematic': 1, 'basically': 2, 'updated': 1, 'next': 6, 'some': 14, 'color': 1, 'medication': 1, 'later': 1, 'seven': 3, 'continue': 2, 'said': 3, 'addition': 1, 'tbi': 1, 'status': 1, 'wanted': 4, 'touch': 1, 'postgres': 1, 'replication': 4, 'real': 3, 'quick': 1, 'arms': 1, 'wrapped': 1, 'attention': 2, 'commenting': 1, 'hitting': 2, 'towards': 1, 'last': 5, 'improvements': 4, 'product': 3, 'side': 2, 'whose': 1, 'responsibility': 1, 'getting': 2, 'handle': 1, 'constraints': 1, 'mentioning': 1, 'queue': 1, 'an': 8, 'hour': 1, 'ago': 1, 'unrelated': 1, 'dri': 2, 'needs': 2, 'course': 1, 'dependency': 1, 'where': 7, 'being': 3, 'piqued': 1, 'source': 1, 'slave': 1, 'host': 5, 'secondary': 1, 'pulled': 1, 'escalations': 1, 'action': 1, 'far': 1, 'creating': 1, 'dedicated': 4, 'pull': 1, 'did': 5, 'saw': 1, 'craig': 2, 'gums': 1, 'little': 4, 'database': 4, 'figure': 3, 'truly': 1, 'computation': 1, 'old': 2, 'resource': 2, 'server': 1, 'tuning': 3, 'occur': 1, 'having': 3, 'conflicting': 3, 'query': 2, 'traffic': 2, 'coming': 1, 'other': 8, 'workloads': 1, 'performance': 1, 'made': 1, 'relate': 1, 'topic': 1, 'demand': 2, 'layer': 1, 'dot': 1, 'com': 1, 'activities': 1, 'improving': 1, 'definitely': 2, 'actions': 1, 'going': 10, 'take': 3, 'though': 3, 'separating': 1, 'dealing': 1, 'profile': 1, 'queries': 1, 'affect': 1, 'ability': 1, 'update': 4, 'steve': 2, 'partner': 1, 'databases': 1, 'increase': 1, 'down': 5, 'unclear': 1, 'bang': 1, 'buck': 1, 'computational': 1, 'dedication': 1, 'good': 11, 'squeeze': 1, 'balloon': 1, 'area': 1, 'honor': 1, 'itself': 1, 'put': 1, 'infricky': 1, 'week': 2, 'thank': 3, 'mecon': 1, 'yes': 2, 'rob': 1, 'assassins': 1, 'provide': 3, 'previous': 3, 'improve': 2, 'defect': 1, 'tracking': 2, 'against': 1, 'slos': 3, 'first': 1, 'iteration': 3, 'pi': 2, 'experimenting': 1, 'show': 2, 'defects': 1, 'findings': 1, 'hovering': 1, 'focused': 1, 'mostly': 2, 's': 7, 'hence': 2, 'ss': 3, 'lower': 3, 'b': 2, 'measurement': 2, 'average': 4, 'open': 10, 'box': 1, 'age': 8, 'give': 2, 'us': 4, 'whole': 2, 'picture': 2, \"what's\": 4, 'left': 1, 'cleaning': 1, 'backlog': 1, 'yet': 2, 'beyond': 1, 'off': 2, 'c': 2, 'through': 3, 'charts': 3, 'noted': 1, 'spike': 2, 'meantime': 1, 'close': 5, 'insight': 1, 'supplemental': 1, 'end': 1, 'helps': 1, 'seen': 1, 'dip': 2, 'nor': 1, 'count': 1, 'latter': 1, 'dig': 2, 'reevaluate': 1, 'everything': 3, 'synced': 1, 'christie': 1, 'insights': 1, 'wondering': 1, 'fact': 1, 'changed': 1, 'severity': 2, 'across': 1, 'board': 1, 'may': 2, 'older': 1, 'bugs': 12, \"hadn't\": 1, 'addressed': 1, 'moved': 1, 'caused': 1, 'limited': 1, 'fashion': 1, 'huge': 1, 'volume': 1, 'iterated': 1, 'after': 1, 'pin': 1, 'priority': 1, 'since': 1, 'owns': 1, 'prioritization': 1, \"wouldn't\": 1, 'account': 1, 'entirely': 1, \"isn't\": 1, 'infertile': 2, \"they've\": 1, 'gotten': 1, 'backed': 1, 'issues': 1, 'portion': 1, 'related': 2, 'lifting': 1, 'extra': 1, 'debug': 1, 'slicing': 1, 'eight': 1, 'measuring': 1, 'slo': 8, 'achievement': 3, 'closed': 2, 'exponential': 1, 'growth': 1, 'trivial': 1, 'major': 1, 'overdue': 1, 'long': 2, 'entire': 1, 'population': 1, 'wrong': 1, 'feedbacks': 1, 'opened': 1, 'including': 1, 'discussed': 1, 'happy': 2, 'adjust': 1, 'ahead': 1, 'closer': 1, 'proposing': 2, 'percentages': 1, 'display': 1, 'exceeding': 1, 'chart': 1, 'else': 2, 'sounds': 1, 'stream': 1, 'deliver': 1, 'pretty': 1, 'historically': 3, 'reconstruct': 2, 'tickets': 1, 'history': 1, 'breach': 1, 'might': 1, 'much': 3, 'harder': 1, 'computationally': 1, 'totally': 1, 'respect': 1, 'nine': 1, 'looked': 1, 'line': 6, 'prior': 1, 'periods': 1, 'anything': 2, 'wants': 1, 'watching': 1, 'news': 1, 'q': 1, 'decline': 3, 'several': 2, 'quarters': 2, 'tenth': 1, 'quarter': 2, 'tenths': 1, 'full': 1, 'improvement': 1, 'obviously': 2, 'upward': 1, 'direction': 2, 'enough': 1, 'whether': 1, 'actual': 1, 'trend': 1, 'optimistic': 1, 'keener': 1, 'past': 1, 'done': 1, 'catching': 1, 'noticed': 1, 'sus': 1, 'eye': 1, 'cannot': 1, 'assume': 1, 'bug': 1, 'discussion': 1, 'points': 1, 'underlying': 1, 'change': 2, 'measurements': 2, 'hopefully': 2, 'shape': 1, 'flat': 2, 'address': 2, 'temporary': 1, 'jump': 1, 'clear': 1, 'period': 1, 'similar': 1, 'prioritized': 1, 'hearing': 1, 'neither': 1, 'activity': 2, 'reflected': 2, 'term': 1, 'making': 1, 'nero': 2, 'seems': 1, 'significantly': 1, 'target': 3, 'helped': 1, 'bounce': 1, 'december': 2, 'bounced': 1, 'family': 2, 'friends': 2, 'heavier': 1, 'vacation': 1, 'higher': 4, 'each': 1, 'year': 5, 'compare': 1, 'october': 3, 'november': 3, 'january': 2, 'comparatively': 1, 'find': 1, 'contact': 1, 'chris': 1, 'expectation': 1, 'short': 1, 'day': 1, 'carriages': 1, 'texas': 2, 'help': 2, 'folks': 1, 'who': 1, 'rest': 1, 'effective': 1, 'hoping': 1, 'better': 2, 'result': 1, 'release': 1, 'usually': 1, 'accounted': 1, 'marches': 2, 'expecting': 1, 'rebound': 1, 'awesome': 1, 'series': 1, 'targets': 1, \"you'll\": 1, 'ambitious': 1, 'kept': 2, 'raising': 2, 'stare': 1, 'step': 1, 'ignoring': 1, 'seasonal': 1, 'raised': 2, 'realize': 1, 'returns': 1, 'business': 1, 'wise': 1, 'fy': 1, 'raise': 2, 'availability': 1, 'bump': 1, 'realized': 1, 'anymore': 1, 'brought': 1, 'dark': 1, 'forward': 1, 'lot': 1, 'while': 1, 'preventing': 1, 'dipping': 1, 'necessary': 1, 'rates': 1, 'productive': 1, 'fix': 1, 'opposite': 1, 'agree': 1, 'indicators': 1, 'makes': 1, 'anyone': 1, 'vocalize': 1, 'everybody': 1, 'she': 2, 'whatever': 1, 'needed': 1, 'cheers': 1, 'toxic': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filler_word_counts = {k:0 for k in filler_word_list}\n",
        "for w in filler_word_list:\n",
        "    try:\n",
        "        print(w, word_counts[w])\n",
        "        filler_word_counts[w] = word_counts[w]\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvMA252f5W5a",
        "outputId": "64efba5d-020e-4585-ec13-54b4715d1e3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "um 2\n",
            "oh 2\n",
            "very 2\n",
            "really 5\n",
            "like 26\n",
            "so 71\n",
            "and 108\n",
            "but 24\n",
            "okay 8\n",
            "well 12\n",
            "now 8\n",
            "definitely 2\n",
            "actually 8\n",
            "basically 2\n",
            "totally 1\n",
            "right 14\n",
            "just 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filler_two_words_counts = {k:0 for k in filler_two_words_list}\n",
        "for i, t in enumerate(text_tokens):\n",
        "    try:\n",
        "        two_t = t + \" \" + text_tokens[i+1]\n",
        "        if two_t in filler_two_words_list:\n",
        "            print(i, two_t)\n",
        "            filler_two_words_counts[two_t] += 1\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0k_9Zw08PSh",
        "outputId": "658ffee2-79d7-4107-bc7c-ba34baa092ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "878 you know\n",
            "1641 you know\n",
            "3360 you know\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filler_word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57cJ5sm19IJ0",
        "outputId": "8d7e3990-d49d-4388-be06-ee3dd7afb216"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'um': 2, 'huh': 0, 'oh': 2, 'er': 0, 'ah': 0, 'uh': 0, 'very': 2, 'really': 5, 'highly': 0, 'like': 26, 'so': 71, 'and': 108, 'but': 24, 'ok': 0, 'okay': 8, 'well': 12, 'now': 8, 'literally': 0, 'definitely': 2, 'actually': 8, 'basically': 2, 'totally': 1, 'seriously': 0, 'right': 14, 'just': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filler_two_words_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoUd5upH9QUK",
        "outputId": "23f91382-3028-413c-dcee-00675c6bec5c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i guess': 0, 'i mean': 0, 'you know': 3, 'i suppose': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_filler_words_counts = {**filler_word_counts, **filler_two_words_counts}\n",
        "overall_filler_words_counts = dict(sorted(overall_filler_words_counts.items(), key=lambda x: x[1], reverse=True))\n",
        "print(overall_filler_words_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1HEJe6i9S-B",
        "outputId": "e6d33d9e-69ec-4568-a03f-0649675c903e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'and': 108, 'so': 71, 'just': 27, 'like': 26, 'but': 24, 'right': 14, 'well': 12, 'okay': 8, 'now': 8, 'actually': 8, 'really': 5, 'you know': 3, 'um': 2, 'oh': 2, 'very': 2, 'definitely': 2, 'basically': 2, 'totally': 1, 'huh': 0, 'er': 0, 'ah': 0, 'uh': 0, 'highly': 0, 'ok': 0, 'literally': 0, 'seriously': 0, 'i guess': 0, 'i mean': 0, 'i suppose': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jargon\n",
        "* https://stackoverflow.com/questions/28339622/is-there-a-corpus-of-english-words-in-nltk\n",
        "* https://stackoverflow.com/questions/39178054/python-removing-some-punctuation-from-text\n",
        "* https://stackoverflow.com/questions/3788870/how-to-check-if-a-word-is-an-english-word-with-python\n",
        "* https://stackoverflow.com/questions/29381919/importerror-the-enchant-c-library-was-not-found-please-install-it-via-your-o"
      ],
      "metadata": {
        "id": "qjWLl20Q-VqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import words"
      ],
      "metadata": {
        "id": "O4AnsuUC-WTO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP44ZKXo-4q9",
        "outputId": "d262e51b-626c-456d-df58-e2fe27c37d32"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet "
      ],
      "metadata": {
        "id": "3yDGGDikAoao"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEPx_j1mAwJ3",
        "outputId": "567d8246-0aa3-4330-d922-eb5f29c04a95"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = words.words() + list(wordnet.words())"
      ],
      "metadata": {
        "id": "wEPGfFM0Aqr-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyenchant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2uypuTpByH6",
        "outputId": "94ef4c5d-58f6-4f59-9c7f-fd5d4794b546"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libenchant1c2a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5doDjpyB-yI",
        "outputId": "32155b03-db08-45ac-d62a-f87592757469"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libhunspell-1.7-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.7-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 1,316 kB of archives.\n",
            "After this operation, 5,474 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libtext-iconv-perl amd64 1.7-7 [13.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libaspell15 amd64 0.60.8-1ubuntu0.1 [328 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 emacsen-common all 3.0.4 [14.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 dictionaries-common all 1.28.1 [178 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 aspell amd64 0.60.8-1ubuntu0.1 [88.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 aspell-en all 2018.04.16-0-1 [299 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 hunspell-en-us all 1:2018.04.16-1 [170 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libhunspell-1.7-0 amd64 1.7.0-2build2 [147 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 libenchant1c2a amd64 1.6.0-11.3build1 [64.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 enchant amd64 1.6.0-11.3build1 [12.4 kB]\n",
            "Fetched 1,316 kB in 1s (1,116 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 122349 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-7_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-7) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.8-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.8-1ubuntu0.1) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_3.0.4_all.deb ...\n",
            "Unpacking emacsen-common (3.0.4) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.28.1_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.28.1) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.8-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking aspell (0.60.8-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2018.04.16-0-1_all.deb ...\n",
            "Unpacking aspell-en (2018.04.16-0-1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2018.04.16-1_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2018.04.16-1) ...\n",
            "Selecting previously unselected package libhunspell-1.7-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.7-0_1.7.0-2build2_amd64.deb ...\n",
            "Unpacking libhunspell-1.7-0:amd64 (1.7.0-2build2) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.3build1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.3build1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.3build1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.3build1) ...\n",
            "Setting up libtext-iconv-perl (1.7-7) ...\n",
            "Setting up libaspell15:amd64 (0.60.8-1ubuntu0.1) ...\n",
            "Setting up emacsen-common (3.0.4) ...\n",
            "Setting up libhunspell-1.7-0:amd64 (1.7.0-2build2) ...\n",
            "Setting up dictionaries-common (1.28.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up aspell (0.60.8-1ubuntu0.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up hunspell-en-us (1:2018.04.16-1) ...\n",
            "Setting up aspell-en (2018.04.16-0-1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.3build1) ...\n",
            "Setting up enchant (1.6.0-11.3build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for dictionaries-common (1.28.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import enchant\n",
        "d = enchant.Dict(\"en_US\")"
      ],
      "metadata": {
        "id": "sIVONENABugK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jargon_counts = {}\n",
        "for i, t in enumerate(text_tokens):\n",
        "    # use a combo of the two instead of just NLTK\n",
        "    if not d.check(t) and not d.check(t[0].upper() + t[1:]) and t not in vocabulary:\n",
        "        print(t)\n",
        "        if t not in jargon_counts:\n",
        "            jargon_counts[t] = 0\n",
        "        jargon_counts[t] += 1\n",
        "\n",
        "jargon_counts = dict(sorted(jargon_counts.items(), key=lambda x: x[1], reverse=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSDzaIszBu9W",
        "outputId": "809328b3-96ac-4dbb-a1bb-78ee6b8b6dfa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GitLab\n",
            "UX\n",
            "UX\n",
            "KPIs\n",
            "MRs\n",
            "MRs\n",
            "MRs\n",
            "MRs\n",
            "GitLab\n",
            "GitLab\n",
            "MRs\n",
            "GitLab\n",
            "MRs\n",
            "MRs\n",
            "flatline\n",
            "presophisticated\n",
            "postfixes\n",
            "KPI\n",
            "MRs\n",
            "MRs\n",
            "SLAs\n",
            "CTO\n",
            "PIs\n",
            "MRs\n",
            "TBI\n",
            "postgres\n",
            "DRI\n",
            "DRI\n",
            "infricky\n",
            "SLOs\n",
            "SLOs\n",
            "Ss\n",
            "MRs\n",
            "SLO\n",
            "SLO\n",
            "SLO\n",
            "SLO\n",
            "feedbacks\n",
            "SLO\n",
            "SLO\n",
            "SLO\n",
            "SLO\n",
            "Ss\n",
            "Ss\n",
            "SLOs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(jargon_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owVml2QkDPLb",
        "outputId": "0870518e-8315-4ef1-860c-f6d16274c19b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MRs': 11, 'SLO': 8, 'GitLab': 4, 'SLOs': 3, 'Ss': 3, 'UX': 2, 'DRI': 2, 'KPIs': 1, 'flatline': 1, 'presophisticated': 1, 'postfixes': 1, 'KPI': 1, 'SLAs': 1, 'CTO': 1, 'PIs': 1, 'TBI': 1, 'postgres': 1, 'infricky': 1, 'feedbacks': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of where the NLTK list is useful\n",
        "print(d.check(\"october\"))\n",
        "print(\"october\" in vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iijxO7h_Ci-u",
        "outputId": "ab8d0816-1b02-406a-a893-de2bb02dc363"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}